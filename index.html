<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<!--  This file is generated by Nim. -->
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />

<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- Favicon -->
<link rel="shortcut icon" href="data:image/x-icon;base64,AAABAAEAEBAAAAEAIABoBAAAFgAAACgAAAAQAAAAIAAAAAEAIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AAAAAAUAAAAF////AP///wD///8A////AP///wD///8A////AP///wD///8A////AAAAAAIAAABbAAAAlQAAAKIAAACbAAAAmwAAAKIAAACVAAAAWwAAAAL///8A////AP///wD///8A////AAAAABQAAADAAAAAYwAAAA3///8A////AP///wD///8AAAAADQAAAGMAAADAAAAAFP///wD///8A////AP///wAAAACdAAAAOv///wD///8A////AP///wD///8A////AP///wD///8AAAAAOgAAAJ3///8A////AP///wAAAAAnAAAAcP///wAAAAAoAAAASv///wD///8A////AP///wAAAABKAAAAKP///wAAAABwAAAAJ////wD///8AAAAAgQAAABwAAACIAAAAkAAAAJMAAACtAAAAFQAAABUAAACtAAAAkwAAAJAAAACIAAAAHAAAAIH///8A////AAAAAKQAAACrAAAAaP///wD///8AAAAARQAAANIAAADSAAAARf///wD///8AAAAAaAAAAKsAAACk////AAAAADMAAACcAAAAnQAAABj///8A////AP///wAAAAAYAAAAGP///wD///8A////AAAAABgAAACdAAAAnAAAADMAAAB1AAAAwwAAAP8AAADpAAAAsQAAAE4AAAAb////AP///wAAAAAbAAAATgAAALEAAADpAAAA/wAAAMMAAAB1AAAAtwAAAOkAAAD/AAAA/wAAAP8AAADvAAAA3gAAAN4AAADeAAAA3gAAAO8AAAD/AAAA/wAAAP8AAADpAAAAtwAAAGUAAAA/AAAA3wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAADfAAAAPwAAAGX///8A////AAAAAEgAAADtAAAAvwAAAL0AAADGAAAA7wAAAO8AAADGAAAAvQAAAL8AAADtAAAASP///wD///8A////AP///wD///8AAAAAO////wD///8A////AAAAAIcAAACH////AP///wD///8AAAAAO////wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A//8AAP//AAD4HwAA7/cAAN/7AAD//wAAoYUAAJ55AACf+QAAh+EAAAAAAADAAwAA4AcAAP5/AAD//wAA//8AAA=="/>

<!-- Google fonts -->
<link href='https://fonts.googleapis.com/css?family=Raleway:400,600,900' rel='stylesheet' type='text/css'/>
<link href='https://fonts.googleapis.com/css?family=Source+Code+Pro:400,500,600' rel='stylesheet' type='text/css'/>

<!-- CSS -->
<title>Module arraymancer</title>
<style type="text/css" >
/*
Stylesheet for use with Docutils/rst2html.

See http://docutils.sf.net/docs/howto/html-stylesheets.html for how to
customize this style sheet.

Modified from Chad Skeeters' rst2html-style
https://bitbucket.org/cskeeters/rst2html-style/

Modified by Boyd Greenfield
*/
/* SCSS variables */
/* Text weights */
/* Body colors */
/* Text colors */
/* Link colors */
/* Syntax highlighting colors */
/* Pct changes */
/* Mixins */
/* Body/layout */
html {
  font-size: 100%;
  -webkit-text-size-adjust: 100%;
  -ms-text-size-adjust: 100%; }

/* Where we want fancier font if available */
h1, h2, h3, h4, h5, h6, p.module-desc, table.docinfo + blockquote p, table.docinfo blockquote p, h1 + blockquote p {
  font-family: "Raleway", "Helvetica Neue", "HelveticaNeue", Helvetica, Arial, sans-serif !important; }

h1.title {
  font-weight: 900; }

body {
  font-family: "Helvetica Neue", "HelveticaNeue", "Raleway", Helvetica, Arial, sans-serif;
  font-weight: 400;
  font-size: 14px;
  line-height: 20px;
  color: #666;
  background-color: rgba(252, 248, 244, 0.75); }

/* Skeleton grid */
.container {
  position: relative;
  width: 100%;
  max-width: 960px;
  margin: 0 auto;
  padding: 0 20px;
  box-sizing: border-box; }

.column,
.columns {
  width: 100%;
  float: left;
  box-sizing: border-box; }

/* For devices larger than 400px */
@media (min-width: 400px) {
  .container {
    width: 100%;
    padding: 0; } }
/* For devices larger than 650px */
@media (min-width: 650px) {
  .container {
    width: 100%; }

  .column,
  .columns {
    margin-left: 4%; }

  .column:first-child,
  .columns:first-child {
    margin-left: 0; }

  .one.column,
  .one.columns {
    width: 4.66666666667%; }

  .two.columns {
    width: 13.3333333333%; }

  .three.columns {
    width: 22%; }

  .four.columns {
    width: 30.6666666667%; }

  .five.columns {
    width: 39.3333333333%; }

  .six.columns {
    width: 48%; }

  .seven.columns {
    width: 56.6666666667%; }

  .eight.columns {
    width: 65.3333333333%; }

  .nine.columns {
    width: 74.0%; }

  .ten.columns {
    width: 82.6666666667%; }

  .eleven.columns {
    width: 91.3333333333%; }

  .twelve.columns {
    width: 100%;
    margin-left: 0; }

  .one-third.column {
    width: 30.6666666667%; }

  .two-thirds.column {
    width: 65.3333333333%; } }
/* Customer Overrides */
.footer {
  text-align: center;
  color: #969696;
  padding-top: 10%; }

p.module-desc {
  font-size: 1.1em;
  color: #666666; }

a.link-seesrc {
  color: #aec7d2;
  font-style: italic; }

a.link-seesrc:hover {
  color: #6c9aae; }

#toc-list {
  word-wrap: break-word; }

ul.simple-toc {
  list-style: none; }

ul.simple-toc a.reference-toplevel {
  font-weight: bold;
  color: #0077b3; }

ul.simple-toc-section {
  list-style-type: circle;
  color: #6c9aae; }

ul.simple-toc-section a.reference {
  color: #0077b3; }

cite {
  font-style: italic !important; }

dt > pre {
  border-color: rgba(0, 0, 0, 0.15);
  background-color: transparent;
  margin: 15px 0px 5px; }

dd > pre {
  border-color: rgba(0, 0, 0, 0.1);
  background-color: whitesmoke;
  margin-top: 8px; }

.item > dd {
  margin-left: 10px;
  margin-bottom: 30px; }

/* Nim line-numbered tables */
.line-nums-table {
  width: 100%;
  table-layout: fixed; }

table.line-nums-table {
  border-radius: 4px;
  border: 1px solid #cccccc;
  background-color: whitesmoke;
  border-collapse: separate;
  margin-top: 15px;
  margin-bottom: 25px; }

.line-nums-table tbody {
  border: none; }

.line-nums-table td pre {
  border: none;
  background-color: transparent; }

.line-nums-table td.blob-line-nums {
  width: 28px; }

.line-nums-table td.blob-line-nums pre {
  color: #b0b0b0;
  -webkit-filter: opacity(75%);
  text-align: right;
  border-color: transparent;
  background-color: transparent;
  padding-left: 0px;
  margin-left: 0px;
  padding-right: 0px;
  margin-right: 0px; }

/* Docgen styles */
/* Links */
a {
  color: #0077b3;
  text-decoration: none; }

a:hover,
a:focus {
  color: #00334d;
  text-decoration: underline; }

a:visited {
  color: #00334d; }

a:focus {
  outline: thin dotted #2d2d2d;
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px; }

a:hover,
a:active {
  outline: 0; }

sub,
sup {
  position: relative;
  font-size: 75%;
  line-height: 0;
  vertical-align: baseline; }

sup {
  top: -0.5em; }

sub {
  bottom: -0.25em; }

img {
  width: auto;
  height: auto;
  max-width: 100%;
  vertical-align: middle;
  border: 0;
  -ms-interpolation-mode: bicubic; }

@media print {
  * {
    color: black !important;
    text-shadow: none !important;
    background: transparent !important;
    box-shadow: none !important; }

  a,
  a:visited {
    text-decoration: underline; }

  a[href]:after {
    content: " (" attr(href) ")"; }

  abbr[title]:after {
    content: " (" attr(title) ")"; }

  .ir a:after,
  a[href^="javascript:"]:after,
  a[href^="#"]:after {
    content: ""; }

  pre,
  blockquote {
    border: 1px solid #999;
    page-break-inside: avoid; }

  thead {
    display: table-header-group; }

  tr,
  img {
    page-break-inside: avoid; }

  img {
    max-width: 100% !important; }

  @page {
    margin: 0.5cm; }

  h1 {
    page-break-before: always; }

  h1.title {
    page-break-before: avoid; }

  p,
  h2,
  h3 {
    orphans: 3;
    widows: 3; }

  h2,
  h3 {
    page-break-after: avoid; } }
.img-rounded {
  -webkit-border-radius: 6px;
  -moz-border-radius: 6px;
  border-radius: 6px; }

.img-polaroid {
  padding: 4px;
  background-color: rgba(252, 248, 244, 0.75);
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.2);
  -webkit-box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
  -moz-box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
  box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1); }

p {
  margin: 0 0 12px; }

small {
  font-size: 85%; }

strong {
  font-weight: 600; }

em {
  font-style: italic; }

cite {
  font-style: normal; }

h1,
h2,
h3,
h4,
h5,
h6 {
  font-family: "Helvetica Neue", "HelveticaNeue", "Raleway", Helvetica, Arial, sans-serif;
  font-weight: 600;
  line-height: 20px;
  color: inherit;
  text-rendering: optimizelegibility; }

h1 {
  font-size: 2em;
  padding-bottom: .15em;
  border-bottom: 1px solid #aaaaaa;
  margin-top: 1.0em;
  line-height: 1.2em; }

h1.title {
  padding-bottom: 1em;
  border-bottom: 0px;
  font-size: 2.75em; }

h2 {
  font-size: 1.5em;
  margin-top: 1.5em; }

h3 {
  font-size: 1.3em;
  font-style: italic;
  margin-top: 0.75em; }

h4 {
  font-size: 1.3em;
  margin-top: 0.5em; }

h5 {
  font-size: 1.2em;
  margin-top: 0.25em; }

h6 {
  font-size: 1.1em; }

ul,
ol {
  padding: 0;
  margin: 0 0 0px 15px; }

ul ul,
ul ol,
ol ol,
ol ul {
  margin-bottom: 0; }

li {
  line-height: 20px; }

dl {
  margin-bottom: 20px; }

dt,
dd {
  line-height: 20px; }

dt {
  font-weight: bold; }

dd {
  margin-left: 10px;
  margin-bottom: 26px; }

hr {
  margin: 20px 0;
  border: 0;
  border-top: 1px solid #eeeeee;
  border-bottom: 1px solid #ffffff; }

abbr[title],
abbr[data-original-title] {
  cursor: help;
  border-bottom: 1px dotted #999999; }

abbr.initialism {
  font-size: 90%;
  text-transform: uppercase; }

blockquote {
  padding: 0 0 0 15px;
  margin: 0 0 20px;
  border-left: 5px solid #EFEBE0; }

table.docinfo + blockquote, table.docinfo blockquote, h1 + blockquote {
  border-left: 5px solid #c9c9c9;
}

table.docinfo + blockquote p, table.docinfo blockquote p, h1 + blockquote p {
  margin-bottom: 0;
  font-size: 15px;
  font-weight: 200;
  line-height: 1.5;
  font-style: italic; }

q:before,
q:after,
blockquote:before,
blockquote:after {
  content: ""; }

address {
  display: block;
  margin-bottom: 20px;
  font-style: normal;
  line-height: 20px; }

code,
pre {
  font-family: "Source Code Pro", Monaco, Menlo, Consolas, "Courier New", monospace;
  padding: 0 3px 2px;
  font-weight: 500;
  font-size: 12px;
  color: #444444;
  -webkit-border-radius: 3px;
  -moz-border-radius: 3px;
  border-radius: 3px; }

.pre {
  font-family: "Source Code Pro", Monaco, Menlo, Consolas, "Courier New", monospace;
  font-weight: 600;
  /*color: #504da6;*/
}

code {
  padding: 2px 4px;
  color: #444444;
  white-space: nowrap;
  background-color: white;
  border: 1px solid #777777; }

pre {
  display: inline-block;
  box-sizing: border-box;
  min-width: calc(100% - 19.5px);
  padding: 9.5px;
  margin: 0.25em 10px 0.25em 10px;
  font-size: 14px;
  line-height: 20px;
  white-space: pre !important;
  overflow-y: hidden;
  overflow-x: visible;
  background-color: whitesmoke;
  border: 1px solid #cccccc;
  -webkit-border-radius: 4px;
  -moz-border-radius: 4px;
  border-radius: 4px; }

pre.prettyprint {
  margin-bottom: 20px; }

pre code {
  padding: 0;
  color: inherit;
  white-space: pre;
  overflow-x: visible;
  background-color: transparent;
  border: 0; }

.pre-scrollable {
  max-height: 340px;
  overflow-y: scroll; }

table {
  max-width: 100%;
  background-color: transparent;
  border-collapse: collapse;
  border-spacing: 0; }

table th, table td {
  padding: 0px 8px 0px;
}

.table {
  width: 100%;
  margin-bottom: 20px; }

.table th,
.table td {
  padding: 8px;
  line-height: 20px;
  text-align: left;
  vertical-align: top;
  border-top: 1px solid #444444; }

.table th {
  font-weight: bold; }

.table thead th {
  vertical-align: bottom; }

.table caption + thead tr:first-child th,
.table caption + thead tr:first-child td,
.table colgroup + thead tr:first-child th,
.table colgroup + thead tr:first-child td,
.table thead:first-child tr:first-child th,
.table thead:first-child tr:first-child td {
  border-top: 0; }

.table tbody + tbody {
  border-top: 2px solid #444444; }

.table .table {
  background-color: rgba(252, 248, 244, 0.75); }

.table-condensed th,
.table-condensed td {
  padding: 4px 5px; }

.table-bordered {
  border: 1px solid #444444;
  border-collapse: separate;
  *border-collapse: collapse;
  border-left: 0;
  -webkit-border-radius: 4px;
  -moz-border-radius: 4px;
  border-radius: 4px; }

.table-bordered th,
.table-bordered td {
  border-left: 1px solid #444444; }

.table-bordered caption + thead tr:first-child th,
.table-bordered caption + tbody tr:first-child th,
.table-bordered caption + tbody tr:first-child td,
.table-bordered colgroup + thead tr:first-child th,
.table-bordered colgroup + tbody tr:first-child th,
.table-bordered colgroup + tbody tr:first-child td,
.table-bordered thead:first-child tr:first-child th,
.table-bordered tbody:first-child tr:first-child th,
.table-bordered tbody:first-child tr:first-child td {
  border-top: 0; }

.table-bordered thead:first-child tr:first-child > th:first-child,
.table-bordered tbody:first-child tr:first-child > td:first-child,
.table-bordered tbody:first-child tr:first-child > th:first-child {
  -webkit-border-top-left-radius: 4px;
  border-top-left-radius: 4px;
  -moz-border-radius-topleft: 4px; }

.table-bordered thead:first-child tr:first-child > th:last-child,
.table-bordered tbody:first-child tr:first-child > td:last-child,
.table-bordered tbody:first-child tr:first-child > th:last-child {
  -webkit-border-top-right-radius: 4px;
  border-top-right-radius: 4px;
  -moz-border-radius-topright: 4px; }

.table-bordered thead:last-child tr:last-child > th:first-child,
.table-bordered tbody:last-child tr:last-child > td:first-child,
.table-bordered tbody:last-child tr:last-child > th:first-child,
.table-bordered tfoot:last-child tr:last-child > td:first-child,
.table-bordered tfoot:last-child tr:last-child > th:first-child {
  -webkit-border-bottom-left-radius: 4px;
  border-bottom-left-radius: 4px;
  -moz-border-radius-bottomleft: 4px; }

.table-bordered thead:last-child tr:last-child > th:last-child,
.table-bordered tbody:last-child tr:last-child > td:last-child,
.table-bordered tbody:last-child tr:last-child > th:last-child,
.table-bordered tfoot:last-child tr:last-child > td:last-child,
.table-bordered tfoot:last-child tr:last-child > th:last-child {
  -webkit-border-bottom-right-radius: 4px;
  border-bottom-right-radius: 4px;
  -moz-border-radius-bottomright: 4px; }

.table-bordered tfoot + tbody:last-child tr:last-child td:first-child {
  -webkit-border-bottom-left-radius: 0;
  border-bottom-left-radius: 0;
  -moz-border-radius-bottomleft: 0; }

.table-bordered tfoot + tbody:last-child tr:last-child td:last-child {
  -webkit-border-bottom-right-radius: 0;
  border-bottom-right-radius: 0;
  -moz-border-radius-bottomright: 0; }

.table-bordered caption + thead tr:first-child th:first-child,
.table-bordered caption + tbody tr:first-child td:first-child,
.table-bordered colgroup + thead tr:first-child th:first-child,
.table-bordered colgroup + tbody tr:first-child td:first-child {
  -webkit-border-top-left-radius: 4px;
  border-top-left-radius: 4px;
  -moz-border-radius-topleft: 4px; }

.table-bordered caption + thead tr:first-child th:last-child,
.table-bordered caption + tbody tr:first-child td:last-child,
.table-bordered colgroup + thead tr:first-child th:last-child,
.table-bordered colgroup + tbody tr:first-child td:last-child {
  -webkit-border-top-right-radius: 4px;
  border-top-right-radius: 4px;
  -moz-border-radius-topright: 4px; }

table.docutils th {
  background-color: #e8e8e8; }

table.docutils tr:hover {
  background-color: whitesmoke; }

.table-striped tbody > tr:nth-child(odd) > td,
.table-striped tbody > tr:nth-child(odd) > th {
  background-color: rgba(252, 248, 244, 0.75); }

.table-hover tbody tr:hover > td,
.table-hover tbody tr:hover > th {
  background-color: rgba(241, 222, 204, 0.75); }

table td[class*="span"],
table th[class*="span"],
.row-fluid table td[class*="span"],
.row-fluid table th[class*="span"] {
  display: table-cell;
  float: none;
  margin-left: 0; }

.hero-unit {
  padding: 60px;
  margin-bottom: 30px;
  font-size: 18px;
  font-weight: 200;
  line-height: 30px;
  color: inherit;
  background-color: rgba(230, 197, 164, 0.75);
  -webkit-border-radius: 6px;
  -moz-border-radius: 6px;
  border-radius: 6px; }

.hero-unit h1 {
  margin-bottom: 0;
  font-size: 60px;
  line-height: 1;
  letter-spacing: -1px;
  color: inherit; }

.hero-unit li {
  line-height: 30px; }

/* rst2html default used to remove borders from tables and images */
.borderless, table.borderless td, table.borderless th {
  border: 0; }

table.borderless td, table.borderless th {
  /* Override padding for "table.docutils td" with "! important".
     The right padding separates the table cells. */
  padding: 0 0.5em 0 0 !important; }

.first {
  /* Override more specific margin styles with "! important". */
  margin-top: 0 !important; }

.last, .with-subtitle {
  margin-bottom: 0 !important; }

.hidden {
  display: none; }

a.toc-backref {
  text-decoration: none;
  color: #444444; }

blockquote.epigraph {
  margin: 2em 5em; }

dl.docutils dd {
  margin-bottom: 0.5em; }

object[type="image/svg+xml"], object[type="application/x-shockwave-flash"] {
  overflow: hidden; }

/* Uncomment (and remove this text!) to get bold-faced definition list terms
dl.docutils dt {
  font-weight: bold }
*/
div.abstract {
  margin: 2em 5em; }

div.abstract p.topic-title {
  font-weight: bold;
  text-align: center; }

div.admonition, div.attention, div.caution, div.danger, div.error,
div.hint, div.important, div.note, div.tip, div.warning {
  margin: 2em;
  border: medium outset;
  padding: 1em; }

div.note, div.warning {
  margin: 1.5em 0px;
  border: none; }

div.note p.admonition-title,
div.warning p.admonition-title {
  display: none; }

/* Clearfix
 * http://css-tricks.com/snippets/css/clear-fix/
 */
div.note:after,
div.warning:after {
  content: "";
  display: table;
  clear: both; }

div.note p:before,
div.warning p:before {
  display: block;
  float: left;
  font-size: 4em;
  line-height: 1em;
  margin-right: 20px;
  margin-left: 0em;
  margin-top: -10px;
  content: '\0270D';
  /*handwriting*/ }

div.warning p:before {
  content: '\026A0';
  /*warning*/ }

div.admonition p.admonition-title, div.hint p.admonition-title,
div.important p.admonition-title, div.note p.admonition-title,
div.tip p.admonition-title {
  font-weight: bold;
  font-family: "Helvetica Neue", "HelveticaNeue", "Raleway", Helvetica, Arial, sans-serif; }

div.attention p.admonition-title, div.caution p.admonition-title,
div.danger p.admonition-title, div.error p.admonition-title,
div.warning p.admonition-title, .code .error {
  color: #b30000;
  font-weight: bold;
  font-family: "Helvetica Neue", "HelveticaNeue", "Raleway", Helvetica, Arial, sans-serif; }

/* Uncomment (and remove this text!) to get reduced vertical space in
   compound paragraphs.
div.compound .compound-first, div.compound .compound-middle {
  margin-bottom: 0.5em }

div.compound .compound-last, div.compound .compound-middle {
  margin-top: 0.5em }
*/
div.dedication {
  margin: 2em 5em;
  text-align: center;
  font-style: italic; }

div.dedication p.topic-title {
  font-weight: bold;
  font-style: normal; }

div.figure {
  margin-left: 2em;
  margin-right: 2em; }

div.footer, div.header {
  clear: both;
  font-size: smaller; }

div.line-block {
  display: block;
  margin-top: 1em;
  margin-bottom: 1em; }

div.line-block div.line-block {
  margin-top: 0;
  margin-bottom: 0;
  margin-left: 1.5em; }

div.sidebar {
  margin: 0 0 0.5em 1em;
  border: medium outset;
  padding: 1em;
  background-color: rgba(252, 248, 244, 0.75);
  width: 40%;
  float: right;
  clear: right; }

div.sidebar p.rubric {
  font-family: "Helvetica Neue", "HelveticaNeue", "Raleway", Helvetica, Arial, sans-serif;
  font-size: medium; }

div.system-messages {
  margin: 5em; }

div.system-messages h1 {
  color: #b30000; }

div.system-message {
  border: medium outset;
  padding: 1em; }

div.system-message p.system-message-title {
  color: #b30000;
  font-weight: bold; }

div.topic {
  margin: 2em; }

h1.section-subtitle, h2.section-subtitle, h3.section-subtitle,
h4.section-subtitle, h5.section-subtitle, h6.section-subtitle {
  margin-top: 0.4em; }

h1.title {
  text-align: center; }

h2.subtitle {
  text-align: center; }

hr.docutils {
  width: 75%; }

img.align-left, .figure.align-left, object.align-left {
  clear: left;
  float: left;
  margin-right: 1em; }

img.align-right, .figure.align-right, object.align-right {
  clear: right;
  float: right;
  margin-left: 1em; }

img.align-center, .figure.align-center, object.align-center {
  display: block;
  margin-left: auto;
  margin-right: auto; }

.align-left {
  text-align: left; }

.align-center {
  clear: both;
  text-align: center; }

.align-right {
  text-align: right; }

/* reset inner alignment in figures */
div.align-right {
  text-align: inherit; }

/* div.align-center * { */
/*   text-align: left } */

ul.simple > li {
  margin-bottom: 0.5em }

ol.simple, ul.simple {
  margin-bottom: 1em; }

ol.arabic {
  list-style: decimal; }

ol.loweralpha {
  list-style: lower-alpha; }

ol.upperalpha {
  list-style: upper-alpha; }

ol.lowerroman {
  list-style: lower-roman; }

ol.upperroman {
  list-style: upper-roman; }

p.attribution {
  text-align: right;
  margin-left: 50%; }

p.caption {
  font-style: italic; }

p.credits {
  font-style: italic;
  font-size: smaller; }

p.label {
  white-space: nowrap; }

p.rubric {
  font-weight: bold;
  font-size: larger;
  color: maroon;
  text-align: center; }

p.sidebar-title {
  font-family: "Helvetica Neue", "HelveticaNeue", "Raleway", Helvetica, Arial, sans-serif;
  font-weight: bold;
  font-size: larger; }

p.sidebar-subtitle {
  font-family: "Helvetica Neue", "HelveticaNeue", "Raleway", Helvetica, Arial, sans-serif;
  font-weight: bold; }

p.topic-title {
  font-weight: bold; }

pre.address {
  margin-bottom: 0;
  margin-top: 0;
  font: inherit; }

pre.literal-block, pre.doctest-block, pre.math, pre.code {
  margin-left: 2em;
  margin-right: 2em; }

pre.code .ln {
  color: grey; }

/* line numbers */
pre.code, code {
  background-color: #eeeeee; }

pre.code .comment, code .comment {
  color: #5c6576; }

pre.code .keyword, code .keyword {
  color: #3B0D06;
  font-weight: bold; }

pre.code .literal.string, code .literal.string {
  color: #0c5404; }

pre.code .name.builtin, code .name.builtin {
  color: #352b84; }

pre.code .deleted, code .deleted {
  background-color: #DEB0A1; }

pre.code .inserted, code .inserted {
  background-color: #A3D289; }

span.classifier {
  font-family: "Helvetica Neue", "HelveticaNeue", "Raleway", Helvetica, Arial, sans-serif;
  font-style: oblique; }

span.classifier-delimiter {
  font-family: "Helvetica Neue", "HelveticaNeue", "Raleway", Helvetica, Arial, sans-serif;
  font-weight: bold; }

span.interpreted {
  font-family: "Helvetica Neue", "HelveticaNeue", "Raleway", Helvetica, Arial, sans-serif; }

span.option {
  white-space: nowrap; }

span.pre {
  white-space: pre; }

span.problematic {
  color: #b30000; }

span.section-subtitle {
  /* font-size relative to parent (h1..h6 element) */
  font-size: 80%; }

table.citation {
  border-left: solid 1px #666666;
  margin-left: 1px; }

table.docinfo {
  margin: 0em;
  margin-top: 2em;
  margin-bottom: 2em;
  font-family: "Raleway", "Helvetica Neue", "HelveticaNeue", Helvetica, Arial, sans-serif !important;
  color: #444444; }

table.docutils {
  margin-top: 0.5em;
  margin-bottom: 0.5em; }

table.footnote {
  border-left: solid 1px #2d2d2d;
  margin-left: 1px; }

table.docutils td, table.docutils th,
table.docinfo td, table.docinfo th {
  padding-left: 0.5em;
  padding-right: 0.5em;
  vertical-align: top; }

table.docutils th.field-name, table.docinfo th.docinfo-name {
  font-weight: 700;
  text-align: left;
  white-space: nowrap;
  padding-left: 0; }

h1 tt.docutils, h2 tt.docutils, h3 tt.docutils,
h4 tt.docutils, h5 tt.docutils, h6 tt.docutils {
  font-size: 100%; }

ul.auto-toc {
  list-style-type: none; }

span.DecNumber {
  color: #252dbe; }

span.BinNumber {
  color: #252dbe; }

span.HexNumber {
  color: #252dbe; }

span.OctNumber {
  color: #252dbe; }

span.FloatNumber {
  color: #252dbe; }

span.Identifier {
  color: #3b3b3b; }

span.Keyword {
  font-weight: 600;
  color: #5e8f60; }

span.StringLit {
  color: #a4255b; }

span.LongStringLit {
  color: #a4255b; }

span.CharLit {
  color: #a4255b; }

span.EscapeSequence {
  color: black; }

span.Operator {
  color: black; }

span.Punctuation {
  color: black; }

span.Comment, span.LongComment {
  font-style: italic;
  font-weight: 400;
  color: #484a86; }

span.RegularExpression {
  color: darkviolet; }

span.TagStart {
  color: darkviolet; }

span.TagEnd {
  color: darkviolet; }

span.Key {
  color: #252dbe; }

span.Value {
  color: #252dbe; }

span.RawData {
  color: #a4255b; }

span.Assembler {
  color: #252dbe; }

span.Preprocessor {
  color: #252dbe; }

span.Directive {
  color: #252dbe; }

span.Command, span.Rule, span.Hyperlink, span.Label, span.Reference,
span.Other {
  color: black; }

/* Pop type, const, proc, and iterator defs in nim def blocks */
dt pre > span.Identifier, dt pre > span.Operator {
  color: #155da4;
  font-weight: 700; }

dt pre > span.Identifier ~ span.Identifier, dt pre > span.Operator ~ span.Identifier {
  color: inherit;
  font-weight: inherit; }

dt pre > span.Operator ~ span.Identifier, dt pre > span.Operator ~ span.Operator {
  color: inherit;
  font-weight: inherit; }

/* Nim sprite for the footer (taken from main page favicon) */
.nim-sprite {
  display: inline-block;
  height: 12px;
  width: 12px;
  background-position: 0 0;
  background-size: 12px 12px;
  -webkit-filter: opacity(50%);
  background-repeat: no-repeat;
  background-image: url("data:image/x-icon;base64,AAABAAEAEBAAAAEAIABoBAAAFgAAACgAAAAQAAAAIAAAAAEAIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AAAAAAUAAAAF////AP///wD///8A////AP///wD///8A////AP///wD///8A////AAAAAAIAAABbAAAAlQAAAKIAAACbAAAAmwAAAKIAAACVAAAAWwAAAAL///8A////AP///wD///8A////AAAAABQAAADAAAAAYwAAAA3///8A////AP///wD///8AAAAADQAAAGMAAADAAAAAFP///wD///8A////AP///wAAAACdAAAAOv///wD///8A////AP///wD///8A////AP///wD///8AAAAAOgAAAJ3///8A////AP///wAAAAAnAAAAcP///wAAAAAoAAAASv///wD///8A////AP///wAAAABKAAAAKP///wAAAABwAAAAJ////wD///8AAAAAgQAAABwAAACIAAAAkAAAAJMAAACtAAAAFQAAABUAAACtAAAAkwAAAJAAAACIAAAAHAAAAIH///8A////AAAAAKQAAACrAAAAaP///wD///8AAAAARQAAANIAAADSAAAARf///wD///8AAAAAaAAAAKsAAACk////AAAAADMAAACcAAAAnQAAABj///8A////AP///wAAAAAYAAAAGP///wD///8A////AAAAABgAAACdAAAAnAAAADMAAAB1AAAAwwAAAP8AAADpAAAAsQAAAE4AAAAb////AP///wAAAAAbAAAATgAAALEAAADpAAAA/wAAAMMAAAB1AAAAtwAAAOkAAAD/AAAA/wAAAP8AAADvAAAA3gAAAN4AAADeAAAA3gAAAO8AAAD/AAAA/wAAAP8AAADpAAAAtwAAAGUAAAA/AAAA3wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAADfAAAAPwAAAGX///8A////AAAAAEgAAADtAAAAvwAAAL0AAADGAAAA7wAAAO8AAADGAAAAvQAAAL8AAADtAAAASP///wD///8A////AP///wD///8AAAAAO////wD///8A////AAAAAIcAAACH////AP///wD///8AAAAAO////wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A//8AAP//AAD4HwAA7/cAAN/7AAD//wAAoYUAAJ55AACf+QAAh+EAAAAAAADAAwAA4AcAAP5/AAD//wAA//8AAA==");
  margin-bottom: -5px; }
  div.pragma {
    display: none;
  }
  span.pragmabegin {
    cursor: pointer;
  }
  span.pragmaend {
    cursor: pointer;
  }

div.search_results {
  background-color: antiquewhite;
  margin: 3em;
  padding: 1em;
  border: 1px solid #4d4d4d;
}
</style>

<script type="text/javascript" src="../dochack.js"></script>

<script type="text/javascript">
function togglepragma(d) {
  if (d.style.display != 'inline')
    d.style.display = 'inline';
  else
    d.style.display = 'none';
}

function main() {
  var elements = document.getElementsByClassName("pragmabegin");
  for (var i = 0; i < elements.length; ++i) {
    var e = elements[i];
    e.onclick = function(event) {
      togglepragma(event.target.nextSibling);
    };
  }
  var elements = document.getElementsByClassName("pragmaend");
  for (var i = 0; i < elements.length; ++i) {
    var e = elements[i];
    e.onclick = function(event) {
      togglepragma(event.target.previousSibling);
    };
  }
}
</script>

</head>
<body onload="main()">
<div class="document" id="documentId">
  <div class="container">
    <h1 class="title">Module arraymancer</h1>
    <div class="row">
  <div class="three columns">
  <div>
    Search: <input type="text" id="searchInput"
      onkeyup="search()" />
  </div>
  <div>
    Group by:
    <select onchange="groupBy(this.value)">
      <option value="section">Section</option>
      <option value="type">Type</option>
    </select>
  </div>
  <ul class="simple simple-toc" id="toc-list">
<li><a class="reference" id="arraymancer-a-n-dimensional-tensor-ndarray-library_toc" href="#arraymancer-a-n-dimensional-tensor-ndarray-library">Arraymancer - A n-dimensional tensor (ndarray) library</a></li>
<ul class="simple"><li><a class="reference" id="arraymancer-a-n-dimensional-tensor-ndarray-library-why-arraymancer_toc" href="#arraymancer-a-n-dimensional-tensor-ndarray-library-why-arraymancer">Why Arraymancer</a></li>
<li><a class="reference" id="arraymancer-a-n-dimensional-tensor-ndarray-library-future-ambitions_toc" href="#arraymancer-a-n-dimensional-tensor-ndarray-library-future-ambitions">Future ambitions</a></li>
<li><a class="reference" id="arraymancer-a-n-dimensional-tensor-ndarray-library-support-types-os-hardware_toc" href="#arraymancer-a-n-dimensional-tensor-ndarray-library-support-types-os-hardware">Support (Types, OS, Hardware)</a></li>
<li><a class="reference" id="arraymancer-a-n-dimensional-tensor-ndarray-library-limitations_toc" href="#arraymancer-a-n-dimensional-tensor-ndarray-library-limitations">Limitations:</a></li>
<li><a class="reference" id="arraymancer-a-n-dimensional-tensor-ndarray-library-installation_toc" href="#arraymancer-a-n-dimensional-tensor-ndarray-library-installation">Installation:</a></li>
<li><a class="reference" id="arraymancer-a-n-dimensional-tensor-ndarray-library-features_toc" href="#arraymancer-a-n-dimensional-tensor-ndarray-library-features">Features</a></li>
<ul class="simple"><li><a class="reference" id="features-speed_toc" href="#features-speed">Speed</a></li>
<li><a class="reference" id="features-safe-vs-unsafe-copy-vs-view_toc" href="#features-safe-vs-unsafe-copy-vs-view">Safe vs unsafe: copy vs view</a></li>
<li><a class="reference" id="features-tensors-on-cpu-and-on-cuda_toc" href="#features-tensors-on-cpu-and-on-cuda">Tensors on CPU and on Cuda</a></li>
<li><a class="reference" id="features-tensor-properties_toc" href="#features-tensor-properties">Tensor properties</a></li>
<li><a class="reference" id="features-tensor-creation_toc" href="#features-tensor-creation">Tensor creation</a></li>
<li><a class="reference" id="features-accessing-and-modifying-a-value_toc" href="#features-accessing-and-modifying-a-value">Accessing and modifying a value</a></li>
<li><a class="reference" id="features-copying_toc" href="#features-copying">Copying</a></li>
<li><a class="reference" id="features-slicing_toc" href="#features-slicing">Slicing</a></li>
<li><a class="reference" id="features-slice-mutations_toc" href="#features-slice-mutations">Slice mutations</a></li>
<li><a class="reference" id="features-shapeshifting_toc" href="#features-shapeshifting">Shapeshifting</a></li>
<ul class="simple"><li><a class="reference" id="shapeshifting-transposing_toc" href="#shapeshifting-transposing">Transposing</a></li>
<li><a class="reference" id="shapeshifting-reshaping_toc" href="#shapeshifting-reshaping">Reshaping</a></li>
<li><a class="reference" id="shapeshifting-permuting-reordering-dimension_toc" href="#shapeshifting-permuting-reordering-dimension">Permuting - Reordering dimension</a></li>
<li><a class="reference" id="shapeshifting-concatenation_toc" href="#shapeshifting-concatenation">Concatenation</a></li>
</ul><li><a class="reference" id="features-universal-functions_toc" href="#features-universal-functions">Universal functions</a></li>
<li><a class="reference" id="features-type-conversion_toc" href="#features-type-conversion">Type conversion</a></li>
<li><a class="reference" id="features-matrix-and-vector-operations_toc" href="#features-matrix-and-vector-operations">Matrix and vector operations</a></li>
<li><a class="reference" id="features-broadcasting_toc" href="#features-broadcasting">Broadcasting</a></li>
<li><a class="reference" id="features-iterators_toc" href="#features-iterators">Iterators</a></li>
<li><a class="reference" id="features-higher-order-functions-map-reduce-fold_toc" href="#features-higher-order-functions-map-reduce-fold">Higher-order functions (Map, Reduce, Fold)</a></li>
<ul class="simple"><li><a class="reference" id="higher-order-functions-map-reduce-fold-map-apply-map2-apply2_toc" href="#higher-order-functions-map-reduce-fold-map-apply-map2-apply2"><tt class="docutils literal"><span class="pre">map</span></tt>, <tt class="docutils literal"><span class="pre">apply</span></tt>, <tt class="docutils literal"><span class="pre">map2</span></tt>, <tt class="docutils literal"><span class="pre">apply2</span></tt></a></li>
<li><a class="reference" id="higher-order-functions-map-reduce-fold-reduce-on-the-whole-tensor-or-along-an-axis_toc" href="#higher-order-functions-map-reduce-fold-reduce-on-the-whole-tensor-or-along-an-axis"><tt class="docutils literal"><span class="pre">reduce</span></tt> on the whole Tensor or along an axis</a></li>
<li><a class="reference" id="higher-order-functions-map-reduce-fold-fold-on-the-whole-tensor-or-along-an-axis_toc" href="#higher-order-functions-map-reduce-fold-fold-on-the-whole-tensor-or-along-an-axis"><tt class="docutils literal"><span class="pre">fold</span></tt> on the whole Tensor or along an axis</a></li>
</ul><li><a class="reference" id="features-aggregate-and-statistics_toc" href="#features-aggregate-and-statistics">Aggregate and Statistics</a></li>
</ul></ul><li>
  <a class="reference reference-toplevel" href="#6" id="56">Imports</a>
  <ul class="simple simple-toc-section">
    
  </ul>
</li>
<li>
  <a class="reference reference-toplevel" href="#7" id="57">Types</a>
  <ul class="simple simple-toc-section">
      <li><a class="reference" href="#Backend"
    title="Backend = enum
  Cpu, Cuda"><wbr />Backend<span class="attachedType" style="visibility:hidden"></span></a></li>
  <li><a class="reference" href="#Tensor"
    title="Tensor[T] = object
  shape*: seq[int]
  strides*: seq[int]
  offset*: int
  data*: seq[T]"><wbr />Tensor<span class="attachedType" style="visibility:hidden"></span></a></li>
  <li><a class="reference" href="#CudaSeq"
    title="CudaSeq[T] = object
  len: int
  data: ref [ptr UncheckedArray[T]]"><wbr />Cuda<wbr />Seq<span class="attachedType" style="visibility:hidden"></span></a></li>
  <li><a class="reference" href="#CudaTensor"
    title="CudaTensor[T] = object
  shape*: seq[int]
  strides*: seq[int]
  offset*: int
  data*: CudaSeq[T]"><wbr />Cuda<wbr />Tensor<span class="attachedType" style="visibility:hidden"></span></a></li>
  <li><a class="reference" href="#SteppedSlice"
    title="SteppedSlice = object
  a, b: int
  step: int
  a_from_end: bool
  b_from_end: bool"><wbr />Stepped<wbr />Slice<span class="attachedType" style="visibility:hidden"></span></a></li>
  <li><a class="reference" href="#Step"
    title="Step = object
  b: int
  step: int"><wbr />Step<span class="attachedType" style="visibility:hidden"></span></a></li>

  </ul>
</li>
<li>
  <a class="reference reference-toplevel" href="#10" id="60">Consts</a>
  <ul class="simple simple-toc-section">
      <li><a class="reference" href="#_"
    title="_ = SteppedSlice(b: 1, step: 1, b_from_end: true)"><wbr />`_<wbr />`<span class="attachedType" style="visibility:hidden"></span></a></li>

  </ul>
</li>
<li>
  <a class="reference reference-toplevel" href="#12" id="62">Procs</a>
  <ul class="simple simple-toc-section">
      <li><a class="reference" href="#size,AnyTensor"
    title="size(t: AnyTensor): int"><wbr />size<span class="attachedType" style="visibility:hidden"></span></a></li>
  <li><a class="reference" href="#shape_to_strides,seq[int],OrderType"
    title="shape_to_strides(shape: seq[int]; layout: OrderType = rowMajor): seq[int]"><wbr />shape_<wbr />to_<wbr />strides<span class="attachedType" style="visibility:hidden"></span></a></li>
  <li><a class="reference" href="#is_C_contiguous,AnyTensor"
    title="is_C_contiguous(t: AnyTensor): bool"><wbr />is_<wbr />C_<wbr />contiguous<span class="attachedType" style="visibility:hidden"></span></a></li>
  <li><a class="reference" href="#is_F_contiguous,AnyTensor"
    title="is_F_contiguous(t: AnyTensor): bool"><wbr />is_<wbr />F_<wbr />contiguous<span class="attachedType" style="visibility:hidden"></span></a></li>
  <li><a class="reference" href="#isContiguous,AnyTensor"
    title="isContiguous(t: AnyTensor): bool"><wbr />is<wbr />Contiguous<span class="attachedType" style="visibility:hidden"></span></a></li>
  <li><a class="reference" href="#unsafeView,Tensor[T]"
    title="unsafeView[T](t: Tensor[T]): Tensor[T]"><wbr />unsafe<wbr />View<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#newTensor,openArray[int],typedesc"
    title="newTensor(shape: openArray[int]; T: typedesc): Tensor[T]"><wbr />new<wbr />Tensor<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#toTensor,openArray,int"
    title="toTensor(s: openArray; dummy_bugfix: static[int] = 0): auto"><wbr />to<wbr />Tensor<span class="attachedType" style="visibility:hidden"></span></a></li>
  <li><a class="reference" href="#toTensor,string"
    title="toTensor(s: string): auto"><wbr />to<wbr />Tensor<span class="attachedType" style="visibility:hidden"></span></a></li>
  <li><a class="reference" href="#zeros,openArray[int],typedesc[T]"
    title="zeros[T: SomeNumber](shape: openArray[int]; typ: typedesc[T]): Tensor[T]"><wbr />zeros<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#zeros_like,Tensor[T: SomeNumber]"
    title="zeros_like[T: SomeNumber](t: Tensor[T]): Tensor[T]"><wbr />zeros_<wbr />like<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#ones,openArray[int],typedesc[T]"
    title="ones[T: SomeNumber](shape: openArray[int]; typ: typedesc[T]): Tensor[T]"><wbr />ones<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#ones_like,AnyTensor[T: SomeNumber]"
    title="ones_like[T: SomeNumber](t: AnyTensor[T]): auto"><wbr />ones_<wbr />like<span class="attachedType" style="visibility:hidden"></span></a></li>
  <li><a class="reference" href="#randomTensor,openArray[int],float"
    title="randomTensor(shape: openArray[int]; max: float): Tensor[float]"><wbr />random<wbr />Tensor<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#randomTensor,openArray[int],int"
    title="randomTensor(shape: openArray[int]; max: int): Tensor[int]"><wbr />random<wbr />Tensor<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#randomTensor,openArray[int],Slice[T]"
    title="randomTensor[T](shape: openArray[int]; slice: Slice[T]): Tensor[T]"><wbr />random<wbr />Tensor<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#newTensor,openArray[int],typedesc,"
    title="newTensor(shape: openArray[int]; T: typedesc; backend: static[Backend]): auto"><wbr />new<wbr />Tensor<span class="attachedType" style="visibility:hidden">Backend</span></a></li>
  <li><a class="reference" href="#toTensor,openArray,"
    title="toTensor(s: openArray; backend: static[Backend]): auto"><wbr />to<wbr />Tensor<span class="attachedType" style="visibility:hidden">Backend</span></a></li>
  <li><a class="reference" href="#toTensor,string,"
    title="toTensor(s: string; backend: static[Backend]): auto"><wbr />to<wbr />Tensor<span class="attachedType" style="visibility:hidden">Backend</span></a></li>
  <li><a class="reference" href="#zeros,openArray[int],typedesc[T],"
    title="zeros[T: SomeNumber](shape: openArray[int]; typ: typedesc[T];
                    backend: static[Backend]): auto"><wbr />zeros<span class="attachedType" style="visibility:hidden">Backend</span></a></li>
  <li><a class="reference" href="#ones,openArray[int],typedesc[T],"
    title="ones[T: SomeNumber](shape: openArray[int]; typ: typedesc[T]; backend: static[Backend]): auto"><wbr />ones<span class="attachedType" style="visibility:hidden">Backend</span></a></li>
  <li><a class="reference" href="#randomTensor,openArray[int],float,"
    title="randomTensor(shape: openArray[int]; max: float; backend: static[Backend]): auto"><wbr />random<wbr />Tensor<span class="attachedType" style="visibility:hidden">Backend</span></a></li>
  <li><a class="reference" href="#randomTensor,openArray[int],int,"
    title="randomTensor(shape: openArray[int]; max: int; backend: static[Backend]): auto"><wbr />random<wbr />Tensor<span class="attachedType" style="visibility:hidden">Backend</span></a></li>
  <li><a class="reference" href="#randomTensor,openArray[int],Slice[T],"
    title="randomTensor[T](shape: openArray[int]; slice: Slice[T]; B: static[Backend]): auto"><wbr />random<wbr />Tensor<span class="attachedType" style="visibility:hidden">Backend</span></a></li>
  <li><a class="reference" href="#values,Tensor[T]"
    title="values[T](t: Tensor[T]): auto"><wbr />values<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#axis,Tensor[T],int"
    title="axis[T](t: Tensor[T]; axis: int): auto"><wbr />axis<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#|,Slice[int],int"
    title="`|`(s: Slice[int]; step: int): SteppedSlice"><wbr />`|`<span class="attachedType" style="visibility:hidden">SteppedSlice</span></a></li>
  <li><a class="reference" href="#|,int,int"
    title="`|`(b, step: int): Step"><wbr />`|`<span class="attachedType" style="visibility:hidden">Step</span></a></li>
  <li><a class="reference" href="#|,SteppedSlice,int"
    title="`|`(ss: SteppedSlice; step: int): SteppedSlice"><wbr />`|`<span class="attachedType" style="visibility:hidden">SteppedSlice</span></a></li>
  <li><a class="reference" href="#|+,Slice[int],int"
    title="`|+`(s: Slice[int]; step: int): SteppedSlice"><wbr />`|+`<span class="attachedType" style="visibility:hidden">SteppedSlice</span></a></li>
  <li><a class="reference" href="#|+,int,int"
    title="`|+`(b, step: int): Step"><wbr />`|+`<span class="attachedType" style="visibility:hidden">Step</span></a></li>
  <li><a class="reference" href="#|+,SteppedSlice,int"
    title="`|+`(ss: SteppedSlice; step: int): SteppedSlice"><wbr />`|+`<span class="attachedType" style="visibility:hidden">SteppedSlice</span></a></li>
  <li><a class="reference" href="#|-,Slice[int],int"
    title="`|-`(s: Slice[int]; step: int): SteppedSlice"><wbr />`|-`<span class="attachedType" style="visibility:hidden">SteppedSlice</span></a></li>
  <li><a class="reference" href="#|-,int,int"
    title="`|-`(b, step: int): Step"><wbr />`|-`<span class="attachedType" style="visibility:hidden">Step</span></a></li>
  <li><a class="reference" href="#|-,SteppedSlice,int"
    title="`|-`(ss: SteppedSlice; step: int): SteppedSlice"><wbr />`|-`<span class="attachedType" style="visibility:hidden">SteppedSlice</span></a></li>
  <li><a class="reference" href="#..,int,Step"
    title="`..`(a: int; s: Step): SteppedSlice"><wbr />`..`<span class="attachedType" style="visibility:hidden">SteppedSlice</span></a></li>
  <li><a class="reference" href="#..<,int,Step"
    title="`..&lt;`(a: int; s: Step): SteppedSlice"><wbr />`..&lt;`<span class="attachedType" style="visibility:hidden">SteppedSlice</span></a></li>
  <li><a class="reference" href="#..^,int,Step"
    title="`..^`(a: int; s: Step): SteppedSlice"><wbr />`..^`<span class="attachedType" style="visibility:hidden">SteppedSlice</span></a></li>
  <li><a class="reference" href="#^,SteppedSlice"
    title="`^`(s: SteppedSlice): SteppedSlice"><wbr />`^`<span class="attachedType" style="visibility:hidden">SteppedSlice</span></a></li>
  <li><a class="reference" href="#^,Slice"
    title="`^`(s: Slice): SteppedSlice"><wbr />`^`<span class="attachedType" style="visibility:hidden">SteppedSlice</span></a></li>
  <li><a class="reference" href="#==,Tensor[T],Tensor[T]"
    title="`==`[T](a, b: Tensor[T]): bool"><wbr />`==`<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#transpose,Tensor"
    title="transpose(t: Tensor): Tensor"><wbr />transpose<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#unsafeTranspose,Tensor"
    title="unsafeTranspose(t: Tensor): Tensor"><wbr />unsafe<wbr />Transpose<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#asContiguous,Tensor[T],OrderType,bool"
    title="asContiguous[T](t: Tensor[T]; layout: OrderType = rowMajor; force: bool = false): Tensor[T]"><wbr />as<wbr />Contiguous<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#unsafeContiguous,Tensor[T],OrderType,bool"
    title="unsafeContiguous[T](t: Tensor[T]; layout: OrderType = rowMajor; force: bool = false): Tensor[
    T]"><wbr />unsafe<wbr />Contiguous<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#reshape,Tensor,varargs[int]"
    title="reshape(t: Tensor; new_shape: varargs[int]): Tensor"><wbr />reshape<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#unsafeReshape,Tensor,varargs[int]"
    title="unsafeReshape(t: Tensor; new_shape: varargs[int]): Tensor"><wbr />unsafe<wbr />Reshape<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#broadcast,Tensor[T],openArray[int]"
    title="broadcast[T](t: Tensor[T]; shape: openArray[int]): Tensor[T]"><wbr />broadcast<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#unsafeBroadcast,Tensor[T],openArray[int]"
    title="unsafeBroadcast[T](t: Tensor[T]; shape: openArray[int]): Tensor[T]"><wbr />unsafe<wbr />Broadcast<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#broadcast,T,openArray[int]"
    title="broadcast[T: SomeNumber](val: T; shape: openArray[int]): Tensor[T]"><wbr />broadcast<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#permute,Tensor,varargs[int]"
    title="permute(t: Tensor; dims: varargs[int]): Tensor"><wbr />permute<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#concat,varargs[Tensor[T]],int"
    title="concat[T](t_list: varargs[Tensor[T]]; axis: int): Tensor[T]"><wbr />concat<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#squeeze,AnyTensor"
    title="squeeze(t: AnyTensor): AnyTensor"><wbr />squeeze<span class="attachedType" style="visibility:hidden"></span></a></li>
  <li><a class="reference" href="#unsafeSqueeze,Tensor"
    title="unsafeSqueeze(t: Tensor): Tensor"><wbr />unsafe<wbr />Squeeze<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#squeeze,AnyTensor,int"
    title="squeeze(t: AnyTensor; axis: int): AnyTensor"><wbr />squeeze<span class="attachedType" style="visibility:hidden"></span></a></li>
  <li><a class="reference" href="#unsafeSqueeze,Tensor,int"
    title="unsafeSqueeze(t: Tensor; axis: int): Tensor"><wbr />unsafe<wbr />Squeeze<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#$,Tensor[T]"
    title="`$`[T](t: Tensor[T]): string"><wbr />`$`<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#map,Tensor[T],"
    title="map[T, U](t: Tensor[T]; f: T -&gt; U): Tensor[U]"><wbr />map<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#apply,Tensor[T],"
    title="apply[T](t: var Tensor[T]; f: T -&gt; T)"><wbr />apply<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#apply,Tensor[T],proc(T)"
    title="apply[T](t: var Tensor[T]; f: proc (x: var T))"><wbr />apply<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#map2,Tensor[T],,Tensor[U]"
    title="map2[T, U, V](t1: Tensor[T]; f: (T, U) -&gt; V; t2: Tensor[U]): Tensor[V]"><wbr />map2<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#apply2,Tensor[T],proc(T,T),Tensor[U]"
    title="apply2[T, U](a: var Tensor[T]; f: proc (x: var T; y: T); b: Tensor[U])"><wbr />apply2<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#fold,Tensor[U],T,"
    title="fold[U, T](t: Tensor[U]; start_val: T; f: (T, U) -&gt; T): T"><wbr />fold<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#fold,Tensor[U],Tensor[T],,int"
    title="fold[U, T](t: Tensor[U]; start_val: Tensor[T];
          f: (Tensor[T], Tensor[U]) -&gt; Tensor[T]; axis: int): Tensor[T]"><wbr />fold<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#reduce,Tensor[T],"
    title="reduce[T](t: Tensor[T]; f: (T, T) -&gt; T): T"><wbr />reduce<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#reduce,Tensor[T],,int"
    title="reduce[T](t: Tensor[T]; f: (Tensor[T], Tensor[T]) -&gt; Tensor[T]; axis: int): Tensor[T]"><wbr />reduce<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#fmap,Tensor[T],"
    title="fmap[T, U](t: Tensor[T]; f: T -&gt; U): Tensor[U]"><wbr />fmap<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#fmap2,Tensor[T],Tensor[U],"
    title="fmap2[T, U, V](t1: Tensor[T]; t2: Tensor[U]; f: (T, U) -&gt; V): Tensor[V]"><wbr />fmap2<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#agg,Tensor[T: SomeNumber],,T"
    title="agg[T: SomeNumber](t: Tensor[T]; f: (T, T) -&gt; T; start_val: T): T"><wbr />agg<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#agg_inplace,T,proc(T,T),Tensor[T: SomeNumber]"
    title="agg_inplace[T: SomeNumber](accum_val: var T; f: proc (x: var T; y: T); t: Tensor[T])"><wbr />agg_<wbr />inplace<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#agg,Tensor[T: SomeNumber],,Tensor[T: SomeNumber],int"
    title="agg[T: SomeNumber](t: Tensor[T]; f: (Tensor[T], Tensor[T]) -&gt; Tensor[T];
                  start_val: Tensor[T]; axis: int): Tensor[T]"><wbr />agg<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#agg_inplace,Tensor[T: SomeNumber],proc(Tensor[T: SomeNumber],Tensor[T: SomeNumber]),Tensor[T: SomeNumber],int"
    title="agg_inplace[T: SomeNumber](accum_val: var Tensor[T];
                          f: proc (x: var Tensor[T]; y: Tensor[T]); t: Tensor[T];
                          axis: int)"><wbr />agg_<wbr />inplace<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#astype,Tensor[T],typedesc[U]"
    title="astype[T, U](t: Tensor[T]; typ: typedesc[U]): Tensor[U]"><wbr />astype<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#fac,Tensor"
    title="fac(t150703: Tensor): Tensor"><wbr />fac<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#sqrt,Tensor"
    title="sqrt(t150745: Tensor): Tensor"><wbr />sqrt<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#cbrt,Tensor"
    title="cbrt(t150787: Tensor): Tensor"><wbr />cbrt<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#ln,Tensor"
    title="ln(t150829: Tensor): Tensor"><wbr />ln<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#log10,Tensor"
    title="log10(t150871: Tensor): Tensor"><wbr />log10<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#log2,Tensor"
    title="log2(t150913: Tensor): Tensor"><wbr />log2<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#exp,Tensor"
    title="exp(t150955: Tensor): Tensor"><wbr />exp<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#arccos,Tensor"
    title="arccos(t150997: Tensor): Tensor"><wbr />arccos<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#arcsin,Tensor"
    title="arcsin(t151039: Tensor): Tensor"><wbr />arcsin<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#arctan,Tensor"
    title="arctan(t151081: Tensor): Tensor"><wbr />arctan<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#cos,Tensor"
    title="cos(t151123: Tensor): Tensor"><wbr />cos<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#cosh,Tensor"
    title="cosh(t151165: Tensor): Tensor"><wbr />cosh<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#sinh,Tensor"
    title="sinh(t151207: Tensor): Tensor"><wbr />sinh<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#sin,Tensor"
    title="sin(t151249: Tensor): Tensor"><wbr />sin<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#tan,Tensor"
    title="tan(t151291: Tensor): Tensor"><wbr />tan<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#tanh,Tensor"
    title="tanh(t151333: Tensor): Tensor"><wbr />tanh<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#erf,Tensor"
    title="erf(t151375: Tensor): Tensor"><wbr />erf<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#erfc,Tensor"
    title="erfc(t151417: Tensor): Tensor"><wbr />erfc<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#lgamma,Tensor"
    title="lgamma(t151459: Tensor): Tensor"><wbr />lgamma<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#tgamma,Tensor"
    title="tgamma(t151501: Tensor): Tensor"><wbr />tgamma<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#floor,Tensor"
    title="floor(t151543: Tensor): Tensor"><wbr />floor<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#ceil,Tensor"
    title="ceil(t151585: Tensor): Tensor"><wbr />ceil<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#trunc,Tensor"
    title="trunc(t151627: Tensor): Tensor"><wbr />trunc<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#round,Tensor"
    title="round(t151669: Tensor): Tensor"><wbr />round<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#degToRad,Tensor"
    title="degToRad(t151711: Tensor): Tensor"><wbr />deg<wbr />To<wbr />Rad<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#radToDeg,Tensor"
    title="radToDeg(t151753: Tensor): Tensor"><wbr />rad<wbr />To<wbr />Deg<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#dot,Tensor[T: SomeReal],Tensor[T: SomeReal]"
    title="dot[T: SomeReal](a, b: Tensor[T]): T"><wbr />dot<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#dot,Tensor[T: SomeInteger],Tensor[T: SomeInteger]"
    title="dot[T: SomeInteger](a, b: Tensor[T]): T"><wbr />dot<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#+,Tensor[T: SomeNumber],Tensor[T: SomeNumber]"
    title="`+`[T: SomeNumber](a, b: Tensor[T]): Tensor[T]"><wbr />`+`<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#+=,Tensor[T: SomeNumber],Tensor[T: SomeNumber]"
    title="`+=`[T: SomeNumber](a: var Tensor[T]; b: Tensor[T])"><wbr />`+=`<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#-,Tensor[T: SomeNumber]"
    title="`-`[T: SomeNumber](t: Tensor[T]): Tensor[T]"><wbr />`-`<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#-,Tensor[T: SomeNumber],Tensor[T: SomeNumber]"
    title="`-`[T: SomeNumber](a, b: Tensor[T]): Tensor[T]"><wbr />`-`<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#-=,Tensor[T: SomeNumber],Tensor[T: SomeNumber]"
    title="`-=`[T: SomeNumber](a: var Tensor[T]; b: Tensor[T])"><wbr />`-=`<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#*,T,Tensor[T: SomeNumber]"
    title="`*`[T: SomeNumber](a: T; t: Tensor[T]): Tensor[T]"><wbr />`*`<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#*,Tensor[T: SomeNumber],T"
    title="`*`[T: SomeNumber](t: Tensor[T]; a: T): Tensor[T]"><wbr />`*`<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#*=,Tensor[T: SomeNumber],T"
    title="`*=`[T: SomeNumber](t: var Tensor[T]; a: T)"><wbr />`*=`<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#/,Tensor[T: SomeReal],T"
    title="`&#x2F;`[T: SomeReal](t: Tensor[T]; a: T): Tensor[T]"><wbr />`/`<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#div,Tensor[T: SomeInteger],T"
    title="`div`[T: SomeInteger](t: Tensor[T]; a: T): Tensor[T]"><wbr />`div`<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#/=,Tensor[T: SomeReal],T"
    title="`&#x2F;=`[T: SomeReal](t: var Tensor[T]; a: T)"><wbr />`/=`<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#/=,Tensor[T: SomeInteger],T"
    title="`&#x2F;=`[T: SomeInteger](t: var Tensor[T]; a: T)"><wbr />`/=`<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#*,Tensor[T: SomeReal],Tensor[T: SomeReal]"
    title="`*`[T: SomeReal](a, b: Tensor[T]): Tensor[T]"><wbr />`*`<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#*,Tensor[T: SomeInteger],Tensor[T: SomeInteger]"
    title="`*`[T: SomeInteger](a, b: Tensor[T]): Tensor[T]"><wbr />`*`<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#.+,Tensor[T: SomeNumber],Tensor[T: SomeNumber]"
    title="`.+`[T: SomeNumber](a, b: Tensor[T]): Tensor[T]"><wbr />`.+`<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#.-,Tensor[T: SomeNumber],Tensor[T: SomeNumber]"
    title="`.-`[T: SomeNumber](a, b: Tensor[T]): Tensor[T]"><wbr />`.-`<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#.*,Tensor[T: SomeNumber],Tensor[T: SomeNumber]"
    title="`.*`[T: SomeNumber](a, b: Tensor[T]): Tensor[T]"><wbr />`.*`<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#./,Tensor[T: SomeInteger],Tensor[T: SomeInteger]"
    title="`.&#x2F;`[T: SomeInteger](a, b: Tensor[T]): Tensor[T]"><wbr />`./`<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#./,Tensor[T: SomeReal],Tensor[T: SomeReal]"
    title="`.&#x2F;`[T: SomeReal](a, b: Tensor[T]): Tensor[T]"><wbr />`./`<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#.+=,Tensor[T: SomeNumber],Tensor[T: SomeNumber]"
    title="`.+=`[T: SomeNumber](a: var Tensor[T]; b: Tensor[T])"><wbr />`.+=`<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#.-=,Tensor[T: SomeNumber],Tensor[T: SomeNumber]"
    title="`.-=`[T: SomeNumber](a: var Tensor[T]; b: Tensor[T])"><wbr />`.-=`<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#.*=,Tensor[T: SomeNumber],Tensor[T: SomeNumber]"
    title="`.*=`[T: SomeNumber](a: var Tensor[T]; b: Tensor[T])"><wbr />`.*=`<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#./=,Tensor[T: SomeInteger],Tensor[T: SomeInteger]"
    title="`.&#x2F;=`[T: SomeInteger](a: var Tensor[T]; b: Tensor[T])"><wbr />`./=`<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#./=,Tensor[T: SomeReal],Tensor[T: SomeReal]"
    title="`.&#x2F;=`[T: SomeReal](a: var Tensor[T]; b: Tensor[T])"><wbr />`./=`<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#.+,T,Tensor[T: SomeNumber]"
    title="`.+`[T: SomeNumber](val: T; t: Tensor[T]): Tensor[T]"><wbr />`.+`<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#.+,Tensor[T: SomeNumber],T"
    title="`.+`[T: SomeNumber](t: Tensor[T]; val: T): Tensor[T]"><wbr />`.+`<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#.-,T,Tensor[T: SomeNumber]"
    title="`.-`[T: SomeNumber](val: T; t: Tensor[T]): Tensor[T]"><wbr />`.-`<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#.-,Tensor[T: SomeNumber],T"
    title="`.-`[T: SomeNumber](t: Tensor[T]; val: T): Tensor[T]"><wbr />`.-`<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#./,T,Tensor[T: SomeInteger]"
    title="`.&#x2F;`[T: SomeInteger](val: T; t: Tensor[T]): Tensor[T]"><wbr />`./`<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#./,T,Tensor[T: SomeReal]"
    title="`.&#x2F;`[T: SomeReal](val: T; t: Tensor[T]): Tensor[T]"><wbr />`./`<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#.+=,Tensor[T: SomeNumber],T"
    title="`.+=`[T: SomeNumber](t: var Tensor[T]; val: T)"><wbr />`.+=`<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#.-=,Tensor[T: SomeNumber],T"
    title="`.-=`[T: SomeNumber](t: var Tensor[T]; val: T)"><wbr />`.-=`<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#sum,Tensor[T: SomeNumber]"
    title="sum[T: SomeNumber](t: Tensor[T]): T"><wbr />sum<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#sum,Tensor[T: SomeNumber],int"
    title="sum[T: SomeNumber](t: Tensor[T]; axis: int): Tensor[T]"><wbr />sum<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#mean,Tensor[T: SomeReal]"
    title="mean[T: SomeReal](t: Tensor[T]): T"><wbr />mean<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#mean,Tensor[T: SomeReal],int"
    title="mean[T: SomeReal](t: Tensor[T]; axis: int): Tensor[T]"><wbr />mean<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#toRawSeq,Tensor[T]"
    title="toRawSeq[T](t: Tensor[T]): seq[T]"><wbr />to<wbr />Raw<wbr />Seq<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#export_tensor,Tensor[T]"
    title="export_tensor[T](t: Tensor[T]): tuple[shape: seq[int], strides: seq[int], data: seq[T]]"><wbr />export_<wbr />tensor<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#layoutOnDevice,CudaTensor[T: SomeReal]"
    title="layoutOnDevice[T: SomeReal](t: CudaTensor[T]): CudaTensorLayout[T]"><wbr />layout<wbr />On<wbr />Device<span class="attachedType" style="visibility:hidden">CudaTensor</span></a></li>
  <li><a class="reference" href="#unsafeView,CudaTensor[T]"
    title="unsafeView[T](t: CudaTensor[T]): CudaTensor[T]"><wbr />unsafe<wbr />View<span class="attachedType" style="visibility:hidden">CudaTensor</span></a></li>
  <li><a class="reference" href="#clone,CudaTensor[T]"
    title="clone[T](t: CudaTensor[T]): CudaTensor[T]"><wbr />clone<span class="attachedType" style="visibility:hidden">CudaTensor</span></a></li>
  <li><a class="reference" href="#cuda,Tensor[T: SomeReal]"
    title="cuda[T: SomeReal](t: Tensor[T]): CudaTensor[T]"><wbr />cuda<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#cpu,CudaTensor[T: SomeReal]"
    title="cpu[T: SomeReal](t: CudaTensor[T]): Tensor[T]"><wbr />cpu<span class="attachedType" style="visibility:hidden">CudaTensor</span></a></li>
  <li><a class="reference" href="#$,CudaTensor[T]"
    title="`$`[T](t: CudaTensor[T]): string"><wbr />`$`<span class="attachedType" style="visibility:hidden">CudaTensor</span></a></li>
  <li><a class="reference" href="#dot,CudaTensor[T: SomeReal],CudaTensor[T: SomeReal]"
    title="dot[T: SomeReal](a, b: CudaTensor[T]): T"><wbr />dot<span class="attachedType" style="visibility:hidden">CudaTensor</span></a></li>
  <li><a class="reference" href="#+=,CudaTensor[T: SomeReal],CudaTensor[T: SomeReal]"
    title="`+=`[T: SomeReal](a: var CudaTensor[T]; b: CudaTensor[T])"><wbr />`+=`<span class="attachedType" style="visibility:hidden">CudaTensor</span></a></li>
  <li><a class="reference" href="#+,CudaTensor[T: SomeReal],CudaTensor[T: SomeReal]"
    title="`+`[T: SomeReal](a, b: CudaTensor[T]): CudaTensor[T]"><wbr />`+`<span class="attachedType" style="visibility:hidden">CudaTensor</span></a></li>
  <li><a class="reference" href="#-=,CudaTensor[T: SomeReal],CudaTensor[T: SomeReal]"
    title="`-=`[T: SomeReal](a: var CudaTensor[T]; b: CudaTensor[T])"><wbr />`-=`<span class="attachedType" style="visibility:hidden">CudaTensor</span></a></li>
  <li><a class="reference" href="#-,CudaTensor[T: SomeReal],CudaTensor[T: SomeReal]"
    title="`-`[T: SomeReal](a, b: CudaTensor[T]): CudaTensor[T]"><wbr />`-`<span class="attachedType" style="visibility:hidden">CudaTensor</span></a></li>
  <li><a class="reference" href="#*=,CudaTensor[T: SomeReal],T"
    title="`*=`[T: SomeReal](t: var CudaTensor[T]; a: T)"><wbr />`*=`<span class="attachedType" style="visibility:hidden">CudaTensor</span></a></li>
  <li><a class="reference" href="#*,T,CudaTensor[T: SomeReal]"
    title="`*`[T: SomeReal](a: T; t: CudaTensor[T]): CudaTensor[T]"><wbr />`*`<span class="attachedType" style="visibility:hidden">CudaTensor</span></a></li>
  <li><a class="reference" href="#*,CudaTensor[T: SomeReal],T"
    title="`*`[T: SomeReal](t: CudaTensor[T]; a: T): CudaTensor[T]"><wbr />`*`<span class="attachedType" style="visibility:hidden">CudaTensor</span></a></li>
  <li><a class="reference" href="#/=,CudaTensor[T: SomeReal],T"
    title="`&#x2F;=`[T: SomeReal](t: var CudaTensor[T]; a: T)"><wbr />`/=`<span class="attachedType" style="visibility:hidden">CudaTensor</span></a></li>
  <li><a class="reference" href="#/,CudaTensor[T: SomeReal],T"
    title="`&#x2F;`[T: SomeReal](t: CudaTensor[T]; a: T): CudaTensor[T]"><wbr />`/`<span class="attachedType" style="visibility:hidden">CudaTensor</span></a></li>
  <li><a class="reference" href="#/,T,CudaTensor[T: SomeReal]"
    title="`&#x2F;`[T: SomeReal](a: T; t: CudaTensor[T]): CudaTensor[T]"><wbr />`/`<span class="attachedType" style="visibility:hidden">CudaTensor</span></a></li>
  <li><a class="reference" href="#*,CudaTensor[T: SomeReal],CudaTensor[T: SomeReal]"
    title="`*`[T: SomeReal](a, b: CudaTensor[T]): CudaTensor[T]"><wbr />`*`<span class="attachedType" style="visibility:hidden">CudaTensor</span></a></li>
  <li><a class="reference" href="#transpose,CudaTensor"
    title="transpose(t: CudaTensor): CudaTensor"><wbr />transpose<span class="attachedType" style="visibility:hidden">CudaTensor</span></a></li>
  <li><a class="reference" href="#asContiguous,CudaTensor[T: SomeReal],OrderType,bool"
    title="asContiguous[T: SomeReal](t: CudaTensor[T]; layout: OrderType = colMajor;
                         force: bool = false): CudaTensor[T]"><wbr />as<wbr />Contiguous<span class="attachedType" style="visibility:hidden">CudaTensor</span></a></li>

  </ul>
</li>
<li>
  <a class="reference reference-toplevel" href="#14" id="64">Iterators</a>
  <ul class="simple simple-toc-section">
      <li><a class="reference" href="#items.i,Tensor[T]"
    title="items[T](t: Tensor[T]): T"><wbr />items<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#mitems.i,Tensor[T]"
    title="mitems[T](t: var Tensor[T]): var T"><wbr />mitems<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#pairs.i,Tensor[T]"
    title="pairs[T](t: Tensor[T]): (seq[int], T)"><wbr />pairs<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#axis.i,Tensor[T],int"
    title="axis[T](t: Tensor[T]; axis: int): Tensor[T]"><wbr />axis<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>

  </ul>
</li>
<li>
  <a class="reference reference-toplevel" href="#16" id="66">Macros</a>
  <ul class="simple simple-toc-section">
      <li><a class="reference" href="#[].m,AnyTensor[T],varargs[untyped]"
    title="`[]`[T](t: AnyTensor[T]; args: varargs[untyped]): untyped"><wbr />`[]`<span class="attachedType" style="visibility:hidden"></span></a></li>
  <li><a class="reference" href="#unsafeSlice.m,Tensor[T],varargs[untyped]"
    title="unsafeSlice[T](t: Tensor[T]; args: varargs[untyped]): untyped"><wbr />unsafe<wbr />Slice<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#[]=.m,Tensor[T],varargs[untyped]"
    title="`[]=`[T](t: var Tensor[T]; args: varargs[untyped]): untyped"><wbr />`[]=`<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>

  </ul>
</li>
<li>
  <a class="reference reference-toplevel" href="#17" id="67">Templates</a>
  <ul class="simple simple-toc-section">
      <li><a class="reference" href="#rank.t,AnyTensor"
    title="rank(t: AnyTensor): int"><wbr />rank<span class="attachedType" style="visibility:hidden"></span></a></li>
  <li><a class="reference" href="#get_data_ptr.t,AnyTensor[T]"
    title="get_data_ptr[T](t: AnyTensor[T]): ptr T"><wbr />get_<wbr />data_<wbr />ptr<span class="attachedType" style="visibility:hidden"></span></a></li>
  <li><a class="reference" href="#bc.t,,openArray[int]"
    title="bc(t: (Tensor | SomeNumber); shape: openArray[int]): untyped"><wbr />bc<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#makeUniversal.t,untyped"
    title="makeUniversal(func_name: untyped)"><wbr />make<wbr />Universal<span class="attachedType" style="visibility:hidden"></span></a></li>
  <li><a class="reference" href="#makeUniversalLocal.t,untyped"
    title="makeUniversalLocal(func_name: untyped)"><wbr />make<wbr />Universal<wbr />Local<span class="attachedType" style="visibility:hidden"></span></a></li>
  <li><a class="reference" href="#rewriteToTensorReshape.t,openArray,varargs[int],"
    title="rewriteToTensorReshape{reshape(toTensor(oa, dummy_bugfix), shape)
}(oa: openArray; shape: varargs[int]; dummy_bugfix: static[int]): auto"><wbr />rewrite<wbr />To<wbr />Tensor<wbr />Reshape<span class="attachedType" style="visibility:hidden"></span></a></li>
  <li><a class="reference" href="#at.t,Tensor[T],varargs[untyped]"
    title="at[T](t: Tensor[T]; args: varargs[untyped]): untyped"><wbr />at<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>
  <li><a class="reference" href="#unsafeAt.t,Tensor[T],varargs[untyped]"
    title="unsafeAt[T](t: Tensor[T]; args: varargs[untyped]): untyped"><wbr />unsafe<wbr />At<span class="attachedType" style="visibility:hidden">Tensor</span></a></li>

  </ul>
</li>

</ul>

  </div>
  <div class="nine columns" id="content">
  <div id="tocRoot"></div>
  <p class="module-desc">
<h1><a class="toc-backref" id="arraymancer-a-n-dimensional-tensor-ndarray-library" href="#arraymancer-a-n-dimensional-tensor-ndarray-library">Arraymancer - A n-dimensional tensor (ndarray) library</a></h1><p>Arraymancer is a tensor (N-dimensional array) project. The main focus is providing a fast and ergonomic CPU and GPU ndarray library on which to build a numerical computing and in particular a deep learning ecosystem.</p>
<p>The library is inspired by Numpy and PyTorch.</p>

<h2><a class="toc-backref" id="arraymancer-a-n-dimensional-tensor-ndarray-library-why-arraymancer" href="#arraymancer-a-n-dimensional-tensor-ndarray-library-why-arraymancer">Why Arraymancer</a></h2><p>The deep learning frameworks are currently in two camps:</p>
<ul class="simple"><li>Research: Theano, Tensorflow, Keras, Torch, PyTorch</li>
<li>Production: Caffe, Darknet, (Tensorflow)</li>
</ul>
<p>Putting a research model in production, on a drone or as a webservice for example, is difficult:</p>
<ul class="simple"><li>Managing Python versions and environment is hell</li>
<li>Python data science ecosystem does not run on embedded devices (Nvidia Tegra/drones) or mobile phones</li>
<li>~Transforming a tuned research model (in Python) to a usable Caffe or Darknet model (in C) is almost impossible. PMML is supposed to be the &quot;common&quot; XML description of ML models but is not really supported by anyone.~ <strong>Edit - Sept 7, 2017</strong>: Microsoft and Facebook are announcing <a class="reference external" href="https://research.fb.com/facebook-and-microsoft-introduce-new-open-ecosystem-for-interchangeable-ai-frameworks/">Open Neural Network Exchange</a></li>
<li>Tensorflow is supposed to bridge the gap between research and production but its syntax and ergonomics are a pain to work with.</li>
<li>Deployed models are static, there is no interface to add a new observation/training sample to any framework. The end goal is to use a model as a webservice.</li>
</ul>
<p>All those pain points may seem like a huge undertaking however thanks to the Nim language, we can have Arraymancer:</p>
<ul class="simple"><li>Be as fast as C</li>
<li>Accelerated routines with Intel MKL/OpenBLAS or even NNPACK</li>
<li>Access to CUDA and generate custom CUDA kernels on the fly via metaprogramming.</li>
<li>A Python-like syntax with custom operators <tt class="docutils literal"><span class="pre">a * b</span></tt> for tensor multiplication instead of <tt class="docutils literal"><span class="pre">a.dot(b)</span></tt> (Numpy/Tensorflow) or <tt class="docutils literal"><span class="pre">a.mm(b)</span></tt> (Torch)</li>
<li>Numpy-like slicing ergonomics <tt class="docutils literal"><span class="pre">t[0..4, 2..10|2]</span></tt></li>
</ul>

<h2><a class="toc-backref" id="arraymancer-a-n-dimensional-tensor-ndarray-library-future-ambitions" href="#arraymancer-a-n-dimensional-tensor-ndarray-library-future-ambitions">Future ambitions</a></h2><p>Because apparently to be successful you need a vision, I would like Arraymancer to be:</p>
<ul class="simple"><li>The go-to tool for Deep Learning video processing. I.e. <tt class="docutils literal"><span class="pre">vid = load_video(&quot;./cats/youtube_cat_video.mkv&quot;)</span></tt></li>
<li>Target javascript, WebAssembly, Apple Metal, ARM devices, AMD Rocm, OpenCL, you name it.</li>
<li>Target cryptominers FPGAs because they drove the price of GPUs for honest deep-learners too high.</li>
</ul>

<h2><a class="toc-backref" id="arraymancer-a-n-dimensional-tensor-ndarray-library-support-types-os-hardware" href="#arraymancer-a-n-dimensional-tensor-ndarray-library-support-types-os-hardware">Support (Types, OS, Hardware)</a></h2><p>Arraymancer's tensors supports arbitrary types (floats, strings, objects ...).</p>
<p>Arraymancer run anywhere you can compile C code. Linux, MacOS are supported, Windows should work too as Appveyor (Continuous Integration for Windows) never flash red.<br />Optionally you can compile Arraymancer with Cuda support.<br /></p><p>Note: Arraymancer Tensors and CudaTensors are tensors in the machine learning sense (multidimensional array) not in the mathematical sense (describe transformation laws)</p>

<h2><a class="toc-backref" id="arraymancer-a-n-dimensional-tensor-ndarray-library-limitations" href="#arraymancer-a-n-dimensional-tensor-ndarray-library-limitations">Limitations:</a></h2><p>EXPERIMENTAL: Arraymancer may summon Ragnarok and cause the heat death of the Universe.</p>
<p>Display of 5-dimensional or more tensors is not implemented. (To be honest Christopher Nolan had the same issue in Interstellar)</p>

<h2><a class="toc-backref" id="arraymancer-a-n-dimensional-tensor-ndarray-library-installation" href="#arraymancer-a-n-dimensional-tensor-ndarray-library-installation">Installation:</a></h2><p>Nim is available in some Linux repositories and on Homebrew for macOS.</p>
<p>I however recommend installing Nim in your user profile via <a class="reference external" href="https://github.com/dom96/choosenim">choosenim</a>. Once choosenim installed Nim, you can <tt class="docutils literal"><span class="pre">nimble arraymancer</span></tt> which will pull arraymancer and all its dependencies.</p>

<h2><a class="toc-backref" id="arraymancer-a-n-dimensional-tensor-ndarray-library-features" href="#arraymancer-a-n-dimensional-tensor-ndarray-library-features">Features</a></h2><p>Detailed API is available on Arraymancer official <a class="reference external" href="https://mratsim.github.io/Arraymancer/">documentation</a>.</p>
<p>For now Arraymancer is still at the ndarray stage, however a <a class="reference external" href="https://github.com/edubart/arraymancer-vision">vision package</a> and a <a class="reference external" href="https://github.com/edubart/arraymancer-demos">machine learning demo</a> have started.</p>

<h3><a class="toc-backref" id="features-speed" href="#features-speed">Speed</a></h3><p>On the demo benchmark, Arraymancer already reach speeds with comparable to Torch on logistic regression on OpenBLAS, though further MKL optimizations are possible (batched matmul probably):</p>
<table border="1" class="docutils"><tr><th>Library</th><th>Timing</th></tr>
<tr><td>Torch CUDA</td><td>582 ms</td></tr>
<tr><td>Torch MKL</td><td>1417ms</td></tr>
<tr><td>Torch OpenBLAS</td><td>13044 ms</td></tr>
<tr><td>Numpy MKL</td><td>17906 ms</td></tr>
<tr><td>Arraymancer MKL</td><td>2325 ms</td></tr>
<tr><td>Arraymancer OpenBLAS</td><td>12502 ms</td></tr>
</table><pre>
Intel(R) Core(TM) i7-3770K CPU @ 3.50GHz GeForce GTX 1080 Ti ArchLinux (kernel 4.9.51-1-lts, glibc 2.26) GCC 7.2.0 MKL 2017.17.0.4.4 OpenBLAS 0.2.20 CUDA 8.0.61</pre>
<p>In the future, Arraymancer will leverage Nim compiler to automatically fuse operations<br />like <tt class="docutils literal"><span class="pre">alpha A*B + beta C</span></tt> or a combination of element-wise operations. This is already done to fuse <tt class="docutils literal"><span class="pre">toTensor</span></tt> and <tt class="docutils literal"><span class="pre">reshape</span></tt>.<br /></p>
<h3><a class="toc-backref" id="features-safe-vs-unsafe-copy-vs-view" href="#features-safe-vs-unsafe-copy-vs-view">Safe vs unsafe: copy vs view</a></h3><p>Compared to most frameworks, Arraymancer choose to be safe by default but allows <tt class="docutils literal"><span class="pre">unsafe</span></tt> operations to optimize for speed and memory. The tensor resulting from <tt class="docutils literal"><span class="pre">unsafe</span></tt> operations (no-copy operations) share the underlying storage with the input tensor (also called views or shallow copies). This is often a surprise for beginners.</p>
<p>In the future Arraymancer will leverage Nim compiler to automatically detect when an original is not used and modified anymore to automatically replace it by the <tt class="docutils literal"><span class="pre">unsafe</span></tt> equivalent.</p>
<p>For CudaTensors, operations are unsafe by default (including assignmnt with <tt class="docutils literal"><span class="pre">=</span></tt>) while waiting for further Nim optimizations for manually managed memory. CudaTensors can be copied safely with <tt class="docutils literal"><span class="pre">.clone</span></tt></p>

<h3><a class="toc-backref" id="features-tensors-on-cpu-and-on-cuda" href="#features-tensors-on-cpu-and-on-cuda">Tensors on CPU and on Cuda</a></h3><p>Tensors and CudaTensors do not have the same features implemented yet.<br />Also Cuda Tensors can only be float32 or float64 while Cpu Tensor can be integers, string, boolean or any custom object.<br /></p><p>Here is a comparative table, not that this feature set is developing very rapidly.</p>
<table border="1" class="docutils"><tr><th>Action</th><th>Tensor</th><th>CudaTensor</th></tr>
<tr><td>Accessing tensor properties</td><td>[x]</td><td>[x]</td></tr>
<tr><td>Tensor creation</td><td>[x]</td><td>by converting a cpu Tensor</td></tr>
<tr><td>Accessing or modifying a single value</td><td>[x]</td><td>[]</td></tr>
<tr><td>Iterating on a Tensor</td><td>[x]</td><td>[]</td></tr>
<tr><td>Slicing a Tensor</td><td>[x]</td><td>[x]</td></tr>
<tr><td>Slice mutation <tt class="docutils literal"><span class="pre">a[1,_] = 10</span></tt></td><td>[x]</td><td>[]</td></tr>
<tr><td>Comparison <tt class="docutils literal"><span class="pre">==</span></tt></td><td>[x]</td><td>Coming soon</td></tr>
<tr><td>Element-wise basic operations</td><td>[x]</td><td>[x]</td></tr>
<tr><td>Universal functions</td><td>[x]</td><td>[x]</td></tr>
<tr><td>Automatically broadcasted operations</td><td>[x]</td><td>Coming soon</td></tr>
<tr><td>Matrix-Matrix and Matrix vector multiplication</td><td>[x]</td><td>[x] Note: sliced CudaTensors must explicitly be made contiguous</td></tr>
<tr><td>Displaying a tensor</td><td>[x]</td><td>[x]</td></tr>
<tr><td>Higher-order functions (map, apply, reduce, fold</td><td>)[x]</td><td>Apply, but only for internal use</td></tr>
<tr><td>Transposing</td><td>[x]</td><td>[x]</td></tr>
<tr><td>Converting to contiguous</td><td>[x]</td><td>[x]</td></tr>
<tr><td>Reshaping</td><td>[x]</td><td>[]</td></tr>
<tr><td>Explicit broadcast</td><td>[x]</td><td>Coming soon</td></tr>
<tr><td>Permuting dimensions</td><td>[x]</td><td>Coming soon</td></tr>
<tr><td>Concatenating along existing dimensions</td><td>[x]</td><td>[]</td></tr>
<tr><td>Squeezing singleton dimensions</td><td>[x]</td><td>Coming soon</td></tr>
<tr><td>Slicing + squeezing in one operation</td><td>[x]</td><td>Coming soon</td></tr>
</table>
<h3><a class="toc-backref" id="features-tensor-properties" href="#features-tensor-properties">Tensor properties</a></h3><p>Tensors have the following properties:</p>
<ul class="simple"><li><tt class="docutils literal"><span class="pre">rank</span></tt>:<ul class="simple"><li>0 for scalar (unfortunately cannot be stored)</li>
<li>1 for vector</li>
<li>2 for matrices</li>
<li>N for N-dimension array</li>
</ul>
</li>
<li><tt class="docutils literal"><span class="pre">shape</span></tt>: a sequence of the tensor dimensions along each axis.</li>
</ul>
<p>Next properties are technical and there for completeness</p>
<ul class="simple"><li><tt class="docutils literal"><span class="pre">strides</span></tt>: a sequence of numbers of steps to get the next item along a dimension.</li>
<li><tt class="docutils literal"><span class="pre">offset</span></tt>: the first element of the tensor</li>
</ul>
<pre class="listing"><span class="Keyword">import</span> <span class="Identifier">arraymancer</span>

<span class="Keyword">let</span> <span class="Identifier">d</span> <span class="Operator">=</span> <span class="Punctuation">[</span><span class="Punctuation">[</span><span class="DecNumber">1</span><span class="Punctuation">,</span> <span class="DecNumber">2</span><span class="Punctuation">,</span> <span class="DecNumber">3</span><span class="Punctuation">]</span><span class="Punctuation">,</span> <span class="Punctuation">[</span><span class="DecNumber">4</span><span class="Punctuation">,</span> <span class="DecNumber">5</span><span class="Punctuation">,</span> <span class="DecNumber">6</span><span class="Punctuation">]</span><span class="Punctuation">]</span><span class="Operator">.</span><span class="Identifier">toTensor</span><span class="Punctuation">(</span><span class="Punctuation">)</span>

<span class="Identifier">echo</span> <span class="Identifier">d</span>
<span class="Comment"># Tensor of shape 2x3 of type &quot;int&quot; on backend &quot;Cpu&quot;</span>
<span class="Comment"># |1      2       3|</span>
<span class="Comment"># |4      5       6|</span>

<span class="Identifier">echo</span> <span class="Identifier">d</span><span class="Operator">.</span><span class="Identifier">rank</span> <span class="Comment"># 2</span>
<span class="Identifier">echo</span> <span class="Identifier">d</span><span class="Operator">.</span><span class="Identifier">shape</span> <span class="Comment"># @[2, 3]</span>
<span class="Identifier">echo</span> <span class="Identifier">d</span><span class="Operator">.</span><span class="Identifier">strides</span> <span class="Comment"># @[3, 1] =&gt; Next row is 3 elements away in memory while next column is 1 element away.</span>
<span class="Identifier">echo</span> <span class="Identifier">d</span><span class="Operator">.</span><span class="Identifier">offset</span> <span class="Comment"># 0</span></pre>
<h3><a class="toc-backref" id="features-tensor-creation" href="#features-tensor-creation">Tensor creation</a></h3><p>The canonical way to initialize a tensor is by converting a seq of seq of ... or an array of array of ... into a tensor using <tt class="docutils literal"><span class="pre">toTensor</span></tt>.</p>
<p><tt class="docutils literal"><span class="pre">toTensor</span></tt> supports deep nested sequences and arrays, even sequence of arrays of sequences.</p>
<pre class="listing"><span class="Keyword">import</span> <span class="Identifier">arraymancer</span>

<span class="Keyword">let</span> <span class="Identifier">c</span> <span class="Operator">=</span> <span class="Punctuation">[</span>
          <span class="Punctuation">[</span>
            <span class="Punctuation">[</span><span class="DecNumber">1</span><span class="Punctuation">,</span><span class="DecNumber">2</span><span class="Punctuation">,</span><span class="DecNumber">3</span><span class="Punctuation">]</span><span class="Punctuation">,</span>
            <span class="Punctuation">[</span><span class="DecNumber">4</span><span class="Punctuation">,</span><span class="DecNumber">5</span><span class="Punctuation">,</span><span class="DecNumber">6</span><span class="Punctuation">]</span>
          <span class="Punctuation">]</span><span class="Punctuation">,</span>
          <span class="Punctuation">[</span>
            <span class="Punctuation">[</span><span class="DecNumber">11</span><span class="Punctuation">,</span><span class="DecNumber">22</span><span class="Punctuation">,</span><span class="DecNumber">33</span><span class="Punctuation">]</span><span class="Punctuation">,</span>
            <span class="Punctuation">[</span><span class="DecNumber">44</span><span class="Punctuation">,</span><span class="DecNumber">55</span><span class="Punctuation">,</span><span class="DecNumber">66</span><span class="Punctuation">]</span>
          <span class="Punctuation">]</span><span class="Punctuation">,</span>
          <span class="Punctuation">[</span>
            <span class="Punctuation">[</span><span class="DecNumber">111</span><span class="Punctuation">,</span><span class="DecNumber">222</span><span class="Punctuation">,</span><span class="DecNumber">333</span><span class="Punctuation">]</span><span class="Punctuation">,</span>
            <span class="Punctuation">[</span><span class="DecNumber">444</span><span class="Punctuation">,</span><span class="DecNumber">555</span><span class="Punctuation">,</span><span class="DecNumber">666</span><span class="Punctuation">]</span>
          <span class="Punctuation">]</span><span class="Punctuation">,</span>
          <span class="Punctuation">[</span>
            <span class="Punctuation">[</span><span class="DecNumber">1111</span><span class="Punctuation">,</span><span class="DecNumber">2222</span><span class="Punctuation">,</span><span class="DecNumber">3333</span><span class="Punctuation">]</span><span class="Punctuation">,</span>
            <span class="Punctuation">[</span><span class="DecNumber">4444</span><span class="Punctuation">,</span><span class="DecNumber">5555</span><span class="Punctuation">,</span><span class="DecNumber">6666</span><span class="Punctuation">]</span>
          <span class="Punctuation">]</span>
        <span class="Punctuation">]</span><span class="Operator">.</span><span class="Identifier">toTensor</span><span class="Punctuation">(</span><span class="Punctuation">)</span>
<span class="Identifier">echo</span> <span class="Identifier">c</span>

<span class="Comment"># Tensor of shape 4x2x3 of type &quot;int&quot; on backend &quot;Cpu&quot;</span>
<span class="Comment">#  |      1       2       3 |     11      22      33 |    111     222     333 |   1111    2222    3333|</span>
<span class="Comment">#  |      4       5       6 |     44      55      66 |    444     555     666 |   4444    5555    6666|</span></pre><p><tt class="docutils literal"><span class="pre">newTensor</span></tt> procedure can be used to initialize a tensor of a specific shape with a default value. (0 for numbers, false for bool ...)</p>
<p><tt class="docutils literal"><span class="pre">zeros</span></tt> and <tt class="docutils literal"><span class="pre">ones</span></tt> procedures create a new tensor filled with 0 and 1 respectively.</p>
<p><tt class="docutils literal"><span class="pre">zeros_like</span></tt> and <tt class="docutils literal"><span class="pre">ones_like</span></tt> take an input tensor and output a tensor of the same shape but filled with 0 and 1 respectively.</p>
<pre class="listing"><span class="Keyword">let</span> <span class="Identifier">e</span> <span class="Operator">=</span> <span class="Identifier">newTensor</span><span class="Punctuation">(</span><span class="Punctuation">[</span><span class="DecNumber">2</span><span class="Punctuation">,</span> <span class="DecNumber">3</span><span class="Punctuation">]</span><span class="Punctuation">,</span> <span class="Identifier">bool</span><span class="Punctuation">)</span>
<span class="Comment"># Tensor of shape 2x3 of type &quot;bool&quot; on backend &quot;Cpu&quot;</span>
<span class="Comment"># |false  false   false|</span>
<span class="Comment"># |false  false   false|</span>

<span class="Keyword">let</span> <span class="Identifier">f</span> <span class="Operator">=</span> <span class="Identifier">zeros</span><span class="Punctuation">(</span><span class="Punctuation">[</span><span class="DecNumber">4</span><span class="Punctuation">,</span> <span class="DecNumber">3</span><span class="Punctuation">]</span><span class="Punctuation">,</span> <span class="Identifier">float</span><span class="Punctuation">)</span>
<span class="Comment"># Tensor of shape 4x3 of type &quot;float&quot; on backend &quot;Cpu&quot;</span>
<span class="Comment"># |0.0    0.0     0.0|</span>
<span class="Comment"># |0.0    0.0     0.0|</span>
<span class="Comment"># |0.0    0.0     0.0|</span>
<span class="Comment"># |0.0    0.0     0.0|</span>

<span class="Keyword">let</span> <span class="Identifier">g</span> <span class="Operator">=</span> <span class="Identifier">ones</span><span class="Punctuation">(</span><span class="Punctuation">[</span><span class="DecNumber">4</span><span class="Punctuation">,</span> <span class="DecNumber">3</span><span class="Punctuation">]</span><span class="Punctuation">,</span> <span class="Identifier">float</span><span class="Punctuation">)</span>
<span class="Comment">#Tensor of shape 4x3 of type &quot;float&quot; on backend &quot;Cpu&quot;</span>
<span class="Comment">#|1.0    1.0     1.0|</span>
<span class="Comment">#|1.0    1.0     1.0|</span>
<span class="Comment">#|1.0    1.0     1.0|</span>
<span class="Comment">#|1.0    1.0     1.0|</span>

<span class="Keyword">let</span> <span class="Identifier">tmp</span> <span class="Operator">=</span> <span class="Punctuation">[</span><span class="Punctuation">[</span><span class="DecNumber">1</span><span class="Punctuation">,</span><span class="DecNumber">2</span><span class="Punctuation">]</span><span class="Punctuation">,</span><span class="Punctuation">[</span><span class="DecNumber">3</span><span class="Punctuation">,</span><span class="DecNumber">4</span><span class="Punctuation">]</span><span class="Punctuation">]</span><span class="Operator">.</span><span class="Identifier">toTensor</span><span class="Punctuation">(</span><span class="Punctuation">)</span>
<span class="Keyword">let</span> <span class="Identifier">h</span> <span class="Operator">=</span> <span class="Identifier">tmp</span><span class="Operator">.</span><span class="Identifier">zeros_like</span>
<span class="Comment"># Tensor of shape 2x2 of type &quot;int&quot; on backend &quot;Cpu&quot;</span>
<span class="Comment"># |0      0|</span>
<span class="Comment"># |0      0|</span>

<span class="Keyword">let</span> <span class="Identifier">i</span> <span class="Operator">=</span> <span class="Identifier">tmp</span><span class="Operator">.</span><span class="Identifier">ones_like</span>
<span class="Comment">#Tensor of shape 2x2 of type &quot;int&quot; on backend &quot;Cpu&quot;</span>
<span class="Comment">#|1      1|</span>
<span class="Comment">#|1      1|</span></pre>
<h3><a class="toc-backref" id="features-accessing-and-modifying-a-value" href="#features-accessing-and-modifying-a-value">Accessing and modifying a value</a></h3><p>Tensors value can be retrieved or set with array brackets.</p>
<pre class="listing"><span class="Keyword">var</span> <span class="Identifier">a</span> <span class="Operator">=</span> <span class="Identifier">toSeq</span><span class="Punctuation">(</span><span class="FloatNumber">1.</span><span class="Operator">.</span><span class="DecNumber">24</span><span class="Punctuation">)</span><span class="Operator">.</span><span class="Identifier">toTensor</span><span class="Punctuation">(</span><span class="Punctuation">)</span><span class="Operator">.</span><span class="Identifier">reshape</span><span class="Punctuation">(</span><span class="DecNumber">2</span><span class="Punctuation">,</span><span class="DecNumber">3</span><span class="Punctuation">,</span><span class="DecNumber">4</span><span class="Punctuation">)</span>

<span class="Identifier">echo</span> <span class="Identifier">a</span>
<span class="Comment"># Tensor of shape 2x3x4 of type &quot;int&quot; on backend &quot;Cpu&quot;</span>
<span class="Comment">#  |      1       2       3       4 |     13      14      15      16|</span>
<span class="Comment">#  |      5       6       7       8 |     17      18      19      20|</span>
<span class="Comment">#  |      9       10      11      12 |    21      22      23      24|</span>

<span class="Identifier">echo</span> <span class="Identifier">a</span><span class="Punctuation">[</span><span class="DecNumber">1</span><span class="Punctuation">,</span> <span class="DecNumber">1</span><span class="Punctuation">,</span> <span class="DecNumber">1</span><span class="Punctuation">]</span>
<span class="Comment"># 18</span>

<span class="Identifier">a</span><span class="Punctuation">[</span><span class="DecNumber">1</span><span class="Punctuation">,</span> <span class="DecNumber">1</span><span class="Punctuation">,</span> <span class="DecNumber">1</span><span class="Punctuation">]</span> <span class="Operator">=</span> <span class="DecNumber">999</span>
<span class="Identifier">echo</span> <span class="Identifier">a</span>
<span class="Comment"># Tensor of shape 2x3x4 of type &quot;int&quot; on backend &quot;Cpu&quot;</span>
<span class="Comment">#  |      1       2       3       4 |     13      14      15      16|</span>
<span class="Comment">#  |      5       6       7       8 |     17      999     19      20|</span>
<span class="Comment">#  |      9       10      11      12 |    21      22      23      24|</span></pre>
<h3><a class="toc-backref" id="features-copying" href="#features-copying">Copying</a></h3><p>Tensor copy is deep by default (all the data is copied). In the majority of cases Nim compiler will detect and avoid useless copies.</p>
<p><tt class="docutils literal"><span class="pre">unsafeView</span></tt> can be used on a Tensor to enforce shallow copying (data is shared between the 2 variables). Most shape manipulation proc also have an <tt class="docutils literal"><span class="pre">unsafe</span></tt> version.</p>

<h3><a class="toc-backref" id="features-slicing" href="#features-slicing">Slicing</a></h3><p>Arraymancer supports the following slicing syntax. It allows for selecting dimension subsets, whole dimension, stepping (one out of 2 rows), reversing dimensions, counting from the end.</p>
<pre class="listing"><span class="Keyword">import</span> <span class="Identifier">math</span><span class="Punctuation">,</span> <span class="Identifier">arraymancer</span><span class="Punctuation">,</span> <span class="Identifier">future</span>

<span class="Keyword">const</span>
    <span class="Identifier">x</span> <span class="Operator">=</span> <span class="Operator">@</span><span class="Punctuation">[</span><span class="DecNumber">1</span><span class="Punctuation">,</span> <span class="DecNumber">2</span><span class="Punctuation">,</span> <span class="DecNumber">3</span><span class="Punctuation">,</span> <span class="DecNumber">4</span><span class="Punctuation">,</span> <span class="DecNumber">5</span><span class="Punctuation">]</span>
    <span class="Identifier">y</span> <span class="Operator">=</span> <span class="Operator">@</span><span class="Punctuation">[</span><span class="DecNumber">1</span><span class="Punctuation">,</span> <span class="DecNumber">2</span><span class="Punctuation">,</span> <span class="DecNumber">3</span><span class="Punctuation">,</span> <span class="DecNumber">4</span><span class="Punctuation">,</span> <span class="DecNumber">5</span><span class="Punctuation">]</span>

<span class="Keyword">var</span>
    <span class="Identifier">vandermonde</span><span class="Punctuation">:</span> <span class="Identifier">seq</span><span class="Punctuation">[</span><span class="Identifier">seq</span><span class="Punctuation">[</span><span class="Identifier">int</span><span class="Punctuation">]</span><span class="Punctuation">]</span>
    <span class="Identifier">row</span><span class="Punctuation">:</span> <span class="Identifier">seq</span><span class="Punctuation">[</span><span class="Identifier">int</span><span class="Punctuation">]</span>

<span class="Identifier">vandermonde</span> <span class="Operator">=</span> <span class="Identifier">newSeq</span><span class="Punctuation">[</span><span class="Identifier">seq</span><span class="Punctuation">[</span><span class="Identifier">int</span><span class="Punctuation">]</span><span class="Punctuation">]</span><span class="Punctuation">(</span><span class="Punctuation">)</span>

<span class="Keyword">for</span> <span class="Identifier">i</span><span class="Punctuation">,</span> <span class="Identifier">xx</span> <span class="Keyword">in</span> <span class="Identifier">x</span><span class="Punctuation">:</span>
    <span class="Identifier">row</span> <span class="Operator">=</span> <span class="Identifier">newSeq</span><span class="Punctuation">[</span><span class="Identifier">int</span><span class="Punctuation">]</span><span class="Punctuation">(</span><span class="Punctuation">)</span>
    <span class="Identifier">vandermonde</span><span class="Operator">.</span><span class="Identifier">add</span><span class="Punctuation">(</span><span class="Identifier">row</span><span class="Punctuation">)</span>
    <span class="Keyword">for</span> <span class="Identifier">j</span><span class="Punctuation">,</span> <span class="Identifier">yy</span> <span class="Keyword">in</span> <span class="Identifier">y</span><span class="Punctuation">:</span>
        <span class="Identifier">vandermonde</span><span class="Punctuation">[</span><span class="Identifier">i</span><span class="Punctuation">]</span><span class="Operator">.</span><span class="Identifier">add</span><span class="Punctuation">(</span><span class="Identifier">xx</span><span class="Operator">^</span><span class="Identifier">yy</span><span class="Punctuation">)</span>

<span class="Keyword">let</span> <span class="Identifier">foo</span> <span class="Operator">=</span> <span class="Identifier">vandermonde</span><span class="Operator">.</span><span class="Identifier">toTensor</span><span class="Punctuation">(</span><span class="Punctuation">)</span>

<span class="Identifier">echo</span> <span class="Identifier">foo</span>

<span class="Comment"># Tensor of shape 5x5 of type &quot;int&quot; on backend &quot;Cpu&quot;</span>
<span class="Comment"># |1      1       1       1       1|</span>
<span class="Comment"># |2      4       8       16      32|</span>
<span class="Comment"># |3      9       27      81      243|</span>
<span class="Comment"># |4      16      64      256     1024|</span>
<span class="Comment"># |5      25      125     625     3125|</span>

<span class="Identifier">echo</span> <span class="Identifier">foo</span><span class="Punctuation">[</span><span class="FloatNumber">1.</span><span class="Operator">.</span><span class="DecNumber">2</span><span class="Punctuation">,</span> <span class="FloatNumber">3.</span><span class="Operator">.</span><span class="DecNumber">4</span><span class="Punctuation">]</span> <span class="Comment"># slice</span>

<span class="Comment"># Tensor of shape 2x2 of type &quot;int&quot; on backend &quot;Cpu&quot;</span>
<span class="Comment"># |16     32|</span>
<span class="Comment"># |81     243|</span>

<span class="Identifier">echo</span> <span class="Identifier">foo</span><span class="Punctuation">[</span><span class="FloatNumber">3.</span><span class="Operator">.</span><span class="Identifier">_</span><span class="Punctuation">,</span> <span class="Identifier">_</span><span class="Punctuation">]</span> <span class="Comment"># Span slice</span>

<span class="Comment"># Tensor of shape 2x5 of type &quot;int&quot; on backend &quot;Cpu&quot;</span>
<span class="Comment"># |4      16      64      256     1024|</span>
<span class="Comment"># |5      25      125     625     3125|</span>

<span class="Identifier">echo</span> <span class="Identifier">foo</span><span class="Punctuation">[</span><span class="Identifier">_</span><span class="Operator">..^</span><span class="DecNumber">3</span><span class="Punctuation">,</span> <span class="Identifier">_</span><span class="Punctuation">]</span> <span class="Comment"># Slice until (inclusive, consistent with Nim)</span>

<span class="Comment"># Tensor of shape 3x5 of type &quot;int&quot; on backend &quot;Cpu&quot;</span>
<span class="Comment"># |1      1       1       1       1|</span>
<span class="Comment"># |2      4       8       16      32|</span>
<span class="Comment"># |3      9       27      81      243|</span>

<span class="Identifier">echo</span> <span class="Identifier">foo</span><span class="Punctuation">[</span><span class="Identifier">_</span><span class="Operator">..</span><span class="Identifier">_</span><span class="Operator">|</span><span class="DecNumber">2</span><span class="Punctuation">,</span> <span class="Identifier">_</span><span class="Punctuation">]</span> <span class="Comment"># Step</span>

<span class="Comment"># Tensor of shape 3x5 of type &quot;int&quot; on backend &quot;Cpu&quot;</span>
<span class="Comment"># |1      1       1       1       1|</span>
<span class="Comment"># |3      9       27      81      243|</span>
<span class="Comment"># |5      25      125     625     3125|</span>

<span class="Identifier">echo</span> <span class="Identifier">foo</span><span class="Punctuation">[</span><span class="Operator">^</span><span class="FloatNumber">1.</span><span class="Operator">.</span><span class="DecNumber">0</span><span class="Operator">|-</span><span class="DecNumber">1</span><span class="Punctuation">,</span> <span class="Identifier">_</span><span class="Punctuation">]</span> <span class="Comment"># Reverse step</span>

<span class="Comment"># Tensor of shape 5x5 of type &quot;int&quot; on backend &quot;Cpu&quot;</span>
<span class="Comment"># |5      25      125     625     3125|</span>
<span class="Comment"># |4      16      64      256     1024|</span>
<span class="Comment"># |3      9       27      81      243|</span>
<span class="Comment"># |2      4       8       16      32|</span>
<span class="Comment"># |1    1    1    1    1|</span></pre>
<h3><a class="toc-backref" id="features-slice-mutations" href="#features-slice-mutations">Slice mutations</a></h3><p>Slices can also be mutated with a single value, a nested seq or array, a tensor or tensor slice.</p>
<pre class="listing"><span class="Keyword">import</span> <span class="Identifier">math</span><span class="Punctuation">,</span> <span class="Identifier">arraymancer</span><span class="Punctuation">,</span> <span class="Identifier">future</span>

<span class="Keyword">const</span>
    <span class="Identifier">x</span> <span class="Operator">=</span> <span class="Operator">@</span><span class="Punctuation">[</span><span class="DecNumber">1</span><span class="Punctuation">,</span> <span class="DecNumber">2</span><span class="Punctuation">,</span> <span class="DecNumber">3</span><span class="Punctuation">,</span> <span class="DecNumber">4</span><span class="Punctuation">,</span> <span class="DecNumber">5</span><span class="Punctuation">]</span>
    <span class="Identifier">y</span> <span class="Operator">=</span> <span class="Operator">@</span><span class="Punctuation">[</span><span class="DecNumber">1</span><span class="Punctuation">,</span> <span class="DecNumber">2</span><span class="Punctuation">,</span> <span class="DecNumber">3</span><span class="Punctuation">,</span> <span class="DecNumber">4</span><span class="Punctuation">,</span> <span class="DecNumber">5</span><span class="Punctuation">]</span>

<span class="Keyword">var</span>
    <span class="Identifier">vandermonde</span><span class="Punctuation">:</span> <span class="Identifier">seq</span><span class="Punctuation">[</span><span class="Identifier">seq</span><span class="Punctuation">[</span><span class="Identifier">int</span><span class="Punctuation">]</span><span class="Punctuation">]</span>
    <span class="Identifier">row</span><span class="Punctuation">:</span> <span class="Identifier">seq</span><span class="Punctuation">[</span><span class="Identifier">int</span><span class="Punctuation">]</span>

<span class="Identifier">vandermonde</span> <span class="Operator">=</span> <span class="Identifier">newSeq</span><span class="Punctuation">[</span><span class="Identifier">seq</span><span class="Punctuation">[</span><span class="Identifier">int</span><span class="Punctuation">]</span><span class="Punctuation">]</span><span class="Punctuation">(</span><span class="Punctuation">)</span>

<span class="Keyword">for</span> <span class="Identifier">i</span><span class="Punctuation">,</span> <span class="Identifier">xx</span> <span class="Keyword">in</span> <span class="Identifier">x</span><span class="Punctuation">:</span>
    <span class="Identifier">row</span> <span class="Operator">=</span> <span class="Identifier">newSeq</span><span class="Punctuation">[</span><span class="Identifier">int</span><span class="Punctuation">]</span><span class="Punctuation">(</span><span class="Punctuation">)</span>
    <span class="Identifier">vandermonde</span><span class="Operator">.</span><span class="Identifier">add</span><span class="Punctuation">(</span><span class="Identifier">row</span><span class="Punctuation">)</span>
    <span class="Keyword">for</span> <span class="Identifier">j</span><span class="Punctuation">,</span> <span class="Identifier">yy</span> <span class="Keyword">in</span> <span class="Identifier">y</span><span class="Punctuation">:</span>
        <span class="Identifier">vandermonde</span><span class="Punctuation">[</span><span class="Identifier">i</span><span class="Punctuation">]</span><span class="Operator">.</span><span class="Identifier">add</span><span class="Punctuation">(</span><span class="Identifier">xx</span><span class="Operator">^</span><span class="Identifier">yy</span><span class="Punctuation">)</span>

<span class="Keyword">var</span> <span class="Identifier">foo</span> <span class="Operator">=</span> <span class="Identifier">vandermonde</span><span class="Operator">.</span><span class="Identifier">toTensor</span><span class="Punctuation">(</span><span class="Punctuation">)</span>

<span class="Identifier">echo</span> <span class="Identifier">foo</span>

<span class="Comment"># Tensor of shape 5x5 of type &quot;int&quot; on backend &quot;Cpu&quot;</span>
<span class="Comment"># |1      1       1       1       1|</span>
<span class="Comment"># |2      4       8       16      32|</span>
<span class="Comment"># |3      9       27      81      243|</span>
<span class="Comment"># |4      16      64      256     1024|</span>
<span class="Comment"># |5      25      125     625     3125|</span>

<span class="Comment"># Mutation with a single value</span>
<span class="Identifier">foo</span><span class="Punctuation">[</span><span class="FloatNumber">1.</span><span class="Operator">.</span><span class="DecNumber">2</span><span class="Punctuation">,</span> <span class="FloatNumber">3.</span><span class="Operator">.</span><span class="DecNumber">4</span><span class="Punctuation">]</span> <span class="Operator">=</span> <span class="DecNumber">999</span>

<span class="Identifier">echo</span> <span class="Identifier">foo</span>
<span class="Comment"># Tensor of shape 5x5 of type &quot;int&quot; on backend &quot;Cpu&quot;</span>
<span class="Comment"># |1      1       1       1       1|</span>
<span class="Comment"># |2      4       8       999     999|</span>
<span class="Comment"># |3      9       27      999     999|</span>
<span class="Comment"># |4      16      64      256     1024|</span>
<span class="Comment"># |5      25      125     625     3125|</span>

<span class="Comment"># Mutation with nested array or nested seq</span>
<span class="Identifier">foo</span><span class="Punctuation">[</span><span class="FloatNumber">0.</span><span class="Operator">.</span><span class="DecNumber">1</span><span class="Punctuation">,</span><span class="FloatNumber">0.</span><span class="Operator">.</span><span class="DecNumber">1</span><span class="Punctuation">]</span> <span class="Operator">=</span> <span class="Punctuation">[</span><span class="Punctuation">[</span><span class="DecNumber">111</span><span class="Punctuation">,</span> <span class="DecNumber">222</span><span class="Punctuation">]</span><span class="Punctuation">,</span> <span class="Punctuation">[</span><span class="DecNumber">333</span><span class="Punctuation">,</span> <span class="DecNumber">444</span><span class="Punctuation">]</span><span class="Punctuation">]</span>

<span class="Identifier">echo</span> <span class="Identifier">foo</span>
<span class="Comment"># Tensor of shape 5x5 of type &quot;int&quot; on backend &quot;Cpu&quot;</span>
<span class="Comment"># |111    222     1       1       1|</span>
<span class="Comment"># |333    444     8       999     999|</span>
<span class="Comment"># |3      9       27      999     999|</span>
<span class="Comment"># |4      16      64      256     1024|</span>
<span class="Comment"># |5      25      125     625     3125|</span>

<span class="Comment"># Mutation with a tensor or tensor slice.</span>
<span class="Identifier">foo</span><span class="Punctuation">[</span><span class="Operator">^</span><span class="FloatNumber">2.</span><span class="Operator">.^</span><span class="DecNumber">1</span><span class="Punctuation">,</span><span class="FloatNumber">2.</span><span class="Operator">.</span><span class="DecNumber">4</span><span class="Punctuation">]</span> <span class="Operator">=</span> <span class="Identifier">foo</span><span class="Punctuation">[</span><span class="Operator">^</span><span class="FloatNumber">1.</span><span class="Operator">.^</span><span class="DecNumber">2</span><span class="Operator">|-</span><span class="DecNumber">1</span><span class="Punctuation">,</span> <span class="FloatNumber">4.</span><span class="Operator">.</span><span class="DecNumber">2</span><span class="Operator">|-</span><span class="DecNumber">1</span><span class="Punctuation">]</span>

<span class="Identifier">echo</span> <span class="Identifier">foo</span>
<span class="Comment"># Tensor of shape 5x5 of type &quot;int&quot; on backend &quot;Cpu&quot;</span>
<span class="Comment"># |111    222     1       1       1|</span>
<span class="Comment"># |333    444     8       999     999|</span>
<span class="Comment"># |3      9       27      999     999|</span>
<span class="Comment"># |4      16      3125    625     125|</span>
<span class="Comment"># |5      25      1024    256     64|</span></pre>
<h3><a class="toc-backref" id="features-shapeshifting" href="#features-shapeshifting">Shapeshifting</a></h3>
<h4><a class="toc-backref" id="shapeshifting-transposing" href="#shapeshifting-transposing">Transposing</a></h4><p>The <tt class="docutils literal"><span class="pre">transpose</span></tt> function will reverse the dimensions of a tensor.</p>

<h4><a class="toc-backref" id="shapeshifting-reshaping" href="#shapeshifting-reshaping">Reshaping</a></h4><p>The <tt class="docutils literal"><span class="pre">reshape</span></tt> function will change the shape of a tensor. The number of elements in the new and old shape must be the same.</p>
<p>For example:</p>
<pre class="listing"><span class="Keyword">let</span> <span class="Identifier">a</span> <span class="Operator">=</span> <span class="Identifier">toSeq</span><span class="Punctuation">(</span><span class="FloatNumber">1.</span><span class="Operator">.</span><span class="DecNumber">24</span><span class="Punctuation">)</span><span class="Operator">.</span><span class="Identifier">toTensor</span><span class="Punctuation">(</span><span class="Punctuation">)</span><span class="Operator">.</span><span class="Identifier">reshape</span><span class="Punctuation">(</span><span class="DecNumber">2</span><span class="Punctuation">,</span><span class="DecNumber">3</span><span class="Punctuation">,</span><span class="DecNumber">4</span><span class="Punctuation">)</span>

<span class="Comment">#Tensor of shape 2x3x4 of type &quot;int&quot; on backend &quot;Cpu&quot;</span>
<span class="Comment"># |      1       2       3       4 |     13      14      15      16|</span>
<span class="Comment"># |      5       6       7       8 |     17      18      19      20|</span>
<span class="Comment"># |      9       10      11      12 |    21      22      23      24|</span></pre>
<h4><a class="toc-backref" id="shapeshifting-permuting-reordering-dimension" href="#shapeshifting-permuting-reordering-dimension">Permuting - Reordering dimension</a></h4><p>The <tt class="docutils literal"><span class="pre">permute</span></tt> proc can be used to reorder dimensions.<br />Input is a tensor and the new dimension order<br /></p><pre class="listing"><span class="Keyword">let</span> <span class="Identifier">a</span> <span class="Operator">=</span> <span class="Identifier">toSeq</span><span class="Punctuation">(</span><span class="FloatNumber">1.</span><span class="Operator">.</span><span class="DecNumber">24</span><span class="Punctuation">)</span><span class="Operator">.</span><span class="Identifier">toTensor</span><span class="Punctuation">(</span><span class="Identifier">Cpu</span><span class="Punctuation">)</span><span class="Operator">.</span><span class="Identifier">reshape</span><span class="Punctuation">(</span><span class="DecNumber">2</span><span class="Punctuation">,</span><span class="DecNumber">3</span><span class="Punctuation">,</span><span class="DecNumber">4</span><span class="Punctuation">)</span>
<span class="Identifier">echo</span> <span class="Identifier">a</span>

<span class="Comment"># Tensor of shape 2x3x4 of type &quot;int&quot; on backend &quot;Cpu&quot;</span>
<span class="Comment">#  |      1       2       3       4 |     13      14      15      16|</span>
<span class="Comment">#  |      5       6       7       8 |     17      18      19      20|</span>
<span class="Comment">#  |      9       10      11      12 |    21      22      23      24|</span>

<span class="Identifier">echo</span> <span class="Identifier">a</span><span class="Operator">.</span><span class="Identifier">permute</span><span class="Punctuation">(</span><span class="DecNumber">0</span><span class="Punctuation">,</span><span class="DecNumber">2</span><span class="Punctuation">,</span><span class="DecNumber">1</span><span class="Punctuation">)</span> <span class="Comment"># dim 0 stays at 0, dim 1 becomes dim 2 and dim 2 becomes dim 1</span>

<span class="Comment"># Tensor of shape 2x4x3 of type &quot;int&quot; on backend &quot;Cpu&quot;</span>
<span class="Comment">#  |      1       5       9 |     13      17      21|</span>
<span class="Comment">#  |      2       6       10 |    14      18      22|</span>
<span class="Comment">#  |      3       7       11 |    15      19      23|</span>
<span class="Comment">#  |      4       8       12 |    16      20      24|</span></pre>
<h4><a class="toc-backref" id="shapeshifting-concatenation" href="#shapeshifting-concatenation">Concatenation</a></h4><p>Tensors can be concatenated along an axis with the <tt class="docutils literal"><span class="pre">concat</span></tt> proc.</p>
<pre class="listing"><span class="Keyword">import</span> <span class="Operator">../</span><span class="Identifier">arraymancer</span><span class="Punctuation">,</span> <span class="Identifier">sequtils</span>


<span class="Keyword">let</span> <span class="Identifier">a</span> <span class="Operator">=</span> <span class="Identifier">toSeq</span><span class="Punctuation">(</span><span class="FloatNumber">1.</span><span class="Operator">.</span><span class="DecNumber">4</span><span class="Punctuation">)</span><span class="Operator">.</span><span class="Identifier">toTensor</span><span class="Punctuation">(</span><span class="Identifier">Cpu</span><span class="Punctuation">)</span><span class="Operator">.</span><span class="Identifier">reshape</span><span class="Punctuation">(</span><span class="DecNumber">2</span><span class="Punctuation">,</span><span class="DecNumber">2</span><span class="Punctuation">)</span>

<span class="Keyword">let</span> <span class="Identifier">b</span> <span class="Operator">=</span> <span class="Identifier">toSeq</span><span class="Punctuation">(</span><span class="FloatNumber">5.</span><span class="Operator">.</span><span class="DecNumber">8</span><span class="Punctuation">)</span><span class="Operator">.</span><span class="Identifier">toTensor</span><span class="Punctuation">(</span><span class="Identifier">Cpu</span><span class="Punctuation">)</span><span class="Operator">.</span><span class="Identifier">reshape</span><span class="Punctuation">(</span><span class="DecNumber">2</span><span class="Punctuation">,</span><span class="DecNumber">2</span><span class="Punctuation">)</span>

<span class="Keyword">let</span> <span class="Identifier">c</span> <span class="Operator">=</span> <span class="Identifier">toSeq</span><span class="Punctuation">(</span><span class="FloatNumber">11.</span><span class="Operator">.</span><span class="DecNumber">16</span><span class="Punctuation">)</span><span class="Operator">.</span><span class="Identifier">toTensor</span><span class="Punctuation">(</span><span class="Identifier">Cpu</span><span class="Punctuation">)</span>
<span class="Keyword">let</span> <span class="Identifier">c0</span> <span class="Operator">=</span> <span class="Identifier">c</span><span class="Operator">.</span><span class="Identifier">reshape</span><span class="Punctuation">(</span><span class="DecNumber">3</span><span class="Punctuation">,</span><span class="DecNumber">2</span><span class="Punctuation">)</span>
<span class="Keyword">let</span> <span class="Identifier">c1</span> <span class="Operator">=</span> <span class="Identifier">c</span><span class="Operator">.</span><span class="Identifier">reshape</span><span class="Punctuation">(</span><span class="DecNumber">2</span><span class="Punctuation">,</span><span class="DecNumber">3</span><span class="Punctuation">)</span>

<span class="Identifier">echo</span> <span class="Identifier">concat</span><span class="Punctuation">(</span><span class="Identifier">a</span><span class="Punctuation">,</span><span class="Identifier">b</span><span class="Punctuation">,</span><span class="Identifier">c0</span><span class="Punctuation">,</span> <span class="Identifier">axis</span> <span class="Operator">=</span> <span class="DecNumber">0</span><span class="Punctuation">)</span>
<span class="Comment">#Tensor of shape 7x2 of type &quot;int&quot; on backend &quot;Cpu&quot;</span>
<span class="Comment">#|1      2|</span>
<span class="Comment">#|3      4|</span>
<span class="Comment">#|5      6|</span>
<span class="Comment">#|7      8|</span>
<span class="Comment">#|11     12|</span>
<span class="Comment">#|13     14|</span>
<span class="Comment">#|15     16|</span>

<span class="Identifier">echo</span> <span class="Identifier">concat</span><span class="Punctuation">(</span><span class="Identifier">a</span><span class="Punctuation">,</span><span class="Identifier">b</span><span class="Punctuation">,</span><span class="Identifier">c1</span><span class="Punctuation">,</span> <span class="Identifier">axis</span> <span class="Operator">=</span> <span class="DecNumber">1</span><span class="Punctuation">)</span>
<span class="Comment"># Tensor of shape 2x7 of type &quot;int&quot; on backend &quot;Cpu&quot;</span>
<span class="Comment"># |1      2       5       6       11      12      13|</span>
<span class="Comment"># |3      4       7       8       14      15      16|</span></pre>
<h3><a class="toc-backref" id="features-universal-functions" href="#features-universal-functions">Universal functions</a></h3><p>Functions that applies to a single element can work on a whole tensor similar to Numpy's universal functions.</p>
<p>3 functions exist: <tt class="docutils literal"><span class="pre">makeUniversal</span></tt>, <tt class="docutils literal"><span class="pre">makeUniversalLocal</span></tt> and <tt class="docutils literal"><span class="pre">map</span></tt>.</p>
<p><tt class="docutils literal"><span class="pre">makeUniversal</span></tt> create a a function that applies to each element of a tensor from any unary function. Most functions from the <tt class="docutils literal"><span class="pre">math</span></tt> module have been generalized to tensors with <tt class="docutils literal"><span class="pre">makeUniversal(sin)</span></tt>.<br />Furthermore those universal functions are exported and available for import.<br /></p><p><tt class="docutils literal"><span class="pre">makeUniversalLocal</span></tt> does not export the universal functions.</p>
<p><tt class="docutils literal"><span class="pre">map</span></tt> is more generic and map any function to all element of a tensor. <tt class="docutils literal"><span class="pre">map</span></tt> works even if the function changes the type of the tensor's elements.</p>
<pre class="listing"><span class="Identifier">echo</span> <span class="Identifier">foo</span><span class="Operator">.</span><span class="Identifier">map</span><span class="Punctuation">(</span><span class="Identifier">x</span> <span class="Operator">=&gt;</span> <span class="Identifier">x</span><span class="Operator">.</span><span class="Identifier">isPowerOfTwo</span><span class="Punctuation">)</span> <span class="Comment"># map a function (`=&gt;` comes from the future module )</span>

<span class="Comment"># Tensor of shape 5x5 of type &quot;bool&quot; on backend &quot;Cpu&quot;</span>
<span class="Comment"># |true   true    true    true    true|</span>
<span class="Comment"># |true   true    true    true    true|</span>
<span class="Comment"># |false  false   false   false   false|</span>
<span class="Comment"># |true   true    true    true    true|</span>
<span class="Comment"># |false  false   false   false   false|</span>

<span class="Keyword">let</span> <span class="Identifier">foo_float</span> <span class="Operator">=</span> <span class="Identifier">foo</span><span class="Operator">.</span><span class="Identifier">map</span><span class="Punctuation">(</span><span class="Identifier">x</span> <span class="Operator">=&gt;</span> <span class="Identifier">x</span><span class="Operator">.</span><span class="Identifier">float</span><span class="Punctuation">)</span>
<span class="Identifier">echo</span> <span class="Identifier">ln</span> <span class="Identifier">foo_float</span> <span class="Comment"># universal function (convert first to float for ln)</span>

<span class="Comment"># Tensor of shape 5x5 of type &quot;float&quot; on backend &quot;Cpu&quot;</span>
<span class="Comment"># |0.0    0.0     0.0     0.0     0.0|</span>
<span class="Comment"># |0.6931471805599453     1.386294361119891       2.079441541679836       2.772588722239781       3.465735902799727|</span>
<span class="Comment"># |1.09861228866811       2.19722457733622        3.295836866004329       4.394449154672439       5.493061443340548|</span>
<span class="Comment"># |1.386294361119891      2.772588722239781       4.158883083359671       5.545177444479562       6.931471805599453|</span>
<span class="Comment"># |1.6094379124341        3.218875824868201       4.828313737302302       6.437751649736401       8.047189562170502|</span></pre>
<h3><a class="toc-backref" id="features-type-conversion" href="#features-type-conversion">Type conversion</a></h3><p>A type conversion fonction <tt class="docutils literal"><span class="pre">astype</span></tt> is provided for convenience</p>
<pre class="listing"><span class="Keyword">let</span> <span class="Identifier">foo_float</span> <span class="Operator">=</span> <span class="Identifier">foo</span><span class="Operator">.</span><span class="Identifier">astype</span><span class="Punctuation">(</span><span class="Identifier">float</span><span class="Punctuation">)</span></pre>
<h3><a class="toc-backref" id="features-matrix-and-vector-operations" href="#features-matrix-and-vector-operations">Matrix and vector operations</a></h3><p>The following linear algebra operations are supported for tensors of rank 1 (vectors) and 2 (matrices):</p>
<ul class="simple"><li>dot product (Vector to Vector) using <tt class="docutils literal"><span class="pre">dot</span></tt></li>
<li>addition and substraction (any rank) using <tt class="docutils literal"><span class="pre">+</span></tt> and <tt class="docutils literal"><span class="pre">-</span></tt></li>
<li>in-place addition and substraction (any-rank) using <tt class="docutils literal"><span class="pre">+=</span></tt> and <tt class="docutils literal"><span class="pre">-=</span></tt></li>
<li>multiplication or division by a scalar using <tt class="docutils literal"><span class="pre">*</span></tt> and <tt class="docutils literal"><span class="pre">/</span></tt></li>
<li>matrix-matrix multiplication using <tt class="docutils literal"><span class="pre">*</span></tt></li>
<li>matrix-vector multiplication using <tt class="docutils literal"><span class="pre">*</span></tt></li>
<li>element-wise multiplication (Hadamard product) using <tt class="docutils literal"><span class="pre">.*</span></tt></li>
</ul>
<p>Note: Matrix operations for floats are accelerated using BLAS (Intel MKL, OpenBLAS, Apple Accelerate ...). Unfortunately there is no acceleration routine for integers. Integer matrix-matrix and matrix-vector multiplications are implemented via semi-optimized routines (no naive loops but don't leverage CPU-specific features).</p>
<pre class="listing"><span class="Identifier">echo</span> <span class="Identifier">foo_float</span> <span class="Operator">*</span> <span class="Identifier">foo_float</span> <span class="Comment"># Accelerated Matrix-Matrix multiplication (needs float)</span>
<span class="Comment"># Tensor of shape 5x5 of type &quot;float&quot; on backend &quot;Cpu&quot;</span>
<span class="Comment"># |15.0    55.0    225.0    979.0     4425.0|</span>
<span class="Comment"># |258.0   1146.0  5274.0   24810.0   118458.0|</span>
<span class="Comment"># |1641.0  7653.0  36363.0  174945.0  849171.0|</span>
<span class="Comment"># |6372.0  30340.0 146244.0 710980.0  3478212.0|</span>
<span class="Comment"># |18555.0 89355.0 434205.0 2123655.0 10436805.0|</span></pre>
<h3><a class="toc-backref" id="features-broadcasting" href="#features-broadcasting">Broadcasting</a></h3><p>Arraymancer supports explicit broadcasting with <tt class="docutils literal"><span class="pre">broadcast</span></tt> and its alias <tt class="docutils literal"><span class="pre">bc</span></tt>.<br />And supports implicit broadcasting with operations beginning with a dot:<br /></p><pre class="listing"><span class="Keyword">let</span> <span class="Identifier">j</span> <span class="Operator">=</span> <span class="Punctuation">[</span><span class="DecNumber">0</span><span class="Punctuation">,</span> <span class="DecNumber">10</span><span class="Punctuation">,</span> <span class="DecNumber">20</span><span class="Punctuation">,</span> <span class="DecNumber">30</span><span class="Punctuation">]</span><span class="Operator">.</span><span class="Identifier">toTensor</span><span class="Punctuation">(</span><span class="Identifier">Cpu</span><span class="Punctuation">)</span><span class="Operator">.</span><span class="Identifier">reshape</span><span class="Punctuation">(</span><span class="DecNumber">4</span><span class="Punctuation">,</span><span class="DecNumber">1</span><span class="Punctuation">)</span>
<span class="Keyword">let</span> <span class="Identifier">k</span> <span class="Operator">=</span> <span class="Punctuation">[</span><span class="DecNumber">0</span><span class="Punctuation">,</span> <span class="DecNumber">1</span><span class="Punctuation">,</span> <span class="DecNumber">2</span><span class="Punctuation">]</span><span class="Operator">.</span><span class="Identifier">toTensor</span><span class="Punctuation">(</span><span class="Identifier">Cpu</span><span class="Punctuation">)</span><span class="Operator">.</span><span class="Identifier">reshape</span><span class="Punctuation">(</span><span class="DecNumber">1</span><span class="Punctuation">,</span><span class="DecNumber">3</span><span class="Punctuation">)</span>

<span class="Identifier">echo</span> <span class="Identifier">j</span> <span class="Operator">.+</span> <span class="Identifier">k</span>
<span class="Comment"># Tensor of shape 4x3 of type &quot;int&quot; on backend &quot;Cpu&quot;</span>
<span class="Comment">#|0      1       2|</span>
<span class="Comment">#|10     11      12|</span>
<span class="Comment">#|20     21      22|</span>
<span class="Comment">#|30     31      32|</span></pre><ul class="simple"><li><tt class="docutils literal"><span class="pre">.+</span></tt>,<tt class="docutils literal"><span class="pre">.-</span></tt>,</li>
<li><tt class="docutils literal"><span class="pre">.*</span></tt>: broadcasted element-wise matrix multiplication also called Hadamard product)</li>
<li><tt class="docutils literal"><span class="pre">./</span></tt>: broadcasted element-wise division or integer-division</li>
<li><tt class="docutils literal"><span class="pre">.+=</span></tt>, <tt class="docutils literal"><span class="pre">.-=</span></tt>, <tt class="docutils literal"><span class="pre">.*=</span></tt>, <tt class="docutils literal"><span class="pre">./=</span></tt>: in-place versions. Only the right operand is broadcastable.</li>
</ul>

<h3><a class="toc-backref" id="features-iterators" href="#features-iterators">Iterators</a></h3><p>Tensors can be iterated in the proper order. Arraymancer provides:</p>
<ul class="simple"><li><tt class="docutils literal"><span class="pre">items</span></tt> and <tt class="docutils literal"><span class="pre">pairs</span></tt>. <tt class="docutils literal"><span class="pre">pairs</span></tt> returns the coordinates of the tensor.</li>
</ul>
<pre class="listing"><span class="Keyword">import</span> <span class="Operator">../</span><span class="Identifier">arraymancer</span><span class="Punctuation">,</span> <span class="Identifier">sequtils</span>

<span class="Keyword">let</span> <span class="Identifier">a</span> <span class="Operator">=</span> <span class="Identifier">toSeq</span><span class="Punctuation">(</span><span class="FloatNumber">1.</span><span class="Operator">.</span><span class="DecNumber">24</span><span class="Punctuation">)</span><span class="Operator">.</span><span class="Identifier">toTensor</span><span class="Punctuation">(</span><span class="Identifier">Cpu</span><span class="Punctuation">)</span><span class="Operator">.</span><span class="Identifier">reshape</span><span class="Punctuation">(</span><span class="DecNumber">2</span><span class="Punctuation">,</span><span class="DecNumber">3</span><span class="Punctuation">,</span><span class="DecNumber">4</span><span class="Punctuation">)</span>
<span class="Comment"># Tensor of shape 2x3x4 of type &quot;int&quot; on backend &quot;Cpu&quot;</span>
<span class="Comment">#  |      1       2       3       4 |     13      14      15      16|</span>
<span class="Comment">#  |      5       6       7       8 |     17      18      19      20|</span>
<span class="Comment">#  |      9       10      11      12 |    21      22      23      24|</span>

<span class="Keyword">for</span> <span class="Identifier">v</span> <span class="Keyword">in</span> <span class="Identifier">a</span><span class="Punctuation">:</span>
  <span class="Identifier">echo</span> <span class="Identifier">v</span>

<span class="Keyword">for</span> <span class="Identifier">coord</span><span class="Punctuation">,</span> <span class="Identifier">v</span> <span class="Keyword">in</span> <span class="Identifier">a</span><span class="Punctuation">:</span>
  <span class="Identifier">echo</span> <span class="Identifier">coord</span>
  <span class="Identifier">echo</span> <span class="Identifier">v</span>
<span class="Comment"># @[0, 0, 0]</span>
<span class="Comment"># 1</span>
<span class="Comment"># @[0, 0, 1]</span>
<span class="Comment"># 2</span>
<span class="Comment"># @[0, 0, 2]</span>
<span class="Comment"># 3</span>
<span class="Comment"># @[0, 0, 3]</span>
<span class="Comment"># 4</span>
<span class="Comment"># @[0, 1, 0]</span>
<span class="Comment"># 5</span>
<span class="Comment"># @[0, 1, 1]</span>
<span class="Comment"># 6</span>
<span class="Comment"># @[0, 1, 2]</span>
<span class="Comment"># 7</span>
<span class="Comment"># @[0, 1, 3]</span>
<span class="Comment"># 8</span>
<span class="Comment"># @[0, 2, 0]</span>
<span class="Comment"># 9</span>
<span class="Comment"># ...</span></pre><p>For convenience a <tt class="docutils literal"><span class="pre">values</span></tt> closure iterator is available for iterator chaining. <tt class="docutils literal"><span class="pre">values</span></tt> is equivalent to <tt class="docutils literal"><span class="pre">items</span></tt>.</p>
<p>A <tt class="docutils literal"><span class="pre">mitems</span></tt> iterator is available to directly mutate elements while iterating.<br />An <tt class="docutils literal"><span class="pre">axis</span></tt> iterator is available to iterate along an axis.<br /></p>
<h3><a class="toc-backref" id="features-higher-order-functions-map-reduce-fold" href="#features-higher-order-functions-map-reduce-fold">Higher-order functions (Map, Reduce, Fold)</a></h3><p>Arraymancer supports efficient higher-order functions on the whole tensor or on an axis.</p>

<h4><a class="toc-backref" id="higher-order-functions-map-reduce-fold-map-apply-map2-apply2" href="#higher-order-functions-map-reduce-fold-map-apply-map2-apply2"><tt class="docutils literal"><span class="pre">map</span></tt>, <tt class="docutils literal"><span class="pre">apply</span></tt>, <tt class="docutils literal"><span class="pre">map2</span></tt>, <tt class="docutils literal"><span class="pre">apply2</span></tt></a></h4><pre class="listing"><span class="Identifier">a</span><span class="Operator">.</span><span class="Identifier">map</span><span class="Punctuation">(</span><span class="Identifier">x</span> <span class="Operator">=&gt;</span> <span class="Identifier">x</span><span class="Operator">+</span><span class="DecNumber">1</span><span class="Punctuation">)</span></pre><p>or</p>
<pre class="listing"><span class="Keyword">proc</span> <span class="Identifier">plusone</span><span class="Punctuation">[</span><span class="Identifier">T</span><span class="Punctuation">]</span><span class="Punctuation">(</span><span class="Identifier">x</span><span class="Punctuation">:</span> <span class="Identifier">T</span><span class="Punctuation">)</span><span class="Punctuation">:</span> <span class="Identifier">T</span> <span class="Operator">=</span>
  <span class="Identifier">x</span> <span class="Operator">+</span> <span class="DecNumber">1</span>
<span class="Identifier">a</span><span class="Operator">.</span><span class="Identifier">map</span><span class="Punctuation">(</span><span class="Identifier">plusone</span><span class="Punctuation">)</span> <span class="Comment"># Map the function plusone</span></pre><p>Note: for basic operation, you can use implicit broadcasting instead <tt class="docutils literal"><span class="pre">a .+ 1</span></tt></p>
<p><tt class="docutils literal"><span class="pre">apply</span></tt> is the same as <tt class="docutils literal"><span class="pre">map</span></tt> but in-place.</p>
<p><tt class="docutils literal"><span class="pre">map2</span></tt> and <tt class="docutils literal"><span class="pre">apply2</span></tt> takes 2 input tensors and respectively, return a new one or modify the first in-place.</p>
<pre class="listing"><span class="Keyword">proc</span> <span class="Punctuation">`</span><span class="Operator">**</span><span class="Punctuation">`</span><span class="Punctuation">[</span><span class="Identifier">T</span><span class="Punctuation">]</span><span class="Punctuation">(</span><span class="Identifier">x</span><span class="Punctuation">,</span> <span class="Identifier">y</span><span class="Punctuation">:</span> <span class="Identifier">T</span><span class="Punctuation">)</span><span class="Punctuation">:</span> <span class="Identifier">T</span> <span class="Operator">=</span> <span class="Comment"># We create a new power `**` function that works on 2 scalars</span>
  <span class="Identifier">pow</span><span class="Punctuation">(</span><span class="Identifier">x</span><span class="Punctuation">,</span> <span class="Identifier">y</span><span class="Punctuation">)</span>
<span class="Identifier">a</span><span class="Operator">.</span><span class="Identifier">map2</span><span class="Punctuation">(</span><span class="Punctuation">`</span><span class="Operator">**</span><span class="Punctuation">`</span><span class="Punctuation">,</span> <span class="Identifier">b</span><span class="Punctuation">)</span>
<span class="Comment"># Or</span>
<span class="Identifier">map2</span><span class="Punctuation">(</span><span class="Identifier">a</span><span class="Punctuation">,</span> <span class="Punctuation">`</span><span class="Operator">**</span><span class="Punctuation">`</span><span class="Punctuation">,</span> <span class="Identifier">b</span><span class="Punctuation">)</span></pre>
<h4><a class="toc-backref" id="higher-order-functions-map-reduce-fold-reduce-on-the-whole-tensor-or-along-an-axis" href="#higher-order-functions-map-reduce-fold-reduce-on-the-whole-tensor-or-along-an-axis"><tt class="docutils literal"><span class="pre">reduce</span></tt> on the whole Tensor or along an axis</a></h4><p><tt class="docutils literal"><span class="pre">reduce</span></tt> apply a function like <tt class="docutils literal"><span class="pre">+</span></tt> or <tt class="docutils literal"><span class="pre">max</span></tt> on the whole Tensor[T] returning a single value T.</p>
<p>For example:</p>
<ul class="simple"><li>Reducing with <tt class="docutils literal"><span class="pre">+</span></tt> returns the sum of all elements of teh Tensor.</li>
<li>Reducing with <tt class="docutils literal"><span class="pre">max</span></tt> returns the biggest element of the Tensor</li>
</ul>
<p><tt class="docutils literal"><span class="pre">reduce</span></tt> can be applied along an axis, for example the sum along the rows of a Tensor.</p>

<h4><a class="toc-backref" id="higher-order-functions-map-reduce-fold-fold-on-the-whole-tensor-or-along-an-axis" href="#higher-order-functions-map-reduce-fold-fold-on-the-whole-tensor-or-along-an-axis"><tt class="docutils literal"><span class="pre">fold</span></tt> on the whole Tensor or along an axis</a></h4><p><tt class="docutils literal"><span class="pre">fold</span></tt> is a generalization of <tt class="docutils literal"><span class="pre">reduce</span></tt>. Its starting value is not the first element of the Tensor.</p>
<p>It can do anything that reduce can, but also has other tricks because it is not constrained by the Tensor type or starting value.</p>
<p>For example:</p>
<ul class="simple"><li>Reducing with <tt class="docutils literal"><span class="pre">was_a_odd_and_what_about_b</span></tt> and a starting value of <tt class="docutils literal"><span class="pre">true</span></tt> returns <tt class="docutils literal"><span class="pre">true</span></tt> if all elements are odd or <tt class="docutils literal"><span class="pre">false</span></tt> otherwise</li>
</ul>
<p>Just in case</p>
<pre class="listing"><span class="Keyword">proc</span> <span class="Identifier">was_a_odd_and_what_about_b</span><span class="Punctuation">[</span><span class="Identifier">T</span><span class="Punctuation">:</span> <span class="Identifier">SomeInteger</span><span class="Punctuation">]</span><span class="Punctuation">(</span><span class="Identifier">a</span><span class="Punctuation">:</span> <span class="Identifier">bool</span><span class="Punctuation">,</span> <span class="Identifier">b</span><span class="Punctuation">:</span> <span class="Identifier">T</span><span class="Punctuation">)</span><span class="Punctuation">:</span> <span class="Identifier">bool</span> <span class="Operator">=</span>
  <span class="Keyword">return</span> <span class="Identifier">a</span> <span class="Keyword">and</span> <span class="Punctuation">(</span><span class="Identifier">b</span> <span class="Keyword">mod</span> <span class="DecNumber">2</span> <span class="Operator">==</span> <span class="DecNumber">1</span><span class="Punctuation">)</span> <span class="Comment"># a is the result of previous computations, b is the new integer to check.</span></pre>
<h3><a class="toc-backref" id="features-aggregate-and-statistics" href="#features-aggregate-and-statistics">Aggregate and Statistics</a></h3><p><tt class="docutils literal"><span class="pre">sum</span></tt> and <tt class="docutils literal"><span class="pre">mean</span></tt> functions are available to compute the sum and mean of a tensor.<br /><tt class="docutils literal"><span class="pre">sum</span></tt> and <tt class="docutils literal"><span class="pre">mean</span></tt> can also be computed along an axis with the <tt class="docutils literal"><span class="pre">axis</span></tt> argument.<br /></p><p>Generic aggregates on the whole tensor or along an axis can be computed with <tt class="docutils literal"><span class="pre">agg</span></tt> and <tt class="docutils literal"><span class="pre">agg_inplace</span></tt> functions. </p>
</p>
  <div class="section" id="6">
<h1><a class="toc-backref" href="#6">Imports</a></h1>
<dl class="item">
<a class="reference external" href="sequtils.html">sequtils</a>, <a class="reference external" href="strutils.html">strutils</a>, <a class="reference external" href="future.html">future</a>, <a class="reference external" href="algorithm.html">algorithm</a>, <a class="reference external" href="nimblas.html">nimblas</a>, <a class="reference external" href="math.html">math</a>, <a class="reference external" href="typetraits.html">typetraits</a>, <a class="reference external" href="macros.html">macros</a>, <a class="reference external" href="random.html">random</a>
</dl></div>
<div class="section" id="7">
<h1><a class="toc-backref" href="#7">Types</a></h1>
<dl class="item">
<dt id="Backend"><a name="Backend"></a><pre><span class="Identifier">Backend</span> <span class="Other">=</span> <span class="Keyword">enum</span>
  <span class="Identifier">Cpu</span><span class="Other">,</span> <span class="Identifier">Cuda</span></pre></dt>
<dd>
<p><tt class="docutils literal"><span class="pre">Backend</span></tt> for tensor computation and memory allocation.</p>
<p>Only deprecated procs from v0.1.3 uses this for the moment.</p>


</dd>
<dt id="Tensor"><a name="Tensor"></a><pre><span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> <span class="Other">=</span> <span class="Keyword">object</span>
  <span class="Identifier">shape</span><span class="Operator">*</span><span class="Other">:</span> <span class="Identifier">seq</span><span class="Other">[</span><span class="Identifier">int</span><span class="Other">]</span>
  <span class="Identifier">strides</span><span class="Operator">*</span><span class="Other">:</span> <span class="Identifier">seq</span><span class="Other">[</span><span class="Identifier">int</span><span class="Other">]</span>
  <span class="Identifier">offset</span><span class="Operator">*</span><span class="Other">:</span> <span class="Identifier">int</span>
  <span class="Identifier">data</span><span class="Operator">*</span><span class="Other">:</span> <span class="Identifier">seq</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span>
</pre></dt>
<dd>
<dl class="docutils"><dt>Tensor data structure stored on Cpu</dt>
<dd><ul class="simple"><li><tt class="docutils literal"><span class="pre">shape</span></tt>: Dimensions of the tensor</li>
<li><tt class="docutils literal"><span class="pre">strides</span></tt>: Numbers of items to skip to get the next item along a dimension.</li>
<li><tt class="docutils literal"><span class="pre">offset</span></tt>: Offset to get the first item of the Tensor. Note: offset can be negative, in particular for slices.</li>
<li><tt class="docutils literal"><span class="pre">data</span></tt>: A sequence that holds the actual data</li>
</ul>
</dd>
</dl>
<p>Fields are public so that external libraries can easily construct a Tensor.</p>


</dd>
<dt id="CudaSeq"><a name="CudaSeq"></a><pre><span class="Identifier">CudaSeq</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> <span class="Other">=</span> <span class="Keyword">object</span>
  <span class="Identifier">len</span><span class="Other">:</span> <span class="Identifier">int</span>
  <span class="Identifier">data</span><span class="Other">:</span> <span class="Keyword">ref</span> <span class="Other">[</span><span class="Keyword">ptr</span> <span class="Identifier">UncheckedArray</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">]</span>
</pre></dt>
<dd>
<p>Seq-like structure on the Cuda backend.</p>
<p>Nim garbage collector will automatically ask cuda to clear GPU memory if <tt class="docutils literal"><span class="pre">data</span></tt> becomes unused.</p>


</dd>
<dt id="CudaTensor"><a name="CudaTensor"></a><pre><span class="Identifier">CudaTensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> <span class="Other">=</span> <span class="Keyword">object</span>
  <span class="Identifier">shape</span><span class="Operator">*</span><span class="Other">:</span> <span class="Identifier">seq</span><span class="Other">[</span><span class="Identifier">int</span><span class="Other">]</span>
  <span class="Identifier">strides</span><span class="Operator">*</span><span class="Other">:</span> <span class="Identifier">seq</span><span class="Other">[</span><span class="Identifier">int</span><span class="Other">]</span>
  <span class="Identifier">offset</span><span class="Operator">*</span><span class="Other">:</span> <span class="Identifier">int</span>
  <span class="Identifier">data</span><span class="Operator">*</span><span class="Other">:</span> <span class="Identifier">CudaSeq</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span>
</pre></dt>
<dd>
<dl class="docutils"><dt>Tensor data structure stored on Nvidia GPU (Cuda)</dt>
<dd><ul class="simple"><li><tt class="docutils literal"><span class="pre">shape</span></tt>: Dimensions of the tensor</li>
<li><tt class="docutils literal"><span class="pre">strides</span></tt>: Numbers of items to skip to get the next item along a dimension.</li>
<li><tt class="docutils literal"><span class="pre">offset</span></tt>: Offset to get the first item of the Tensor. Note: offset can be negative, in particular for slices.</li>
<li><tt class="docutils literal"><span class="pre">data</span></tt>: A cuda seq-like object that points to the data location</li>
</ul>
</dd>
</dl>
<p>Note: currently <tt class="docutils literal"><span class="pre">=</span></tt> assignement for CudaTensor does not copy. Both CudaTensors will share a view of the same data location. Modifying the data in one will modify the data in the other.</p>
<p>In the future CudaTensor will leverage Nim compiler to automatically copy if a memory location would be used more than once in a mutable manner.</p>


</dd>
<dt id="SteppedSlice"><a name="SteppedSlice"></a><pre><span class="Identifier">SteppedSlice</span> <span class="Other">=</span> <span class="Keyword">object</span>
  <span class="Identifier">a</span><span class="Other">,</span> <span class="Identifier">b</span><span class="Other">:</span> <span class="Identifier">int</span>
  <span class="Identifier">step</span><span class="Other">:</span> <span class="Identifier">int</span>
  <span class="Identifier">a_from_end</span><span class="Other">:</span> <span class="Identifier">bool</span>
  <span class="Identifier">b_from_end</span><span class="Other">:</span> <span class="Identifier">bool</span>
</pre></dt>
<dd>
<dl class="docutils"><dt>Internal: A slice object related to a tensor single dimension:</dt>
<dd><ul class="simple"><li>a, b: Respectively the beginning and the end of the range of the dimension</li>
<li>step: The stepping of the slice (can be negative)</li>
<li>a/b_from_end: Indicates if a/b should be counted from 0 or from the end of the tensor relevant dimension.</li>
</ul>
</dd>
</dl>
<p>Slicing syntax like a[2, 1..&lt;5, _] will be converted at compile-time to SteppedSlices</p>


</dd>
<dt id="Step"><a name="Step"></a><pre><span class="Identifier">Step</span> <span class="Other">=</span> <span class="Keyword">object</span>
  <span class="Identifier">b</span><span class="Other">:</span> <span class="Identifier">int</span>
  <span class="Identifier">step</span><span class="Other">:</span> <span class="Identifier">int</span>
</pre></dt>
<dd>
<p>Internal: Workaround to build <tt class="docutils literal"><span class="pre">SteppedSlice</span></tt> without using parenthesis.</p>
<p>Expected syntax is <tt class="docutils literal"><span class="pre">tensor[0..10|1]</span></tt>.</p>
<p>Due to operator precedence of <tt class="docutils literal"><span class="pre">|</span></tt> over <tt class="docutils literal"><span class="pre">..</span></tt> [0..10|1] is interpreted as [0..(10|1)]</p>


</dd>

</dl></div>
<div class="section" id="10">
<h1><a class="toc-backref" href="#10">Consts</a></h1>
<dl class="item">
<dt id="_"><a name="_"></a><pre><span class="Operator">_</span> <span class="Other">=</span> <span class="Identifier">SteppedSlice</span><span class="Other">(</span><span class="Identifier">b</span><span class="Other">:</span> <span class="DecNumber">1</span><span class="Other">,</span> <span class="Identifier">step</span><span class="Other">:</span> <span class="DecNumber">1</span><span class="Other">,</span> <span class="Identifier">b_from_end</span><span class="Other">:</span> <span class="DecNumber">true</span><span class="Other">)</span></pre></dt>
<dd>


</dd>

</dl></div>
<div class="section" id="12">
<h1><a class="toc-backref" href="#12">Procs</a></h1>
<dl class="item">
<dt id="size"><a name="size,AnyTensor"></a><pre><span class="Keyword">proc</span> <span class="Identifier">size</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">AnyTensor</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">int</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>A tensor</li>
</ul>
</dd>
<dt>Returns:</dt>
<dd><ul class="simple"><li>The total number of elements it contains</li>
</ul>
</dd>
</dl>


</dd>
<dt id="shape_to_strides"><a name="shape_to_strides,seq[int],OrderType"></a><pre><span class="Keyword">proc</span> <span class="Identifier">shape_to_strides</span><span class="Other">(</span><span class="Identifier">shape</span><span class="Other">:</span> <span class="Identifier">seq</span><span class="Other">[</span><span class="Identifier">int</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">layout</span><span class="Other">:</span> <span class="Identifier">OrderType</span> <span class="Other">=</span> <span class="Identifier">rowMajor</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">seq</span><span class="Other">[</span><span class="Identifier">int</span><span class="Other">]</span> <span class="Other pragmabegin">{.</span><div class="pragma">
    <span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">raises</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span><span class="Other">,</span> <span class="Identifier">tags</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>A shape (seq of int), for example @[3,5] for a 3x5 matrix</li>
<li>Optionally rowMajor (C layout - default) or colMajor (Fortran)</li>
</ul>
</dd>
<dt>Returns:</dt>
<dd><ul class="simple"><li>The strides in C or Fortran order corresponding to this shape and layout</li>
</ul>
</dd>
</dl>
<p>Arraymancer defaults to rowMajor. Temporarily, CudaTensors are colMajor by default.</p>


</dd>
<dt id="is_C_contiguous"><a name="is_C_contiguous,AnyTensor"></a><pre><span class="Keyword">proc</span> <span class="Identifier">is_C_contiguous</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">AnyTensor</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">bool</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Check if the tensor follows C convention / is row major

</dd>
<dt id="is_F_contiguous"><a name="is_F_contiguous,AnyTensor"></a><pre><span class="Keyword">proc</span> <span class="Identifier">is_F_contiguous</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">AnyTensor</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">bool</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Check if the tensor follows Fortran convention / is column major

</dd>
<dt id="isContiguous"><a name="isContiguous,AnyTensor"></a><pre><span class="Keyword">proc</span> <span class="Identifier">isContiguous</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">AnyTensor</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">bool</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Check if the tensor is contiguous

</dd>
<dt id="unsafeView"><a name="unsafeView,Tensor[T]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">unsafeView</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>A tensor</li>
</ul>
</dd>
<dt>Returns:</dt>
<dd><ul class="simple"><li>A shallow copy. Both tensors share the same memory location.</li>
</ul>
</dd>
<dt>Warning </dt>
<dd>Both tensors shares the same memory. Data modification on one will be reflected on the other. However modifying the shape, strides or offset will not affect the other.</dd>
</dl>


</dd>
<dt id="newTensor"><a name="newTensor,openArray[int],typedesc"></a><pre><span class="Keyword">proc</span> <span class="Identifier">newTensor</span><span class="Other">(</span><span class="Identifier">shape</span><span class="Other">:</span> <span class="Identifier">openArray</span><span class="Other">[</span><span class="Identifier">int</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">typedesc</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Creates a new Tensor on Cpu backend<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>Shape of the Tensor</li>
<li>Type of its elements</li>
</ul>
</dd>
<dt>Result:</dt>
<dd><ul class="simple"><li>A Tensor of the proper shape initialized with the default type value (0 for numeric types) on Cpu backend</li>
</ul>
</dd>
</dl>


</dd>
<dt id="toTensor"><a name="toTensor,openArray,int"></a><pre><span class="Keyword">proc</span> <span class="Identifier">toTensor</span><span class="Other">(</span><span class="Identifier">s</span><span class="Other">:</span> <span class="Identifier">openArray</span><span class="Other">;</span> <span class="Identifier">dummy_bugfix</span><span class="Other">:</span> <span class="Keyword">static</span><span class="Other">[</span><span class="Identifier">int</span><span class="Other">]</span> <span class="Other">=</span> <span class="DecNumber">0</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">auto</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Convert an openarray to a Tensor<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>An array or a seq (can be nested)</li>
</ul>
</dd>
<dt>Result:</dt>
<dd><ul class="simple"><li>A Tensor of the same shape</li>
</ul>
</dd>
</dl>
<p>Note: dummy_bugfix param is unused and is a workaround a Nim bug.</p>


</dd>
<dt id="toTensor"><a name="toTensor,string"></a><pre><span class="Keyword">proc</span> <span class="Identifier">toTensor</span><span class="Other">(</span><span class="Identifier">s</span><span class="Other">:</span> <span class="Identifier">string</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">auto</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">raises</span><span class="Other">:</span> <span class="Other">[</span><span class="Identifier">IndexError</span><span class="Other">]</span><span class="Other">,</span> <span class="Identifier">tags</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Convert a string to a Tensor</p>
<p>This proc handles string specifically as otherwise they are interpreted as a sequence of char</p>


</dd>
<dt id="zeros"><a name="zeros,openArray[int],typedesc[T]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">zeros</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeNumber</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">shape</span><span class="Other">:</span> <span class="Identifier">openArray</span><span class="Other">[</span><span class="Identifier">int</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">typ</span><span class="Other">:</span> <span class="Identifier">typedesc</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> <span class="Other pragmabegin">{.</span><div class="pragma">
    <span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Creates a new Tensor filled with 0<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>Shape of the Tensor</li>
<li>Type of its elements</li>
</ul>
</dd>
<dt>Result:</dt>
<dd><ul class="simple"><li>A zero-ed Tensor of the input shape on backend Cpu</li>
</ul>
</dd>
</dl>


</dd>
<dt id="zeros_like"><a name="zeros_like,Tensor[T: SomeNumber]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">zeros_like</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeNumber</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Creates a new Tensor filled with 0 with the same shape as the input<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>Shape of the Tensor</li>
<li>Type of its elements</li>
</ul>
</dd>
<dt>Result:</dt>
<dd><ul class="simple"><li>A zero-ed Tensor of the same shape</li>
</ul>
</dd>
</dl>


</dd>
<dt id="ones"><a name="ones,openArray[int],typedesc[T]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">ones</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeNumber</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">shape</span><span class="Other">:</span> <span class="Identifier">openArray</span><span class="Other">[</span><span class="Identifier">int</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">typ</span><span class="Other">:</span> <span class="Identifier">typedesc</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> <span class="Other pragmabegin">{.</span><div class="pragma">
    <span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Creates a new Tensor filled with 1<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>Shape of the Tensor</li>
<li>Type of its elements</li>
</ul>
</dd>
<dt>Result:</dt>
<dd><ul class="simple"><li>A one-ed Tensor of the same shape</li>
</ul>
</dd>
</dl>


</dd>
<dt id="ones_like"><a name="ones_like,AnyTensor[T: SomeNumber]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">ones_like</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeNumber</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">AnyTensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">auto</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Creates a new Tensor filled with 0 with the same shape as the input and filled with 1<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>Tensor</li>
</ul>
</dd>
<dt>Result:</dt>
<dd><ul class="simple"><li>A one-ed Tensor of the same shape</li>
</ul>
</dd>
</dl>


</dd>
<dt id="randomTensor"><a name="randomTensor,openArray[int],float"></a><pre><span class="Keyword">proc</span> <span class="Identifier">randomTensor</span><span class="Other">(</span><span class="Identifier">shape</span><span class="Other">:</span> <span class="Identifier">openArray</span><span class="Other">[</span><span class="Identifier">int</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">max</span><span class="Other">:</span> <span class="Identifier">float</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">float</span><span class="Other">]</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">raises</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span><span class="Other">,</span>
    <span class="Identifier">tags</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Creates a new float Tensor filled with values between 0 and max.</p>
<p>Random seed can be set by importing <tt class="docutils literal"><span class="pre">random</span></tt> and <tt class="docutils literal"><span class="pre">randomize(seed)</span></tt></p>
<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>a shape</li>
<li>the max value possible (float)</li>
<li>a tensor backend</li>
</ul>
</dd>
<dt>Result:</dt>
<dd><ul class="simple"><li>A tensor of the input shape filled with random value between 0 and max input value</li>
</ul>
</dd>
</dl>


</dd>
<dt id="randomTensor"><a name="randomTensor,openArray[int],int"></a><pre><span class="Keyword">proc</span> <span class="Identifier">randomTensor</span><span class="Other">(</span><span class="Identifier">shape</span><span class="Other">:</span> <span class="Identifier">openArray</span><span class="Other">[</span><span class="Identifier">int</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">max</span><span class="Other">:</span> <span class="Identifier">int</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">int</span><span class="Other">]</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">raises</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span><span class="Other">,</span> <span class="Identifier">tags</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Creates a new int Tensor filled with values between 0 and max-1.</p>
<p>Random seed can be set by importing <tt class="docutils literal"><span class="pre">random</span></tt> and <tt class="docutils literal"><span class="pre">randomize(seed)</span></tt></p>
<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>a shape</li>
<li>the max value possible (integer, exclusive)</li>
<li>a tensor backend</li>
</ul>
</dd>
<dt>Result:</dt>
<dd><ul class="simple"><li>A tensor of the input shape filled with random value between 0 and max input value (excluded)</li>
</ul>
</dd>
</dl>


</dd>
<dt id="randomTensor"><a name="randomTensor,openArray[int],Slice[T]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">randomTensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">shape</span><span class="Other">:</span> <span class="Identifier">openArray</span><span class="Other">[</span><span class="Identifier">int</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">slice</span><span class="Other">:</span> <span class="Identifier">Slice</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span></pre></dt>
<dd>
<p>Creates a new int Tensor filled with values in the Slice range.</p>
<p>Random seed can be set by importing <tt class="docutils literal"><span class="pre">random</span></tt> and <tt class="docutils literal"><span class="pre">randomize(seed)</span></tt></p>
<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>a shape</li>
<li>a range/slice</li>
<li>a tensor backend</li>
</ul>
</dd>
<dt>Result:</dt>
<dd><ul class="simple"><li>A tensor of the input shape filled with random value in the slice range</li>
</ul>
</dd>
</dl>


</dd>
<dt id="newTensor"><a name="newTensor,openArray[int],typedesc,"></a><pre><span class="Keyword">proc</span> <span class="Identifier">newTensor</span><span class="Other">(</span><span class="Identifier">shape</span><span class="Other">:</span> <span class="Identifier">openArray</span><span class="Other">[</span><span class="Identifier">int</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">typedesc</span><span class="Other">;</span> <span class="Identifier">backend</span><span class="Other">:</span> <span class="Keyword">static</span><span class="Other">[</span><span class="Identifier">Backend</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">auto</span> <span class="Other pragmabegin">{.</span><div class="pragma">
    <span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">deprecated</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>DEPRECATED - The backend: static[Backend] argument has been deprecated for easier maintenance.</p>
<p>Creates a new Tensor</p>
<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>Shape of the Tensor</li>
<li>Type of its elements</li>
<li>Backend</li>
</ul>
</dd>
<dt>Result:</dt>
<dd><ul class="simple"><li>A Tensor of the proper shape initialized with the default type value (0 for numeric types)</li>
</ul>
</dd>
</dl>


</dd>
<dt id="toTensor"><a name="toTensor,openArray,"></a><pre><span class="Keyword">proc</span> <span class="Identifier">toTensor</span><span class="Other">(</span><span class="Identifier">s</span><span class="Other">:</span> <span class="Identifier">openArray</span><span class="Other">;</span> <span class="Identifier">backend</span><span class="Other">:</span> <span class="Keyword">static</span><span class="Other">[</span><span class="Identifier">Backend</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">auto</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">deprecated</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>DEPRECATED - The backend: static[Backend] argument has been deprecated for easier maintenance.</p>
<p>Convert an openarray to a Tensor</p>


</dd>
<dt id="toTensor"><a name="toTensor,string,"></a><pre><span class="Keyword">proc</span> <span class="Identifier">toTensor</span><span class="Other">(</span><span class="Identifier">s</span><span class="Other">:</span> <span class="Identifier">string</span><span class="Other">;</span> <span class="Identifier">backend</span><span class="Other">:</span> <span class="Keyword">static</span><span class="Other">[</span><span class="Identifier">Backend</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">auto</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">deprecated</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>DEPRECATED - The backend: static[Backend] argument has been deprecated for easier maintenance.</p>
<p>Convert an openarray to a Tensor</p>
<p>Handle string specifically (otherwise they are interpreted as openarray[char])</p>


</dd>
<dt id="zeros"><a name="zeros,openArray[int],typedesc[T],"></a><pre><span class="Keyword">proc</span> <span class="Identifier">zeros</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeNumber</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">shape</span><span class="Other">:</span> <span class="Identifier">openArray</span><span class="Other">[</span><span class="Identifier">int</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">typ</span><span class="Other">:</span> <span class="Identifier">typedesc</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span>
                        <span class="Identifier">backend</span><span class="Other">:</span> <span class="Keyword">static</span><span class="Other">[</span><span class="Identifier">Backend</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">auto</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">deprecated</span><span class="Other">,</span> <span class="Identifier">noSideEffect</span><span class="Other">,</span>
    <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
DEPRECATED - The backend: static[Backend] argument has been deprecated for easier maintenance.<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>Shape of the Tensor</li>
<li>Type of its elements</li>
<li>Backend</li>
</ul>
</dd>
<dt>Result:</dt>
<dd><ul class="simple"><li>A zero-ed Tensor of the input shape</li>
</ul>
</dd>
</dl>


</dd>
<dt id="ones"><a name="ones,openArray[int],typedesc[T],"></a><pre><span class="Keyword">proc</span> <span class="Identifier">ones</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeNumber</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">shape</span><span class="Other">:</span> <span class="Identifier">openArray</span><span class="Other">[</span><span class="Identifier">int</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">typ</span><span class="Other">:</span> <span class="Identifier">typedesc</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span>
                       <span class="Identifier">backend</span><span class="Other">:</span> <span class="Keyword">static</span><span class="Other">[</span><span class="Identifier">Backend</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">auto</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">deprecated</span><span class="Other">,</span> <span class="Identifier">noSideEffect</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>DEPRECATED - The backend: static[Backend] argument has been deprecated for easier maintenance.</p>
<p>Creates a new Tensor filled with 1</p>
<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>Shape of the Tensor</li>
<li>Type of its elements</li>
<li>Backend</li>
</ul>
</dd>
<dt>Result:</dt>
<dd><ul class="simple"><li>A one-ed Tensor of the same shape</li>
</ul>
</dd>
</dl>


</dd>
<dt id="randomTensor"><a name="randomTensor,openArray[int],float,"></a><pre><span class="Keyword">proc</span> <span class="Identifier">randomTensor</span><span class="Other">(</span><span class="Identifier">shape</span><span class="Other">:</span> <span class="Identifier">openArray</span><span class="Other">[</span><span class="Identifier">int</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">max</span><span class="Other">:</span> <span class="Identifier">float</span><span class="Other">;</span> <span class="Identifier">backend</span><span class="Other">:</span> <span class="Keyword">static</span><span class="Other">[</span><span class="Identifier">Backend</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">auto</span> <span class="Other pragmabegin">{.</span><div class="pragma">
    <span class="Identifier">deprecated</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>DEPRECATED - The backend: static[Backend] argument has been deprecated for easier maintenance.</p>
<p>Creates a new float Tensor filled with values between 0 and max.</p>
<p>Random seed can be set by importing <tt class="docutils literal"><span class="pre">random</span></tt> and <tt class="docutils literal"><span class="pre">randomize(seed)</span></tt></p>
<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>a shape</li>
<li>the max value possible (float)</li>
<li>a tensor backend</li>
</ul>
</dd>
<dt>Result:</dt>
<dd><ul class="simple"><li>A tensor of the input shape filled with random value between 0 and max input value</li>
</ul>
</dd>
</dl>


</dd>
<dt id="randomTensor"><a name="randomTensor,openArray[int],int,"></a><pre><span class="Keyword">proc</span> <span class="Identifier">randomTensor</span><span class="Other">(</span><span class="Identifier">shape</span><span class="Other">:</span> <span class="Identifier">openArray</span><span class="Other">[</span><span class="Identifier">int</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">max</span><span class="Other">:</span> <span class="Identifier">int</span><span class="Other">;</span> <span class="Identifier">backend</span><span class="Other">:</span> <span class="Keyword">static</span><span class="Other">[</span><span class="Identifier">Backend</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">auto</span> <span class="Other pragmabegin">{.</span><div class="pragma">
    <span class="Identifier">deprecated</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>DEPRECATED - The backend: static[Backend] argument has been deprecated for easier maintenance.</p>
<p>Creates a new int Tensor filled with values between 0 and max-1.</p>
<p>Random seed can be set by importing <tt class="docutils literal"><span class="pre">random</span></tt> and <tt class="docutils literal"><span class="pre">randomize(seed)</span></tt></p>
<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>a shape</li>
<li>the max value possible (integer, exclusive)</li>
<li>a tensor backend</li>
</ul>
</dd>
<dt>Result:</dt>
<dd><ul class="simple"><li>A tensor of the input shape filled with random value between 0 and max input value (excluded)</li>
</ul>
</dd>
</dl>


</dd>
<dt id="randomTensor"><a name="randomTensor,openArray[int],Slice[T],"></a><pre><span class="Keyword">proc</span> <span class="Identifier">randomTensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">shape</span><span class="Other">:</span> <span class="Identifier">openArray</span><span class="Other">[</span><span class="Identifier">int</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">slice</span><span class="Other">:</span> <span class="Identifier">Slice</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">B</span><span class="Other">:</span> <span class="Keyword">static</span><span class="Other">[</span><span class="Identifier">Backend</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">auto</span> <span class="Other pragmabegin">{.</span><div class="pragma">
    <span class="Identifier">deprecated</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>DEPRECATED - The backend: static[Backend] argument has been deprecated for easier maintenance.</p>
<p>Creates a new int Tensor filled with values in the Slice range.</p>
<p>Random seed can be set by importing <tt class="docutils literal"><span class="pre">random</span></tt> and <tt class="docutils literal"><span class="pre">randomize(seed)</span></tt></p>
<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>a shape</li>
<li>a range/slice</li>
<li>a tensor backend</li>
</ul>
</dd>
<dt>Result:</dt>
<dd><ul class="simple"><li>A tensor of the input shape filled with random value in the slice range</li>
</ul>
</dd>
</dl>


</dd>
<dt id="values"><a name="values,Tensor[T]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">values</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">auto</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Creates an closure iterator on Tensor values.</p>
<p>The iterator will iterate in C order regardingless of the tensor properties (Fortran layout, non-contiguous, slice ...). So [0, 0, 0] then [0, 0, 1] then ... then [0, 1, 0] ...</p>
<p>A closure iterator must be assigned to an iterator variable first.</p>
<dl class="docutils"><dt>Usage:</dt>
<dd><pre class="listing"><span class="Keyword">let</span> <span class="Identifier">it</span> <span class="Operator">=</span> <span class="Identifier">t</span><span class="Operator">.</span><span class="Identifier">values</span>
<span class="Keyword">for</span> <span class="Identifier">val</span> <span class="Keyword">in</span> <span class="Identifier">it</span><span class="Punctuation">(</span><span class="Punctuation">)</span><span class="Punctuation">:</span>
  <span class="Comment"># do stuff</span></pre></dd>
</dl>
<p>Note: This is mostly useful for iterator chaining. Prefer the inline iterator <tt class="docutils literal"><span class="pre">items</span></tt> for simple iteration.</p>
<blockquote><p><pre class="listing"><span class="Keyword">for</span> <span class="Identifier">val</span> <span class="Keyword">in</span> <span class="Identifier">t</span><span class="Punctuation">:</span> <span class="Comment"># The `for` loop call the items iterator implicitly.</span>
  <span class="Comment"># do stuff</span></pre></p></blockquote>
<p>Contrary to other ndarray packages looping in Arraymancer is not slow.</p>


</dd>
<dt id="axis"><a name="axis,Tensor[T],int"></a><pre><span class="Keyword">proc</span> <span class="Identifier">axis</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">axis</span><span class="Other">:</span> <span class="Identifier">int</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">auto</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Closure iterator on axis</p>
<p>A closure iterator must be assigned to an iterator variable first.</p>
<dl class="docutils"><dt>Usage:</dt>
<dd><pre class="listing"><span class="Keyword">let</span> <span class="Identifier">it</span> <span class="Operator">=</span> <span class="Identifier">t</span><span class="Operator">.</span><span class="Identifier">axis</span><span class="Punctuation">(</span><span class="DecNumber">1</span><span class="Punctuation">)</span>
<span class="Keyword">for</span> <span class="Identifier">subtensor</span> <span class="Keyword">in</span> <span class="Identifier">it</span><span class="Punctuation">(</span><span class="Punctuation">)</span><span class="Punctuation">:</span>
  <span class="Comment"># do stuff</span></pre></dd>
</dl>
<p>Note: This is mostly useful for iterator chaining. Prefer the inline iterator <tt class="docutils literal"><span class="pre">axis</span></tt> for simple iteration.</p>


</dd>
<dt id="|"><a name="|,Slice[int],int"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`|`</span><span class="Other">(</span><span class="Identifier">s</span><span class="Other">:</span> <span class="Identifier">Slice</span><span class="Other">[</span><span class="Identifier">int</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">step</span><span class="Other">:</span> <span class="Identifier">int</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">SteppedSlice</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span><span class="Other">,</span> <span class="Identifier">raises</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span><span class="Other">,</span>
    <span class="Identifier">tags</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Internal: A <tt class="docutils literal"><span class="pre">SteppedSlice</span></tt> constructor<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>a slice</li>
<li>a step</li>
</ul>
</dd>
<dt>Returns:</dt>
<dd><ul class="simple"><li>a <tt class="docutils literal"><span class="pre">SteppedSlice</span></tt></li>
</ul>
</dd>
</dl>


</dd>
<dt id="|"><a name="|,int,int"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`|`</span><span class="Other">(</span><span class="Identifier">b</span><span class="Other">,</span> <span class="Identifier">step</span><span class="Other">:</span> <span class="Identifier">int</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Step</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span><span class="Other">,</span> <span class="Identifier">raises</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span><span class="Other">,</span> <span class="Identifier">tags</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Internal: A <tt class="docutils literal"><span class="pre">Step</span></tt> constructor</p>
<p><tt class="docutils literal"><span class="pre">Step</span></tt> is a workaround due to operator precedence.</p>
<p>[0..10|1] is interpreted as [0..(10|1)]</p>
<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>the end of a slice range</li>
<li>a step</li>
</ul>
</dd>
<dt>Returns:</dt>
<dd><ul class="simple"><li>a <tt class="docutils literal"><span class="pre">Step</span></tt></li>
</ul>
</dd>
</dl>


</dd>
<dt id="|"><a name="|,SteppedSlice,int"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`|`</span><span class="Other">(</span><span class="Identifier">ss</span><span class="Other">:</span> <span class="Identifier">SteppedSlice</span><span class="Other">;</span> <span class="Identifier">step</span><span class="Other">:</span> <span class="Identifier">int</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">SteppedSlice</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span><span class="Other">,</span> <span class="Identifier">raises</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span><span class="Other">,</span>
    <span class="Identifier">tags</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Internal: Modifies the step of a <tt class="docutils literal"><span class="pre">SteppedSlice</span></tt><dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>a <tt class="docutils literal"><span class="pre">SteppedSLice</span></tt></li>
<li>the new stepping</li>
</ul>
</dd>
<dt>Returns:</dt>
<dd><ul class="simple"><li>a <tt class="docutils literal"><span class="pre">SteppedSLice</span></tt></li>
</ul>
</dd>
</dl>


</dd>
<dt id="|+"><a name="|+,Slice[int],int"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`|+`</span><span class="Other">(</span><span class="Identifier">s</span><span class="Other">:</span> <span class="Identifier">Slice</span><span class="Other">[</span><span class="Identifier">int</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">step</span><span class="Other">:</span> <span class="Identifier">int</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">SteppedSlice</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span><span class="Other">,</span> <span class="Identifier">raises</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span><span class="Other">,</span>
    <span class="Identifier">tags</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Internal: Alias for <tt class="docutils literal"><span class="pre">|</span></tt>

</dd>
<dt id="|+"><a name="|+,int,int"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`|+`</span><span class="Other">(</span><span class="Identifier">b</span><span class="Other">,</span> <span class="Identifier">step</span><span class="Other">:</span> <span class="Identifier">int</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Step</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span><span class="Other">,</span> <span class="Identifier">raises</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span><span class="Other">,</span> <span class="Identifier">tags</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Internal: Alias for <tt class="docutils literal"><span class="pre">|</span></tt>

</dd>
<dt id="|+"><a name="|+,SteppedSlice,int"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`|+`</span><span class="Other">(</span><span class="Identifier">ss</span><span class="Other">:</span> <span class="Identifier">SteppedSlice</span><span class="Other">;</span> <span class="Identifier">step</span><span class="Other">:</span> <span class="Identifier">int</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">SteppedSlice</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span><span class="Other">,</span> <span class="Identifier">raises</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span><span class="Other">,</span>
    <span class="Identifier">tags</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Internal: Alias for <tt class="docutils literal"><span class="pre">|</span></tt>

</dd>
<dt id="|-"><a name="|-,Slice[int],int"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`|-`</span><span class="Other">(</span><span class="Identifier">s</span><span class="Other">:</span> <span class="Identifier">Slice</span><span class="Other">[</span><span class="Identifier">int</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">step</span><span class="Other">:</span> <span class="Identifier">int</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">SteppedSlice</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span><span class="Other">,</span> <span class="Identifier">raises</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span><span class="Other">,</span>
    <span class="Identifier">tags</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Internal: A <tt class="docutils literal"><span class="pre">SteppedSlice</span></tt> constructor</p>
<p>Workaround to tensor[slice|-1] being interpreted as [slice <cite>|-</cite> 1]</p>
<p>Properly create <tt class="docutils literal"><span class="pre">SteppedSLice</span></tt> with negative stepping</p>


</dd>
<dt id="|-"><a name="|-,int,int"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`|-`</span><span class="Other">(</span><span class="Identifier">b</span><span class="Other">,</span> <span class="Identifier">step</span><span class="Other">:</span> <span class="Identifier">int</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Step</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span><span class="Other">,</span> <span class="Identifier">raises</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span><span class="Other">,</span> <span class="Identifier">tags</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Internal: A <tt class="docutils literal"><span class="pre">SteppedSlice</span></tt> constructor</p>
<p>Workaround to tensor[0..10|-1] being intepreted as [0 .. (10 <cite>|-</cite> 1)]</p>
<p>Properly create <tt class="docutils literal"><span class="pre">SteppedSLice</span></tt> with negative stepping</p>


</dd>
<dt id="|-"><a name="|-,SteppedSlice,int"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`|-`</span><span class="Other">(</span><span class="Identifier">ss</span><span class="Other">:</span> <span class="Identifier">SteppedSlice</span><span class="Other">;</span> <span class="Identifier">step</span><span class="Other">:</span> <span class="Identifier">int</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">SteppedSlice</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span><span class="Other">,</span> <span class="Identifier">raises</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span><span class="Other">,</span>
    <span class="Identifier">tags</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Internal: Modifies the step of a <tt class="docutils literal"><span class="pre">SteppedSlice</span></tt></p>
<p>Workaround to tensor[slice|-1] being interpreted as [slice <cite>|-</cite> 1]</p>
<p>Properly create <tt class="docutils literal"><span class="pre">SteppedSLice</span></tt> with negative stepping</p>


</dd>
<dt id=".."><a name="..,int,Step"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`..`</span><span class="Other">(</span><span class="Identifier">a</span><span class="Other">:</span> <span class="Identifier">int</span><span class="Other">;</span> <span class="Identifier">s</span><span class="Other">:</span> <span class="Identifier">Step</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">SteppedSlice</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span><span class="Other">,</span> <span class="Identifier">raises</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span><span class="Other">,</span> <span class="Identifier">tags</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Internal: Build a SteppedSlice from [a .. (b|step)] (workaround to operator precedence)<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>the beginning of the slice range</li>
<li>a <tt class="docutils literal"><span class="pre">Step</span></tt> workaround object</li>
</ul>
</dd>
<dt>Returns:</dt>
<dd><ul class="simple"><li>a <tt class="docutils literal"><span class="pre">SteppedSlice</span></tt>, end of range will be inclusive</li>
</ul>
</dd>
</dl>


</dd>
<dt id="..<"><a name="..<,int,Step"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`..&lt;`</span><span class="Other">(</span><span class="Identifier">a</span><span class="Other">:</span> <span class="Identifier">int</span><span class="Other">;</span> <span class="Identifier">s</span><span class="Other">:</span> <span class="Identifier">Step</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">SteppedSlice</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span><span class="Other">,</span> <span class="Identifier">raises</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span><span class="Other">,</span> <span class="Identifier">tags</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Internal: Build a SteppedSlice from [a ..&lt; (b|step)] (workaround to operator precedence and ..&lt;b not being interpreted as .. &lt;b)<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>the beginning of the slice range</li>
<li>a <tt class="docutils literal"><span class="pre">Step</span></tt> workaround object</li>
</ul>
</dd>
<dt>Returns:</dt>
<dd><ul class="simple"><li>a <tt class="docutils literal"><span class="pre">SteppedSlice</span></tt>, end of range will be exclusive.</li>
</ul>
</dd>
</dl>


</dd>
<dt id="..^"><a name="..^,int,Step"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`..^`</span><span class="Other">(</span><span class="Identifier">a</span><span class="Other">:</span> <span class="Identifier">int</span><span class="Other">;</span> <span class="Identifier">s</span><span class="Other">:</span> <span class="Identifier">Step</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">SteppedSlice</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span><span class="Other">,</span> <span class="Identifier">raises</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span><span class="Other">,</span> <span class="Identifier">tags</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Internal: Build a SteppedSlice from [a ..^ (b|step)] (workaround to operator precedence and ..^b not being interpreted as .. ^b)<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>the beginning of the slice range</li>
<li>a <tt class="docutils literal"><span class="pre">Step</span></tt> workaround object</li>
</ul>
</dd>
<dt>Returns:</dt>
<dd><ul class="simple"><li>a <tt class="docutils literal"><span class="pre">SteppedSlice</span></tt>, end of range will start at &quot;b&quot; away from the end</li>
</ul>
</dd>
</dl>


</dd>
<dt id="^"><a name="^,SteppedSlice"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`^`</span><span class="Other">(</span><span class="Identifier">s</span><span class="Other">:</span> <span class="Identifier">SteppedSlice</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">SteppedSlice</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span><span class="Other">,</span> <span class="Identifier">raises</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span><span class="Other">,</span> <span class="Identifier">tags</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Internal: Prefix to a to indicate starting the slice at &quot;a&quot; away from the end Note: This does not automatically inverse stepping, what if we want ^5..^1

</dd>
<dt id="^"><a name="^,Slice"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`^`</span><span class="Other">(</span><span class="Identifier">s</span><span class="Other">:</span> <span class="Identifier">Slice</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">SteppedSlice</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Internal: Prefix to a to indicate starting the slice at &quot;a&quot; away from the end Note: This does not automatically inverse stepping, what if we want ^5..^1

</dd>
<dt id="=="><a name="==,Tensor[T],Tensor[T]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`==`</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">a</span><span class="Other">,</span> <span class="Identifier">b</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">bool</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Tensor comparison

</dd>
<dt id="transpose"><a name="transpose,Tensor"></a><pre><span class="Keyword">proc</span> <span class="Identifier">transpose</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Transpose a Tensor.</p>
<p>For N-d Tensor with shape (0, 1, 2 ... n-1) the resulting tensor will have shape (n-1, ... 2, 1, 0)</p>
<p>Data is copied as-is and not modified.</p>


</dd>
<dt id="unsafeTranspose"><a name="unsafeTranspose,Tensor"></a><pre><span class="Keyword">proc</span> <span class="Identifier">unsafeTranspose</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Transpose a Tensor without copy.<dl class="docutils"><dt>Warning :</dt>
<dd>This is a no-copy operation, data is shared with the input. This proc does not guarantee that a <tt class="docutils literal"><span class="pre">let</span></tt> value is immutable.</dd>
</dl>
<p>For N-d Tensor with shape (0, 1, 2 ... n-1) the resulting tensor will have shape (n-1, ... 2, 1, 0)</p>


</dd>
<dt id="asContiguous"><a name="asContiguous,Tensor[T],OrderType,bool"></a><pre><span class="Keyword">proc</span> <span class="Identifier">asContiguous</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">layout</span><span class="Other">:</span> <span class="Identifier">OrderType</span> <span class="Other">=</span> <span class="Identifier">rowMajor</span><span class="Other">;</span> <span class="Identifier">force</span><span class="Other">:</span> <span class="Identifier">bool</span> <span class="Other">=</span> <span class="Identifier">false</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span>
    <span class="Identifier">T</span><span class="Other">]</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Transform a tensor with general striding to a Tensor with contiguous layout.</p>
<p>By default tensor will be rowMajor.</p>
<p>By default nothing is done if the tensor is already contiguous (C Major or F major) The &quot;force&quot; parameter can force re-ordering to a specific layout</p>


</dd>
<dt id="unsafeContiguous"><a name="unsafeContiguous,Tensor[T],OrderType,bool"></a><pre><span class="Keyword">proc</span> <span class="Identifier">unsafeContiguous</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">layout</span><span class="Other">:</span> <span class="Identifier">OrderType</span> <span class="Other">=</span> <span class="Identifier">rowMajor</span><span class="Other">;</span>
                        <span class="Identifier">force</span><span class="Other">:</span> <span class="Identifier">bool</span> <span class="Other">=</span> <span class="Identifier">false</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Transform a tensor with general striding to a Tensor with contiguous layout.</p>
<p>If the tensor is already contiguous it is returned without copy, underlying data is shared between the input and the output.</p>
<dl class="docutils"><dt>Warning :</dt>
<dd>This may be a no-copy operation with result data shared with the input. This proc does not guarantee that a <tt class="docutils literal"><span class="pre">let</span></tt> value is immutable.</dd>
</dl>
<p>By default tensor will be rowMajor.</p>
<p>By default nothing is done if the tensor is already contiguous (C Major or F major) The &quot;force&quot; parameter can force re-ordering to a specific layout</p>


</dd>
<dt id="reshape"><a name="reshape,Tensor,varargs[int]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">reshape</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">;</span> <span class="Identifier">new_shape</span><span class="Other">:</span> <span class="Identifier">varargs</span><span class="Other">[</span><span class="Identifier">int</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Reshape a tensor<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>a tensor</li>
<li>a new shape. Number of elements must be the same</li>
</ul>
</dd>
<dt>Returns:</dt>
<dd><ul class="simple"><li>a tensor with the same data but reshaped.</li>
</ul>
</dd>
</dl>


</dd>
<dt id="unsafeReshape"><a name="unsafeReshape,Tensor,varargs[int]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">unsafeReshape</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">;</span> <span class="Identifier">new_shape</span><span class="Other">:</span> <span class="Identifier">varargs</span><span class="Other">[</span><span class="Identifier">int</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Reshape a tensor without copy.</p>
<p> Reshaping without copy is only possible on contiguous Tensors</p>
<dl class="docutils"><dt>Warning :</dt>
<dd>This is a no-copy operation, data is shared with the input. This proc does not guarantee that a <tt class="docutils literal"><span class="pre">let</span></tt> value is immutable.</dd>
</dl>


</dd>
<dt id="broadcast"><a name="broadcast,Tensor[T],openArray[int]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">broadcast</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">shape</span><span class="Other">:</span> <span class="Identifier">openArray</span><span class="Other">[</span><span class="Identifier">int</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Explicitly broadcast a tensor to the specified shape.</p>
<p>Dimension(s) of size 1 can be expanded to arbitrary size by replicating values along that dimension.</p>
<dl class="docutils"><dt>Warning :</dt>
<dd>A broadcasted tensor should not be modified and only used for computation.</dd>
</dl>


</dd>
<dt id="unsafeBroadcast"><a name="unsafeBroadcast,Tensor[T],openArray[int]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">unsafeBroadcast</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">shape</span><span class="Other">:</span> <span class="Identifier">openArray</span><span class="Other">[</span><span class="Identifier">int</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Explicitly broadcast a Tensor to the specified shape. The returned broadcasted Tensor share the underlying data with the input.</p>
<p>Dimension(s) of size 1 can be expanded to arbitrary size by replicating values along that dimension.</p>
<dl class="docutils"><dt>Warning :</dt>
<dd>This is a no-copy operation, data is shared with the input. This proc does not guarantee that a <tt class="docutils literal"><span class="pre">let</span></tt> value is immutable. A broadcasted tensor should not be modified and only used for computation.</dd>
</dl>


</dd>
<dt id="broadcast"><a name="broadcast,T,openArray[int]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">broadcast</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeNumber</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">val</span><span class="Other">:</span> <span class="Identifier">T</span><span class="Other">;</span> <span class="Identifier">shape</span><span class="Other">:</span> <span class="Identifier">openArray</span><span class="Other">[</span><span class="Identifier">int</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Broadcast a number<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>a number to be broadcasted</li>
<li>a tensor shape that will be broadcasted to</li>
</ul>
</dd>
<dt>Returns:</dt>
<dd><ul class="simple"><li>a tensor with the broadcasted shape where all elements has the broadcasted value</li>
</ul>
</dd>
</dl>
<p>The broadcasting is made using tensor data of size 1 and 0 strides, i.e. the operation is memory efficient.</p>
<dl class="docutils"><dt>Warning :</dt>
<dd>A broadcasted tensor should not be modified and only used for computation. Modifying any value from this broadcasted tensor will change all its values.</dd>
</dl>


</dd>
<dt id="permute"><a name="permute,Tensor,varargs[int]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">permute</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">;</span> <span class="Identifier">dims</span><span class="Other">:</span> <span class="Identifier">varargs</span><span class="Other">[</span><span class="Identifier">int</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Permute dimensions of a tensors<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>a tensor</li>
<li>the new dimension order</li>
</ul>
</dd>
<dt>Returns:</dt>
<dd><ul class="simple"><li>a tensor with re-order dimension</li>
</ul>
</dd>
<dt>Usage:</dt>
<dd><pre class="listing"><span class="Identifier">a</span><span class="Operator">.</span><span class="Identifier">permute</span><span class="Punctuation">(</span><span class="DecNumber">0</span><span class="Punctuation">,</span><span class="DecNumber">2</span><span class="Punctuation">,</span><span class="DecNumber">1</span><span class="Punctuation">)</span> <span class="Comment"># dim 0 stays at 0, dim 1 becomes dim 2 and dim 2 becomes dim 1</span></pre></dd>
</dl>


</dd>
<dt id="concat"><a name="concat,varargs[Tensor[T]],int"></a><pre><span class="Keyword">proc</span> <span class="Identifier">concat</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t_list</span><span class="Other">:</span> <span class="Identifier">varargs</span><span class="Other">[</span><span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">axis</span><span class="Other">:</span> <span class="Identifier">int</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Concatenate tensors<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>Tensors</li>
<li>An axis (dimension)</li>
</ul>
</dd>
<dt>Returns:</dt>
<dd><ul class="simple"><li>a tensor</li>
</ul>
</dd>
</dl>


</dd>
<dt id="squeeze"><a name="squeeze,AnyTensor"></a><pre><span class="Keyword">proc</span> <span class="Identifier">squeeze</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">AnyTensor</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">AnyTensor</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Squeeze tensors. For example a Tensor of shape @[4,1,3] will become @[4,3]<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>a tensor</li>
</ul>
</dd>
<dt>Returns:</dt>
<dd><ul class="simple"><li>a tensor with singleton dimensions collapsed</li>
</ul>
</dd>
</dl>


</dd>
<dt id="unsafeSqueeze"><a name="unsafeSqueeze,Tensor"></a><pre><span class="Keyword">proc</span> <span class="Identifier">unsafeSqueeze</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Squeeze tensors. For example a Tensor of shape @[4,1,3] will become @[4,3]<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>a tensor</li>
</ul>
</dd>
<dt>Returns:</dt>
<dd><ul class="simple"><li>a tensor with singleton dimensions collapsed that share the same underlying storage</li>
</ul>
</dd>
<dt>Warning :</dt>
<dd>This is a no-copy operation, data is shared with the input. This proc does not guarantee that a <tt class="docutils literal"><span class="pre">let</span></tt> value is immutable.</dd>
</dl>


</dd>
<dt id="squeeze"><a name="squeeze,AnyTensor,int"></a><pre><span class="Keyword">proc</span> <span class="Identifier">squeeze</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">AnyTensor</span><span class="Other">;</span> <span class="Identifier">axis</span><span class="Other">:</span> <span class="Identifier">int</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">AnyTensor</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Collapse the given axis, if the dimension is not 1, it does nothing.<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>a tensor</li>
<li>an axis (dimension)</li>
</ul>
</dd>
<dt>Returns:</dt>
<dd><ul class="simple"><li>a tensor with that axis collapsed, if it was a singleton dimension</li>
</ul>
</dd>
</dl>


</dd>
<dt id="unsafeSqueeze"><a name="unsafeSqueeze,Tensor,int"></a><pre><span class="Keyword">proc</span> <span class="Identifier">unsafeSqueeze</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">;</span> <span class="Identifier">axis</span><span class="Other">:</span> <span class="Identifier">int</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Collapse the given axis, if the dimension is not 1; it does nothing<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>a tensor</li>
<li>an axis (dimension)</li>
</ul>
</dd>
<dt>Returns:</dt>
<dd><ul class="simple"><li>a tensor with singleton dimensions collapsed</li>
</ul>
</dd>
<dt>Warning :</dt>
<dd>This is a no-copy operation, data is shared with the input. This proc does not guarantee that a <tt class="docutils literal"><span class="pre">let</span></tt> value is immutable.</dd>
</dl>


</dd>
<dt id="$"><a name="$,Tensor[T]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`$`</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">string</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Pretty-print a tensor (when using <tt class="docutils literal"><span class="pre">echo</span></tt> for example)

</dd>
<dt id="map"><a name="map,Tensor[T],"></a><pre><span class="Keyword">proc</span> <span class="Identifier">map</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">,</span> <span class="Identifier">U</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">f</span><span class="Other">:</span> <span class="Identifier">T</span> <span class="Operator">-&gt;</span> <span class="Identifier">U</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">U</span><span class="Other">]</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Apply a unary function in an element-wise manner on Tensor[T], returning a new Tensor.<dl class="docutils"><dt>Usage with Nim's <tt class="docutils literal"><span class="pre">future</span></tt> module:</dt>
<dd><pre class="listing"><span class="Identifier">a</span><span class="Operator">.</span><span class="Identifier">map</span><span class="Punctuation">(</span><span class="Identifier">x</span> <span class="Operator">=&gt;</span> <span class="Identifier">x</span><span class="Operator">+</span><span class="DecNumber">1</span><span class="Punctuation">)</span> <span class="Comment"># Map the anonymous function x =&gt; x+1</span></pre></dd>
<dt>Usage with named functions:</dt>
<dd><pre class="listing"><span class="Keyword">proc</span> <span class="Identifier">plusone</span><span class="Punctuation">[</span><span class="Identifier">T</span><span class="Punctuation">]</span><span class="Punctuation">(</span><span class="Identifier">x</span><span class="Punctuation">:</span> <span class="Identifier">T</span><span class="Punctuation">)</span><span class="Punctuation">:</span> <span class="Identifier">T</span> <span class="Operator">=</span>
  <span class="Identifier">x</span> <span class="Operator">+</span> <span class="DecNumber">1</span>
<span class="Identifier">a</span><span class="Operator">.</span><span class="Identifier">map</span><span class="Punctuation">(</span><span class="Identifier">plusone</span><span class="Punctuation">)</span> <span class="Comment"># Map the function plusone</span></pre></dd>
<dt>Note:</dt>
<dd>for basic operation, you can use implicit broadcasting instead with operators prefixed by a dot :</dd>
<dt></dt>
<dd><pre class="listing"><span class="Identifier">a</span> <span class="Operator">.+</span> <span class="DecNumber">1</span></pre></dd>
</dl>
<p><tt class="docutils literal"><span class="pre">map</span></tt> is especially useful to do multiple element-wise operations on a tensor in a single loop over the data.</p>


</dd>
<dt id="apply"><a name="apply,Tensor[T],"></a><pre><span class="Keyword">proc</span> <span class="Identifier">apply</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Keyword">var</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">f</span><span class="Other">:</span> <span class="Identifier">T</span> <span class="Operator">-&gt;</span> <span class="Identifier">T</span><span class="Other">)</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Apply a unary function in an element-wise manner on Tensor[T], in-place.<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>a var Tensor</li>
<li>A function or anonymous function that <tt class="docutils literal"><span class="pre">returns a value</span></tt></li>
</ul>
</dd>
<dt>Result:</dt>
<dd><ul class="simple"><li>Nothing, the <tt class="docutils literal"><span class="pre">var</span></tt> Tensor is modified in-place</li>
</ul>
</dd>
<dt>Usage with Nim's <tt class="docutils literal"><span class="pre">future</span></tt> module:</dt>
<dd><pre class="listing"><span class="Keyword">var</span> <span class="Identifier">a</span> <span class="Operator">=</span> <span class="Identifier">newTensor</span><span class="Punctuation">(</span><span class="Punctuation">[</span><span class="DecNumber">5</span><span class="Punctuation">,</span><span class="DecNumber">5</span><span class="Punctuation">]</span><span class="Punctuation">,</span> <span class="Identifier">int</span><span class="Punctuation">)</span> <span class="Comment"># a must be ``var``</span>
<span class="Identifier">a</span><span class="Operator">.</span><span class="Identifier">apply</span><span class="Punctuation">(</span><span class="Identifier">x</span> <span class="Operator">=&gt;</span> <span class="Identifier">x</span><span class="Operator">+</span><span class="DecNumber">1</span><span class="Punctuation">)</span> <span class="Comment"># Map the anonymous function x =&gt; x+1</span></pre></dd>
<dt>Usage with named functions:</dt>
<dd><pre class="listing"><span class="Keyword">proc</span> <span class="Identifier">plusone</span><span class="Punctuation">[</span><span class="Identifier">T</span><span class="Punctuation">]</span><span class="Punctuation">(</span><span class="Identifier">x</span><span class="Punctuation">:</span> <span class="Identifier">T</span><span class="Punctuation">)</span><span class="Punctuation">:</span> <span class="Identifier">T</span> <span class="Operator">=</span>
  <span class="Identifier">x</span> <span class="Operator">+</span> <span class="DecNumber">1</span>
<span class="Identifier">a</span><span class="Operator">.</span><span class="Identifier">apply</span><span class="Punctuation">(</span><span class="Identifier">plusone</span><span class="Punctuation">)</span> <span class="Comment"># Apply the function plusone in-place</span></pre></dd>
</dl>


</dd>
<dt id="apply"><a name="apply,Tensor[T],proc(T)"></a><pre><span class="Keyword">proc</span> <span class="Identifier">apply</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Keyword">var</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">f</span><span class="Other">:</span> <span class="Keyword">proc</span> <span class="Other">(</span><span class="Identifier">x</span><span class="Other">:</span> <span class="Keyword">var</span> <span class="Identifier">T</span><span class="Other">)</span><span class="Other">)</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Apply a unary function in an element-wise manner on Tensor[T], in-place.<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>a var Tensor</li>
<li>An in-place function that <tt class="docutils literal"><span class="pre">returns no value</span></tt></li>
</ul>
</dd>
<dt>Result:</dt>
<dd><ul class="simple"><li>Nothing, the <tt class="docutils literal"><span class="pre">var</span></tt> Tensor is modified in-place</li>
</ul>
</dd>
<dt>Usage with Nim's <tt class="docutils literal"><span class="pre">future</span></tt> module:</dt>
<dd><ul class="simple"><li>Future module has a functional programming paradigm, anonymous function cannot mutate the arguments</li>
</ul>
</dd>
<dt>Usage with named functions:</dt>
<dd><pre class="listing"><span class="Keyword">proc</span> <span class="Identifier">pluseqone</span><span class="Punctuation">[</span><span class="Identifier">T</span><span class="Punctuation">]</span><span class="Punctuation">(</span><span class="Identifier">x</span><span class="Punctuation">:</span> <span class="Keyword">var</span> <span class="Identifier">T</span><span class="Punctuation">)</span> <span class="Operator">=</span>
  <span class="Identifier">x</span> <span class="Operator">+=</span> <span class="DecNumber">1</span>
<span class="Identifier">a</span><span class="Operator">.</span><span class="Identifier">apply</span><span class="Punctuation">(</span><span class="Identifier">pluseqone</span><span class="Punctuation">)</span> <span class="Comment"># Apply the in-place function pluseqone</span></pre></dd>
</dl>
<p><tt class="docutils literal"><span class="pre">apply</span></tt> is especially useful to do multiple element-wise operations on a tensor in a single loop over the data.</p>


</dd>
<dt id="map2"><a name="map2,Tensor[T],,Tensor[U]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">map2</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">,</span> <span class="Identifier">U</span><span class="Other">,</span> <span class="Identifier">V</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t1</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">f</span><span class="Other">:</span> <span class="Other">(</span><span class="Identifier">T</span><span class="Other">,</span> <span class="Identifier">U</span><span class="Other">)</span> <span class="Operator">-&gt;</span> <span class="Identifier">V</span><span class="Other">;</span> <span class="Identifier">t2</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">U</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">V</span><span class="Other">]</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Apply a binary function in an element-wise manner on two Tensor[T], returning a new Tensor.</p>
<p>The function is applied on the elements with the same coordinates.</p>
<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>A tensor</li>
<li>A function</li>
<li>A tensor</li>
</ul>
</dd>
<dt>Result:</dt>
<dd><ul class="simple"><li>A new tensor</li>
</ul>
</dd>
<dt>Usage with named functions:</dt>
<dd><pre class="listing"><span class="Keyword">proc</span> <span class="Punctuation">`</span><span class="Operator">**</span><span class="Punctuation">`</span><span class="Punctuation">[</span><span class="Identifier">T</span><span class="Punctuation">]</span><span class="Punctuation">(</span><span class="Identifier">x</span><span class="Punctuation">,</span> <span class="Identifier">y</span><span class="Punctuation">:</span> <span class="Identifier">T</span><span class="Punctuation">)</span><span class="Punctuation">:</span> <span class="Identifier">T</span> <span class="Operator">=</span> <span class="Comment"># We create a new power `**` function that works on 2 scalars</span>
  <span class="Identifier">pow</span><span class="Punctuation">(</span><span class="Identifier">x</span><span class="Punctuation">,</span> <span class="Identifier">y</span><span class="Punctuation">)</span>
<span class="Identifier">a</span><span class="Operator">.</span><span class="Identifier">map2</span><span class="Punctuation">(</span><span class="Punctuation">`</span><span class="Operator">**</span><span class="Punctuation">`</span><span class="Punctuation">,</span> <span class="Identifier">b</span><span class="Punctuation">)</span>
<span class="Comment"># Or</span>
<span class="Identifier">map2</span><span class="Punctuation">(</span><span class="Identifier">a</span><span class="Punctuation">,</span> <span class="Punctuation">`</span><span class="Operator">**</span><span class="Punctuation">`</span><span class="Punctuation">,</span> <span class="Identifier">b</span><span class="Punctuation">)</span></pre></dd>
</dl>
<p><tt class="docutils literal"><span class="pre">map2</span></tt> is especially useful to do multiple element-wise operations on a two tensors in a single loop over the data. for example ```alpha * sin(A) + B```</p>


</dd>
<dt id="apply2"><a name="apply2,Tensor[T],proc(T,T),Tensor[U]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">apply2</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">,</span> <span class="Identifier">U</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">a</span><span class="Other">:</span> <span class="Keyword">var</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">f</span><span class="Other">:</span> <span class="Keyword">proc</span> <span class="Other">(</span><span class="Identifier">x</span><span class="Other">:</span> <span class="Keyword">var</span> <span class="Identifier">T</span><span class="Other">;</span> <span class="Identifier">y</span><span class="Other">:</span> <span class="Identifier">T</span><span class="Other">)</span><span class="Other">;</span> <span class="Identifier">b</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">U</span><span class="Other">]</span><span class="Other">)</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Apply a binary in-place function in an element-wise manner on two Tensor[T], returning a new Tensor.</p>
<p>The function is applied on the elements with the same coordinates.</p>
<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>A var tensor</li>
<li>A function</li>
<li>A tensor</li>
</ul>
</dd>
<dt>Result:</dt>
<dd><ul class="simple"><li>Nothing, the <tt class="docutils literal"><span class="pre">var``Tensor is modified in-place Usage with named functions: .. code:: nim proc `**=`[T](x, y: T) = # We create a new in-place power `**=` function that works on 2 scalars x = pow(x, y) a.apply2(`**=`, b) # Or apply2(a, `**=`, b) ``apply2</span></tt> is especially useful to do multiple element-wise operations on a two tensors in a single loop over the data.</li>
</ul>
</dd>
</dl>
<p>for example ```A += alpha * sin(A) + B```</p>


</dd>
<dt id="fold"><a name="fold,Tensor[U],T,"></a><pre><span class="Keyword">proc</span> <span class="Identifier">fold</span><span class="Other">[</span><span class="Identifier">U</span><span class="Other">,</span> <span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">U</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">start_val</span><span class="Other">:</span> <span class="Identifier">T</span><span class="Other">;</span> <span class="Identifier">f</span><span class="Other">:</span> <span class="Other">(</span><span class="Identifier">T</span><span class="Other">,</span> <span class="Identifier">U</span><span class="Other">)</span> <span class="Operator">-&gt;</span> <span class="Identifier">T</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">T</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Chain result = f(result, element) over all elements of the Tensor<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>A tensor to aggregate on</li>
<li>The starting value</li>
<li>The aggregation function. It is applied this way: new_aggregate = f(old_aggregate, current_value)</li>
</ul>
</dd>
<dt>Result:</dt>
<dd><ul class="simple"><li>An aggregate of the function called on the starting value and all elements of the tensor</li>
</ul>
</dd>
<dt>Usage:</dt>
<dd><pre class="listing"><span class="Identifier">a</span><span class="Operator">.</span><span class="Identifier">fold</span><span class="Punctuation">(</span><span class="DecNumber">100</span><span class="Punctuation">,</span><span class="Identifier">max</span><span class="Punctuation">)</span> <span class="Comment">## This compare 100 with the first tensor value and returns 100</span>
                <span class="Comment">## In the end, we will get the highest value in the Tensor or 100</span>
                <span class="Comment">## whichever is bigger.</span></pre></dd>
</dl>


</dd>
<dt id="fold"><a name="fold,Tensor[U],Tensor[T],,int"></a><pre><span class="Keyword">proc</span> <span class="Identifier">fold</span><span class="Other">[</span><span class="Identifier">U</span><span class="Other">,</span> <span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">U</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">start_val</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span>
              <span class="Identifier">f</span><span class="Other">:</span> <span class="Other">(</span><span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">,</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">U</span><span class="Other">]</span><span class="Other">)</span> <span class="Operator">-&gt;</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">axis</span><span class="Other">:</span> <span class="Identifier">int</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> <span class="Other pragmabegin">{.</span><div class="pragma">
    <span class="Identifier">noSideEffect</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Chain result = f(result, element) over all elements of the Tensor<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>A tensor to aggregate on</li>
<li>The starting value</li>
<li>The aggregation function. It is applied this way: new_aggregate = f(old_aggregate, current_value)</li>
<li>The axis to aggregate on</li>
</ul>
</dd>
<dt>Result:</dt>
<dd><ul class="simple"><li>An Tensor with the aggregate of the function called on the starting value and all slices along the selected axis</li>
</ul>
</dd>
</dl>


</dd>
<dt id="reduce"><a name="reduce,Tensor[T],"></a><pre><span class="Keyword">proc</span> <span class="Identifier">reduce</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">f</span><span class="Other">:</span> <span class="Other">(</span><span class="Identifier">T</span><span class="Other">,</span> <span class="Identifier">T</span><span class="Other">)</span> <span class="Operator">-&gt;</span> <span class="Identifier">T</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">T</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Chain result = f(result, element) over all elements of the Tensor.</p>
<p>The starting value is the first element of the Tensor.</p>
<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>A tensor to aggregate on</li>
<li>The aggregation function. It is applied this way: new_aggregate = f(old_aggregate, current_value)</li>
</ul>
</dd>
<dt>Result:</dt>
<dd><ul class="simple"><li>An aggregate of the function called all elements of the tensor</li>
</ul>
</dd>
<dt>Usage:</dt>
<dd><pre class="listing"><span class="Identifier">a</span><span class="Operator">.</span><span class="Identifier">reduce</span><span class="Punctuation">(</span><span class="Identifier">max</span><span class="Punctuation">)</span> <span class="Comment">## This returns the maximum value in the Tensor.</span></pre></dd>
</dl>


</dd>
<dt id="reduce"><a name="reduce,Tensor[T],,int"></a><pre><span class="Keyword">proc</span> <span class="Identifier">reduce</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">f</span><span class="Other">:</span> <span class="Other">(</span><span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">,</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span> <span class="Operator">-&gt;</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">axis</span><span class="Other">:</span> <span class="Identifier">int</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> <span class="Other pragmabegin">{.</span><div class="pragma">
    <span class="Identifier">noSideEffect</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Chain result = f(result, element) over all elements of the Tensor.</p>
<p>The starting value is the first element of the Tensor.</p>
<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>A tensor to aggregate on</li>
<li>The aggregation function. It is applied this way: new_aggregate = f(old_aggregate, current_value)</li>
<li>An axis to aggregate on</li>
</ul>
</dd>
<dt>Result:</dt>
<dd><ul class="simple"><li>A tensor aggregate of the function called all elements of the tensor</li>
</ul>
</dd>
</dl>


</dd>
<dt id="fmap"><a name="fmap,Tensor[T],"></a><pre><span class="Keyword">proc</span> <span class="Identifier">fmap</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">,</span> <span class="Identifier">U</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">f</span><span class="Other">:</span> <span class="Identifier">T</span> <span class="Operator">-&gt;</span> <span class="Identifier">U</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">U</span><span class="Other">]</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">deprecated</span><span class="Other">,</span> <span class="Identifier">inline</span><span class="Other">,</span> <span class="Identifier">noSideEffect</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>DEPRECATED</p>
<p>Replace by map2</p>


</dd>
<dt id="fmap2"><a name="fmap2,Tensor[T],Tensor[U],"></a><pre><span class="Keyword">proc</span> <span class="Identifier">fmap2</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">,</span> <span class="Identifier">U</span><span class="Other">,</span> <span class="Identifier">V</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t1</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">t2</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">U</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">f</span><span class="Other">:</span> <span class="Other">(</span><span class="Identifier">T</span><span class="Other">,</span> <span class="Identifier">U</span><span class="Other">)</span> <span class="Operator">-&gt;</span> <span class="Identifier">V</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">V</span><span class="Other">]</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">deprecated</span><span class="Other">,</span>
    <span class="Identifier">inline</span><span class="Other">,</span> <span class="Identifier">noSideEffect</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>DEPRECATED</p>
<p>Replaced by map2</p>
<p>Note the new argument order of map2 to accomodate for t1.map2(<cite>op</cite>, t2) where op is an infix operator.</p>


</dd>
<dt id="agg"><a name="agg,Tensor[T: SomeNumber],,T"></a><pre><span class="Keyword">proc</span> <span class="Identifier">agg</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeNumber</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">f</span><span class="Other">:</span> <span class="Other">(</span><span class="Identifier">T</span><span class="Other">,</span> <span class="Identifier">T</span><span class="Other">)</span> <span class="Operator">-&gt;</span> <span class="Identifier">T</span><span class="Other">;</span> <span class="Identifier">start_val</span><span class="Other">:</span> <span class="Identifier">T</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">T</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span>
    <span class="Identifier">inline</span><span class="Other">,</span> <span class="Identifier">deprecated</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>DEPRECATED, use fold instead.</p>
<p>Note: order between function f and start_val has changed</p>
<p>Compute the aggregate</p>
<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>A tensor to aggregate on</li>
<li>The aggregation function. It is applied this way: new_aggregate = f(old_aggregate, current_value)</li>
<li>The starting value</li>
<li>The axis</li>
</ul>
</dd>
</dl>


</dd>
<dt id="agg_inplace"><a name="agg_inplace,T,proc(T,T),Tensor[T: SomeNumber]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">agg_inplace</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeNumber</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">accum_val</span><span class="Other">:</span> <span class="Keyword">var</span> <span class="Identifier">T</span><span class="Other">;</span> <span class="Identifier">f</span><span class="Other">:</span> <span class="Keyword">proc</span> <span class="Other">(</span><span class="Identifier">x</span><span class="Other">:</span> <span class="Keyword">var</span> <span class="Identifier">T</span><span class="Other">;</span> <span class="Identifier">y</span><span class="Other">:</span> <span class="Identifier">T</span><span class="Other">)</span><span class="Other">;</span> <span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span> <span class="Other pragmabegin">{.</span><div class="pragma">
    <span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span><span class="Other">,</span> <span class="Identifier">deprecated</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>DEPRECATED, use fold instead.</p>
<p>You will have to switch to a non-inplace function.</p>
<p>Compute the aggregate</p>
<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>The accumulating value which will be modified in-place</li>
<li>The aggregation in-place function. It is applied this way: f(var old_aggregate, current_value)</li>
<li>A tensor to aggregate from</li>
<li>The axis</li>
</ul>
</dd>
</dl>


</dd>
<dt id="agg"><a name="agg,Tensor[T: SomeNumber],,Tensor[T: SomeNumber],int"></a><pre><span class="Keyword">proc</span> <span class="Identifier">agg</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeNumber</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">f</span><span class="Other">:</span> <span class="Other">(</span><span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">,</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span> <span class="Operator">-&gt;</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span>
                      <span class="Identifier">start_val</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">axis</span><span class="Other">:</span> <span class="Identifier">int</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span>
    <span class="Identifier">inline</span><span class="Other">,</span> <span class="Identifier">deprecated</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>DEPRECATED, use fold instead.</p>
<p>Note: order between function f and start_val has changed</p>
<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>A tensor to aggregate on</li>
<li>The aggregation function. It is applied this way: new_aggregate = f(old_aggregate, current_value)</li>
<li>The starting value</li>
<li>The axis</li>
</ul>
</dd>
</dl>


</dd>
<dt id="agg_inplace"><a name="agg_inplace,Tensor[T: SomeNumber],proc(Tensor[T: SomeNumber],Tensor[T: SomeNumber]),Tensor[T: SomeNumber],int"></a><pre><span class="Keyword">proc</span> <span class="Identifier">agg_inplace</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeNumber</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">accum_val</span><span class="Other">:</span> <span class="Keyword">var</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span>
                              <span class="Identifier">f</span><span class="Other">:</span> <span class="Keyword">proc</span> <span class="Other">(</span><span class="Identifier">x</span><span class="Other">:</span> <span class="Keyword">var</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">y</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">;</span> <span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span>
                              <span class="Identifier">axis</span><span class="Other">:</span> <span class="Identifier">int</span><span class="Other">)</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span><span class="Other">,</span> <span class="Identifier">deprecated</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>DEPRECATED, use fold instead.</p>
<p>You will have to switch to a non-inplace function.</p>
<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>The accumulating value which will be modified in-place</li>
<li>A tensor to aggregate from</li>
<li>The aggregation in-place function. It is applied this way: f(var old_aggregate, current_value)</li>
<li>The axis</li>
</ul>
</dd>
</dl>


</dd>
<dt id="astype"><a name="astype,Tensor[T],typedesc[U]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">astype</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">,</span> <span class="Identifier">U</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">typ</span><span class="Other">:</span> <span class="Identifier">typedesc</span><span class="Other">[</span><span class="Identifier">U</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">U</span><span class="Other">]</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Apply type conversion on the whole tensor

</dd>
<dt id="fac"><a name="fac,Tensor"></a><pre><span class="Keyword">proc</span> <span class="Identifier">fac</span><span class="Other">(</span><span class="Identifier">t</span><span class="DecNumber">150703</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Auto-generated universal version of the function.</p>
<p>The function can be used directly on tensors and will work element-wise.</p>


</dd>
<dt id="sqrt"><a name="sqrt,Tensor"></a><pre><span class="Keyword">proc</span> <span class="Identifier">sqrt</span><span class="Other">(</span><span class="Identifier">t</span><span class="DecNumber">150745</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Auto-generated universal version of the function.</p>
<p>The function can be used directly on tensors and will work element-wise.</p>


</dd>
<dt id="cbrt"><a name="cbrt,Tensor"></a><pre><span class="Keyword">proc</span> <span class="Identifier">cbrt</span><span class="Other">(</span><span class="Identifier">t</span><span class="DecNumber">150787</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Auto-generated universal version of the function.</p>
<p>The function can be used directly on tensors and will work element-wise.</p>


</dd>
<dt id="ln"><a name="ln,Tensor"></a><pre><span class="Keyword">proc</span> <span class="Identifier">ln</span><span class="Other">(</span><span class="Identifier">t</span><span class="DecNumber">150829</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Auto-generated universal version of the function.</p>
<p>The function can be used directly on tensors and will work element-wise.</p>


</dd>
<dt id="log10"><a name="log10,Tensor"></a><pre><span class="Keyword">proc</span> <span class="Identifier">log10</span><span class="Other">(</span><span class="Identifier">t</span><span class="DecNumber">150871</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Auto-generated universal version of the function.</p>
<p>The function can be used directly on tensors and will work element-wise.</p>


</dd>
<dt id="log2"><a name="log2,Tensor"></a><pre><span class="Keyword">proc</span> <span class="Identifier">log2</span><span class="Other">(</span><span class="Identifier">t</span><span class="DecNumber">150913</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Auto-generated universal version of the function.</p>
<p>The function can be used directly on tensors and will work element-wise.</p>


</dd>
<dt id="exp"><a name="exp,Tensor"></a><pre><span class="Keyword">proc</span> <span class="Identifier">exp</span><span class="Other">(</span><span class="Identifier">t</span><span class="DecNumber">150955</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Auto-generated universal version of the function.</p>
<p>The function can be used directly on tensors and will work element-wise.</p>


</dd>
<dt id="arccos"><a name="arccos,Tensor"></a><pre><span class="Keyword">proc</span> <span class="Identifier">arccos</span><span class="Other">(</span><span class="Identifier">t</span><span class="DecNumber">150997</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Auto-generated universal version of the function.</p>
<p>The function can be used directly on tensors and will work element-wise.</p>


</dd>
<dt id="arcsin"><a name="arcsin,Tensor"></a><pre><span class="Keyword">proc</span> <span class="Identifier">arcsin</span><span class="Other">(</span><span class="Identifier">t</span><span class="DecNumber">151039</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Auto-generated universal version of the function.</p>
<p>The function can be used directly on tensors and will work element-wise.</p>


</dd>
<dt id="arctan"><a name="arctan,Tensor"></a><pre><span class="Keyword">proc</span> <span class="Identifier">arctan</span><span class="Other">(</span><span class="Identifier">t</span><span class="DecNumber">151081</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Auto-generated universal version of the function.</p>
<p>The function can be used directly on tensors and will work element-wise.</p>


</dd>
<dt id="cos"><a name="cos,Tensor"></a><pre><span class="Keyword">proc</span> <span class="Identifier">cos</span><span class="Other">(</span><span class="Identifier">t</span><span class="DecNumber">151123</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Auto-generated universal version of the function.</p>
<p>The function can be used directly on tensors and will work element-wise.</p>


</dd>
<dt id="cosh"><a name="cosh,Tensor"></a><pre><span class="Keyword">proc</span> <span class="Identifier">cosh</span><span class="Other">(</span><span class="Identifier">t</span><span class="DecNumber">151165</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Auto-generated universal version of the function.</p>
<p>The function can be used directly on tensors and will work element-wise.</p>


</dd>
<dt id="sinh"><a name="sinh,Tensor"></a><pre><span class="Keyword">proc</span> <span class="Identifier">sinh</span><span class="Other">(</span><span class="Identifier">t</span><span class="DecNumber">151207</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Auto-generated universal version of the function.</p>
<p>The function can be used directly on tensors and will work element-wise.</p>


</dd>
<dt id="sin"><a name="sin,Tensor"></a><pre><span class="Keyword">proc</span> <span class="Identifier">sin</span><span class="Other">(</span><span class="Identifier">t</span><span class="DecNumber">151249</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Auto-generated universal version of the function.</p>
<p>The function can be used directly on tensors and will work element-wise.</p>


</dd>
<dt id="tan"><a name="tan,Tensor"></a><pre><span class="Keyword">proc</span> <span class="Identifier">tan</span><span class="Other">(</span><span class="Identifier">t</span><span class="DecNumber">151291</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Auto-generated universal version of the function.</p>
<p>The function can be used directly on tensors and will work element-wise.</p>


</dd>
<dt id="tanh"><a name="tanh,Tensor"></a><pre><span class="Keyword">proc</span> <span class="Identifier">tanh</span><span class="Other">(</span><span class="Identifier">t</span><span class="DecNumber">151333</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Auto-generated universal version of the function.</p>
<p>The function can be used directly on tensors and will work element-wise.</p>


</dd>
<dt id="erf"><a name="erf,Tensor"></a><pre><span class="Keyword">proc</span> <span class="Identifier">erf</span><span class="Other">(</span><span class="Identifier">t</span><span class="DecNumber">151375</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Auto-generated universal version of the function.</p>
<p>The function can be used directly on tensors and will work element-wise.</p>


</dd>
<dt id="erfc"><a name="erfc,Tensor"></a><pre><span class="Keyword">proc</span> <span class="Identifier">erfc</span><span class="Other">(</span><span class="Identifier">t</span><span class="DecNumber">151417</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Auto-generated universal version of the function.</p>
<p>The function can be used directly on tensors and will work element-wise.</p>


</dd>
<dt id="lgamma"><a name="lgamma,Tensor"></a><pre><span class="Keyword">proc</span> <span class="Identifier">lgamma</span><span class="Other">(</span><span class="Identifier">t</span><span class="DecNumber">151459</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Auto-generated universal version of the function.</p>
<p>The function can be used directly on tensors and will work element-wise.</p>


</dd>
<dt id="tgamma"><a name="tgamma,Tensor"></a><pre><span class="Keyword">proc</span> <span class="Identifier">tgamma</span><span class="Other">(</span><span class="Identifier">t</span><span class="DecNumber">151501</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Auto-generated universal version of the function.</p>
<p>The function can be used directly on tensors and will work element-wise.</p>


</dd>
<dt id="floor"><a name="floor,Tensor"></a><pre><span class="Keyword">proc</span> <span class="Identifier">floor</span><span class="Other">(</span><span class="Identifier">t</span><span class="DecNumber">151543</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Auto-generated universal version of the function.</p>
<p>The function can be used directly on tensors and will work element-wise.</p>


</dd>
<dt id="ceil"><a name="ceil,Tensor"></a><pre><span class="Keyword">proc</span> <span class="Identifier">ceil</span><span class="Other">(</span><span class="Identifier">t</span><span class="DecNumber">151585</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Auto-generated universal version of the function.</p>
<p>The function can be used directly on tensors and will work element-wise.</p>


</dd>
<dt id="trunc"><a name="trunc,Tensor"></a><pre><span class="Keyword">proc</span> <span class="Identifier">trunc</span><span class="Other">(</span><span class="Identifier">t</span><span class="DecNumber">151627</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Auto-generated universal version of the function.</p>
<p>The function can be used directly on tensors and will work element-wise.</p>


</dd>
<dt id="round"><a name="round,Tensor"></a><pre><span class="Keyword">proc</span> <span class="Identifier">round</span><span class="Other">(</span><span class="Identifier">t</span><span class="DecNumber">151669</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Auto-generated universal version of the function.</p>
<p>The function can be used directly on tensors and will work element-wise.</p>


</dd>
<dt id="degToRad"><a name="degToRad,Tensor"></a><pre><span class="Keyword">proc</span> <span class="Identifier">degToRad</span><span class="Other">(</span><span class="Identifier">t</span><span class="DecNumber">151711</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Auto-generated universal version of the function.</p>
<p>The function can be used directly on tensors and will work element-wise.</p>


</dd>
<dt id="radToDeg"><a name="radToDeg,Tensor"></a><pre><span class="Keyword">proc</span> <span class="Identifier">radToDeg</span><span class="Other">(</span><span class="Identifier">t</span><span class="DecNumber">151753</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Auto-generated universal version of the function.</p>
<p>The function can be used directly on tensors and will work element-wise.</p>


</dd>
<dt id="dot"><a name="dot,Tensor[T: SomeReal],Tensor[T: SomeReal]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">dot</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeReal</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">a</span><span class="Other">,</span> <span class="Identifier">b</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">T</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Vector to Vector dot (scalar) product

</dd>
<dt id="dot"><a name="dot,Tensor[T: SomeInteger],Tensor[T: SomeInteger]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">dot</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeInteger</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">a</span><span class="Other">,</span> <span class="Identifier">b</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">T</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Vector to Vector dot (scalar) product

</dd>
<dt id="+"><a name="+,Tensor[T: SomeNumber],Tensor[T: SomeNumber]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`+`</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeNumber</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">a</span><span class="Other">,</span> <span class="Identifier">b</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Tensor addition

</dd>
<dt id="+="><a name="+=,Tensor[T: SomeNumber],Tensor[T: SomeNumber]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`+=`</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeNumber</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">a</span><span class="Other">:</span> <span class="Keyword">var</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">b</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Tensor in-place addition

</dd>
<dt id="-"><a name="-,Tensor[T: SomeNumber]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`-`</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeNumber</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Negate all values of a Tensor

</dd>
<dt id="-"><a name="-,Tensor[T: SomeNumber],Tensor[T: SomeNumber]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`-`</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeNumber</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">a</span><span class="Other">,</span> <span class="Identifier">b</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Tensor substraction

</dd>
<dt id="-="><a name="-=,Tensor[T: SomeNumber],Tensor[T: SomeNumber]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`-=`</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeNumber</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">a</span><span class="Other">:</span> <span class="Keyword">var</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">b</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Tensor in-place addition

</dd>
<dt id="*"><a name="*,T,Tensor[T: SomeNumber]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`*`</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeNumber</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">a</span><span class="Other">:</span> <span class="Identifier">T</span><span class="Other">;</span> <span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Element-wise multiplication by a scalar

</dd>
<dt id="*"><a name="*,Tensor[T: SomeNumber],T"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`*`</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeNumber</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">a</span><span class="Other">:</span> <span class="Identifier">T</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Element-wise multiplication by a scalar

</dd>
<dt id="*="><a name="*=,Tensor[T: SomeNumber],T"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`*=`</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeNumber</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Keyword">var</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">a</span><span class="Other">:</span> <span class="Identifier">T</span><span class="Other">)</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Element-wise multiplication by a scalar (in-place)

</dd>
<dt id="/"><a name="/,Tensor[T: SomeReal],T"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`/`</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeReal</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">a</span><span class="Other">:</span> <span class="Identifier">T</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Element-wise division by a float scalar

</dd>
<dt id="div"><a name="div,Tensor[T: SomeInteger],T"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`div`</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeInteger</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">a</span><span class="Other">:</span> <span class="Identifier">T</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Element-wise division by an integer

</dd>
<dt id="/="><a name="/=,Tensor[T: SomeReal],T"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`/=`</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeReal</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Keyword">var</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">a</span><span class="Other">:</span> <span class="Identifier">T</span><span class="Other">)</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Element-wise division by a scalar (in-place)

</dd>
<dt id="/="><a name="/=,Tensor[T: SomeInteger],T"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`/=`</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeInteger</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Keyword">var</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">a</span><span class="Other">:</span> <span class="Identifier">T</span><span class="Other">)</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Element-wise division by a scalar (in-place)

</dd>
<dt id="*"><a name="*,Tensor[T: SomeReal],Tensor[T: SomeReal]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`*`</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeReal</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">a</span><span class="Other">,</span> <span class="Identifier">b</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Matrix multiplication (Matrix-Matrix and Matrix-Vector)</p>
<p>Float operations use optimized BLAS like OpenBLAS, Intel MKL or BLIS.</p>


</dd>
<dt id="*"><a name="*,Tensor[T: SomeInteger],Tensor[T: SomeInteger]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`*`</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeInteger</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">a</span><span class="Other">,</span> <span class="Identifier">b</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Matrix-Matrix and Matrix-Vector multiplications fallback for integer tensors.</p>
<p>Integer BLAS has been implemented manually. While not as fast as BLAS for floats, it should be much faster than naive loops.</p>
<p>Note: Integers smaller than 2^31 can be converted to float64 without losing precision and can benefit from the optimized float BLAS implementations</p>


</dd>
<dt id=".+"><a name=".+,Tensor[T: SomeNumber],Tensor[T: SomeNumber]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`.+`</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeNumber</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">a</span><span class="Other">,</span> <span class="Identifier">b</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Broadcasted addition for tensors of incompatible but broadcastable shape.

</dd>
<dt id=".-"><a name=".-,Tensor[T: SomeNumber],Tensor[T: SomeNumber]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`.-`</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeNumber</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">a</span><span class="Other">,</span> <span class="Identifier">b</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Broadcasted addition for tensors of incompatible but broadcastable shape.

</dd>
<dt id=".*"><a name=".*,Tensor[T: SomeNumber],Tensor[T: SomeNumber]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`.*`</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeNumber</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">a</span><span class="Other">,</span> <span class="Identifier">b</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Element-wise multiplication (Hadamard product).</p>
<p>And broadcasted element-wise multiplication.</p>


</dd>
<dt id="./"><a name="./,Tensor[T: SomeInteger],Tensor[T: SomeInteger]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`./`</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeInteger</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">a</span><span class="Other">,</span> <span class="Identifier">b</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Tensor element-wise division for integer numbers.</p>
<p>And broadcasted element-wise division.</p>


</dd>
<dt id="./"><a name="./,Tensor[T: SomeReal],Tensor[T: SomeReal]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`./`</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeReal</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">a</span><span class="Other">,</span> <span class="Identifier">b</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Tensor element-wise division for real numbers.</p>
<p>And broadcasted element-wise division.</p>


</dd>
<dt id=".+="><a name=".+=,Tensor[T: SomeNumber],Tensor[T: SomeNumber]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`.+=`</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeNumber</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">a</span><span class="Other">:</span> <span class="Keyword">var</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">b</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Tensor broadcasted in-place addition.</p>
<p>Only the right hand side tensor can be broadcasted.</p>


</dd>
<dt id=".-="><a name=".-=,Tensor[T: SomeNumber],Tensor[T: SomeNumber]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`.-=`</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeNumber</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">a</span><span class="Other">:</span> <span class="Keyword">var</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">b</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Tensor broadcasted in-place substraction.</p>
<p>Only the right hand side tensor can be broadcasted.</p>


</dd>
<dt id=".*="><a name=".*=,Tensor[T: SomeNumber],Tensor[T: SomeNumber]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`.*=`</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeNumber</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">a</span><span class="Other">:</span> <span class="Keyword">var</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">b</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Tensor broadcasted in-place multiplication (Hadamard product)</p>
<p>Only the right hand side tensor can be broadcasted</p>


</dd>
<dt id="./="><a name="./=,Tensor[T: SomeInteger],Tensor[T: SomeInteger]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`./=`</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeInteger</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">a</span><span class="Other">:</span> <span class="Keyword">var</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">b</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Tensor broadcasted in-place integer division.</p>
<p>Only the right hand side tensor can be broadcasted.</p>


</dd>
<dt id="./="><a name="./=,Tensor[T: SomeReal],Tensor[T: SomeReal]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`./=`</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeReal</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">a</span><span class="Other">:</span> <span class="Keyword">var</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">b</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Tensor broadcasted in-place float division.</p>
<p>Only the right hand side tensor can be broadcasted.</p>


</dd>
<dt id=".+"><a name=".+,T,Tensor[T: SomeNumber]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`.+`</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeNumber</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">val</span><span class="Other">:</span> <span class="Identifier">T</span><span class="Other">;</span> <span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Broadcasted addition for tensor + scalar.

</dd>
<dt id=".+"><a name=".+,Tensor[T: SomeNumber],T"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`.+`</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeNumber</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">val</span><span class="Other">:</span> <span class="Identifier">T</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Broadcasted addition for scalar + tensor.

</dd>
<dt id=".-"><a name=".-,T,Tensor[T: SomeNumber]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`.-`</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeNumber</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">val</span><span class="Other">:</span> <span class="Identifier">T</span><span class="Other">;</span> <span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Broadcasted substraction for tensor - scalar.

</dd>
<dt id=".-"><a name=".-,Tensor[T: SomeNumber],T"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`.-`</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeNumber</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">val</span><span class="Other">:</span> <span class="Identifier">T</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Broadcasted substraction for scalar - tensor.

</dd>
<dt id="./"><a name="./,T,Tensor[T: SomeInteger]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`./`</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeInteger</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">val</span><span class="Other">:</span> <span class="Identifier">T</span><span class="Other">;</span> <span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Broadcasted division of an integer by a tensor of integers.

</dd>
<dt id="./"><a name="./,T,Tensor[T: SomeReal]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`./`</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeReal</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">val</span><span class="Other">:</span> <span class="Identifier">T</span><span class="Other">;</span> <span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Broadcasted division of a float by a tensor of floats.

</dd>
<dt id=".+="><a name=".+=,Tensor[T: SomeNumber],T"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`.+=`</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeNumber</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Keyword">var</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">val</span><span class="Other">:</span> <span class="Identifier">T</span><span class="Other">)</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Tensor in-place addition with a broadcasted scalar.

</dd>
<dt id=".-="><a name=".-=,Tensor[T: SomeNumber],T"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`.-=`</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeNumber</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Keyword">var</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">val</span><span class="Other">:</span> <span class="Identifier">T</span><span class="Other">)</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Tensor in-place substraction with a broadcasted scalar.

</dd>
<dt id="sum"><a name="sum,Tensor[T: SomeNumber]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">sum</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeNumber</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">T</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Compute the sum of all elements of T

</dd>
<dt id="sum"><a name="sum,Tensor[T: SomeNumber],int"></a><pre><span class="Keyword">proc</span> <span class="Identifier">sum</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeNumber</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">axis</span><span class="Other">:</span> <span class="Identifier">int</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Compute the sum of all elements of T along an axis

</dd>
<dt id="mean"><a name="mean,Tensor[T: SomeReal]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">mean</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeReal</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">T</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Compute the mean of all elements of T

</dd>
<dt id="mean"><a name="mean,Tensor[T: SomeReal],int"></a><pre><span class="Keyword">proc</span> <span class="Identifier">mean</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeReal</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">axis</span><span class="Other">:</span> <span class="Identifier">int</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Compute the mean of T along an axis

</dd>
<dt id="toRawSeq"><a name="toRawSeq,Tensor[T]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">toRawSeq</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">seq</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Convert a tensor to the raw sequence of data.

</dd>
<dt id="export_tensor"><a name="export_tensor,Tensor[T]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">export_tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Keyword">tuple</span><span class="Other">[</span><span class="Identifier">shape</span><span class="Other">:</span> <span class="Identifier">seq</span><span class="Other">[</span><span class="Identifier">int</span><span class="Other">]</span><span class="Other">,</span> <span class="Identifier">strides</span><span class="Other">:</span> <span class="Identifier">seq</span><span class="Other">[</span><span class="Identifier">int</span><span class="Other">]</span><span class="Other">,</span>
                                        <span class="Identifier">data</span><span class="Other">:</span> <span class="Identifier">seq</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">]</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Export the tensor as a tuple containing<ul class="simple"><li>shape</li>
<li>strides</li>
<li>data</li>
</ul>
<p>If the tensor was not contiguous (a slice for example), it is reshaped. Data is exported in C order (last index changes the fastest, column in 2D case)</p>


</dd>
<dt id="layoutOnDevice"><a name="layoutOnDevice,CudaTensor[T: SomeReal]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">layoutOnDevice</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeReal</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">CudaTensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">CudaTensorLayout</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> <span class="Other pragmabegin">{.</span><div class="pragma">
    <span class="Identifier">noSideEffect</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Store a CudaTensor shape, strides, etc information on the GPU

</dd>
<dt id="unsafeView"><a name="unsafeView,CudaTensor[T]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">unsafeView</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">CudaTensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">CudaTensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">inline</span><span class="Other">,</span> <span class="Identifier">noSideEffect</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>A CudaTensor</li>
</ul>
</dd>
<dt>Returns:</dt>
<dd><ul class="simple"><li>A shallow copy.</li>
</ul>
</dd>
<dt>Warning </dt>
<dd>Both tensors shares the same memory. Data modification on one will be reflected on the other. However modifying the shape, strides or offset will not affect the other.</dd>
</dl>


</dd>
<dt id="clone"><a name="clone,CudaTensor[T]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">clone</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">CudaTensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">CudaTensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span></pre></dt>
<dd>
<p>Clone (deep copy) a CudaTensor. Copy will not share its data with the original.</p>
<p>Tensor is copied as is. For example it will not be made contiguous. Use <cite>asContiguous</cite> for this case</p>


</dd>
<dt id="cuda"><a name="cuda,Tensor[T: SomeReal]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">cuda</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeReal</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">CudaTensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span></pre></dt>
<dd>
Convert a tensor on Cpu to a tensor on a Cuda device.

</dd>
<dt id="cpu"><a name="cpu,CudaTensor[T: SomeReal]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">cpu</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeReal</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">CudaTensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Convert a tensor on a Cuda device to a tensor on Cpu.

</dd>
<dt id="$"><a name="$,CudaTensor[T]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`$`</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">CudaTensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">string</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Pretty-print a CudaTensor (when using <tt class="docutils literal"><span class="pre">echo</span></tt> for example)

</dd>
<dt id="dot"><a name="dot,CudaTensor[T: SomeReal],CudaTensor[T: SomeReal]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">dot</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeReal</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">a</span><span class="Other">,</span> <span class="Identifier">b</span><span class="Other">:</span> <span class="Identifier">CudaTensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">T</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Vector to Vector dot (scalar) product

</dd>
<dt id="+="><a name="+=,CudaTensor[T: SomeReal],CudaTensor[T: SomeReal]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`+=`</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeReal</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">a</span><span class="Other">:</span> <span class="Keyword">var</span> <span class="Identifier">CudaTensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">b</span><span class="Other">:</span> <span class="Identifier">CudaTensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span></pre></dt>
<dd>
CudaTensor in-place addition

</dd>
<dt id="+"><a name="+,CudaTensor[T: SomeReal],CudaTensor[T: SomeReal]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`+`</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeReal</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">a</span><span class="Other">,</span> <span class="Identifier">b</span><span class="Other">:</span> <span class="Identifier">CudaTensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">CudaTensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span></pre></dt>
<dd>
CudaTensor addition

</dd>
<dt id="-="><a name="-=,CudaTensor[T: SomeReal],CudaTensor[T: SomeReal]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`-=`</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeReal</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">a</span><span class="Other">:</span> <span class="Keyword">var</span> <span class="Identifier">CudaTensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">b</span><span class="Other">:</span> <span class="Identifier">CudaTensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span></pre></dt>
<dd>
CudaTensor in-place substraction

</dd>
<dt id="-"><a name="-,CudaTensor[T: SomeReal],CudaTensor[T: SomeReal]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`-`</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeReal</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">a</span><span class="Other">,</span> <span class="Identifier">b</span><span class="Other">:</span> <span class="Identifier">CudaTensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">CudaTensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span></pre></dt>
<dd>
CudaTensor substraction

</dd>
<dt id="*="><a name="*=,CudaTensor[T: SomeReal],T"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`*=`</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeReal</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Keyword">var</span> <span class="Identifier">CudaTensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">a</span><span class="Other">:</span> <span class="Identifier">T</span><span class="Other">)</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
CudaTensor inplace multiplication by a scalar

</dd>
<dt id="*"><a name="*,T,CudaTensor[T: SomeReal]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`*`</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeReal</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">a</span><span class="Other">:</span> <span class="Identifier">T</span><span class="Other">;</span> <span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">CudaTensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">CudaTensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
CudaTensor multiplication by a scalar

</dd>
<dt id="*"><a name="*,CudaTensor[T: SomeReal],T"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`*`</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeReal</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">CudaTensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">a</span><span class="Other">:</span> <span class="Identifier">T</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">CudaTensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
CudaTensor multiplication by a scalar

</dd>
<dt id="/="><a name="/=,CudaTensor[T: SomeReal],T"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`/=`</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeReal</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Keyword">var</span> <span class="Identifier">CudaTensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">a</span><span class="Other">:</span> <span class="Identifier">T</span><span class="Other">)</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
CudaTensor in-place division by a scalar

</dd>
<dt id="/"><a name="/,CudaTensor[T: SomeReal],T"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`/`</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeReal</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">CudaTensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">a</span><span class="Other">:</span> <span class="Identifier">T</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">CudaTensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
CudaTensor division by a scalar

</dd>
<dt id="/"><a name="/,T,CudaTensor[T: SomeReal]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`/`</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeReal</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">a</span><span class="Other">:</span> <span class="Identifier">T</span><span class="Other">;</span> <span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">CudaTensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">CudaTensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">inline</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
CudaTensor division by a scalar

</dd>
<dt id="*"><a name="*,CudaTensor[T: SomeReal],CudaTensor[T: SomeReal]"></a><pre><span class="Keyword">proc</span> <span class="Identifier">`*`</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeReal</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">a</span><span class="Other">,</span> <span class="Identifier">b</span><span class="Other">:</span> <span class="Identifier">CudaTensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">CudaTensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span></pre></dt>
<dd>
Matrix multiplication (Matrix-Matrix and Matrix-Vector) on CUDA

</dd>
<dt id="transpose"><a name="transpose,CudaTensor"></a><pre><span class="Keyword">proc</span> <span class="Identifier">transpose</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">CudaTensor</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">CudaTensor</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Transpose a Tensor.</p>
<p>For N-d Tensor with shape (0, 1, 2 ... n-1) the resulting tensor will have shape (n-1, ... 2, 1, 0)</p>
<dl class="docutils"><dt>Warning  CudaTensor temporary default:</dt>
<dd>This is a no-copy operation, data is shared with the input. This proc does not guarantee that a <tt class="docutils literal"><span class="pre">let</span></tt> value is immutable.</dd>
</dl>


</dd>
<dt id="asContiguous"><a name="asContiguous,CudaTensor[T: SomeReal],OrderType,bool"></a><pre><span class="Keyword">proc</span> <span class="Identifier">asContiguous</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeReal</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">CudaTensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">layout</span><span class="Other">:</span> <span class="Identifier">OrderType</span> <span class="Other">=</span> <span class="Identifier">colMajor</span><span class="Other">;</span>
                             <span class="Identifier">force</span><span class="Other">:</span> <span class="Identifier">bool</span> <span class="Other">=</span> <span class="Identifier">false</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">CudaTensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Transform a tensor with general striding to a Tensor with contiguous layout.</p>
<p>By default CudaTensor will be colMajor (contrary to a cpu tensor).</p>
<p>By default nothing is done if the tensor is already contiguous (C Major or F major) The &quot;force&quot; parameter can force re-ordering to a specific layout</p>
<dl class="docutils"><dt>Warning  CudaTensor temporary default:</dt>
<dd>If the CudaTensor is contiguous, this is a no-copy operation, data is shared with the input. This proc does not guarantee that a <tt class="docutils literal"><span class="pre">let</span></tt> value is immutable.</dd>
</dl>


</dd>

</dl></div>
<div class="section" id="14">
<h1><a class="toc-backref" href="#14">Iterators</a></h1>
<dl class="item">
<dt id="items"><a name="items.i,Tensor[T]"></a><pre><span class="Keyword">iterator</span> <span class="Identifier">items</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">T</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Inline iterator on Tensor values</p>
<p>The iterator will iterate in C order regardingless of the tensor properties (Fortran layout, non-contiguous, slice ...). So [0, 0, 0] then [0, 0, 1] then ... then [0, 1, 0] ...</p>
<dl class="docutils"><dt>Usage:</dt>
<dd><pre class="listing"><span class="Keyword">for</span> <span class="Identifier">val</span> <span class="Keyword">in</span> <span class="Identifier">t</span><span class="Punctuation">:</span> <span class="Comment"># items is implicitly called</span>
  <span class="Identifier">val</span> <span class="Operator">+=</span> <span class="DecNumber">42</span></pre></dd>
</dl>


</dd>
<dt id="mitems"><a name="mitems.i,Tensor[T]"></a><pre><span class="Keyword">iterator</span> <span class="Identifier">mitems</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Keyword">var</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Keyword">var</span> <span class="Identifier">T</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Inline iterator on Tensor values. Values yielded can be directly modified and avoid bound-checking/index calculation with t[index] = val.</p>
<p>The iterator will iterate in C order regardingless of the tensor properties (Fortran layout, non-contiguous, slice ...). So [0, 0, 0] then [0, 0, 1] then ... then [0, 1, 0] ...</p>
<dl class="docutils"><dt>Usage:</dt>
<dd><pre class="listing"><span class="Keyword">for</span> <span class="Identifier">val</span> <span class="Keyword">in</span> <span class="Identifier">t</span><span class="Operator">.</span><span class="Identifier">mitems</span><span class="Punctuation">:</span>
  <span class="Identifier">val</span> <span class="Operator">+=</span> <span class="DecNumber">42</span></pre></dd>
</dl>


</dd>
<dt id="pairs"><a name="pairs.i,Tensor[T]"></a><pre><span class="Keyword">iterator</span> <span class="Identifier">pairs</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Other">(</span><span class="Identifier">seq</span><span class="Other">[</span><span class="Identifier">int</span><span class="Other">]</span><span class="Other">,</span> <span class="Identifier">T</span><span class="Other">)</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
<p>Inline iterator on Tensor (coordinates, values)</p>
<p>The iterator will iterate in C order regardingless of the tensor properties (Fortran layout, non-contiguous, slice ...). So [0, 0, 0] then [0, 0, 1] then ... then [0, 1, 0] ...</p>
<p>It returns a tuple of (coordinates, value) like (@[1,0,1], 1337)</p>
<dl class="docutils"><dt>Usage:</dt>
<dd><pre class="listing"><span class="Keyword">for</span> <span class="Identifier">coord</span><span class="Punctuation">,</span> <span class="Identifier">val</span> <span class="Keyword">in</span> <span class="Identifier">t</span><span class="Punctuation">:</span> <span class="Comment"># pairs is implicitly called</span>
  <span class="Identifier">echo</span> <span class="Identifier">coord</span>
  <span class="Identifier">echo</span> <span class="Identifier">val</span></pre><pre class="listing"><span class="Keyword">for</span> <span class="Identifier">coordval</span> <span class="Keyword">in</span> <span class="Identifier">t</span><span class="Operator">.</span><span class="Identifier">pairs</span><span class="Punctuation">:</span> <span class="Comment"># pairs is explicitly called</span>
  <span class="Identifier">echo</span> <span class="Identifier">coordval</span><span class="Punctuation">[</span><span class="DecNumber">0</span><span class="Punctuation">]</span>
  <span class="Identifier">echo</span> <span class="Identifier">coordval</span><span class="Punctuation">[</span><span class="DecNumber">1</span><span class="Punctuation">]</span></pre></dd>
</dl>


</dd>
<dt id="axis"><a name="axis.i,Tensor[T],int"></a><pre><span class="Keyword">iterator</span> <span class="Identifier">axis</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">axis</span><span class="Other">:</span> <span class="Identifier">int</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> <span class="Other pragmabegin">{.</span><div class="pragma"><span class="Identifier">noSideEffect</span></div><span class="Other pragmaend">.}</span></pre></dt>
<dd>
Inline iterator over an axis.<dl class="docutils"><dt>Returns:</dt>
<dd><ul class="simple"><li>A slice along the given axis at each iteration.</li>
</ul>
</dd>
</dl>
<p>Note: The slice dimension is not collapsed by default. You can use <tt class="docutils literal"><span class="pre">unsafeSqueeze</span></tt> to collapse it without copy. In this case <tt class="docutils literal"><span class="pre">unsafeSqueeze</span></tt> is safe.</p>
<dl class="docutils"><dt>Usage:</dt>
<dd><pre class="listing"><span class="Keyword">for</span> <span class="Identifier">subtensor</span> <span class="Keyword">in</span> <span class="Identifier">t</span><span class="Operator">.</span><span class="Identifier">axis</span><span class="Punctuation">(</span><span class="DecNumber">1</span><span class="Punctuation">)</span><span class="Punctuation">:</span>
  <span class="Comment"># do stuff</span></pre></dd>
</dl>


</dd>

</dl></div>
<div class="section" id="16">
<h1><a class="toc-backref" href="#16">Macros</a></h1>
<dl class="item">
<dt id="[]"><a name="[].m,AnyTensor[T],varargs[untyped]"></a><pre><span class="Keyword">macro</span> <span class="Identifier">`[]`</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">AnyTensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">args</span><span class="Other">:</span> <span class="Identifier">varargs</span><span class="Other">[</span><span class="Identifier">untyped</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">untyped</span></pre></dt>
<dd>
Slice a Tensor or a CudaTensor<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>a Tensor or a CudaTensor</li>
<li>and:<ul class="simple"><li>specific coordinates (<tt class="docutils literal"><span class="pre">varargs[int]</span></tt>)</li>
<li>or a slice (cf. tutorial)</li>
</ul>
</li>
</ul>
</dd>
<dt>Returns:</dt>
<dd><ul class="simple"><li>a value or a tensor corresponding to the slice</li>
</ul>
</dd>
<dt>Warning  CudaTensor temporary default:</dt>
<dd>For CudaTensor only, this is a no-copy operation, data is shared with the input. This proc does not guarantee that a <tt class="docutils literal"><span class="pre">let</span></tt> value is immutable.</dd>
<dt>Usage:</dt>
<dd><ul class="simple"><li>Basic indexing - foo[2, 3]</li>
<li>Basic indexing - foo[1+1, 2*2*1]</li>
<li>Basic slicing - foo[1..2, 3]</li>
<li>Basic slicing - foo[1+1..4, 3-2..2]</li>
<li>Span slices - foo[_, 3]</li>
<li>Span slices - foo[1.._, 3]</li>
<li>Span slices - foo[_..3, 3]</li>
<li>Span slices - foo[_.._, 3]</li>
<li>Stepping - foo[1..3|2, 3]</li>
<li>Span stepping - foo[_.._|2, 3]</li>
<li>Span stepping - foo[_.._|+2, 3]</li>
<li>Span stepping - foo[1.._|1, 2..3]</li>
<li>Span stepping - foo[_..&lt;4|2, 3]</li>
<li>Slicing until at n from the end - foo[0..^4, 3]</li>
<li>Span Slicing until at n from the end - foo[_..^2, 3]</li>
<li>Stepped Slicing until at n from the end - foo[1..^1|2, 3]</li>
<li>Slice from the end - foo[^1..0|-1, 3]</li>
<li>Slice from the end - expect non-negative step error - foo[^1..0, 3]</li>
<li>Slice from the end - foo[^(2*2)..2*2, 3]</li>
<li>Slice from the end - foo[^3..^2, 3]</li>
</ul>
</dd>
</dl>


</dd>
<dt id="unsafeSlice"><a name="unsafeSlice.m,Tensor[T],varargs[untyped]"></a><pre><span class="Keyword">macro</span> <span class="Identifier">unsafeSlice</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">args</span><span class="Other">:</span> <span class="Identifier">varargs</span><span class="Other">[</span><span class="Identifier">untyped</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">untyped</span></pre></dt>
<dd>
Slice a Tensor<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>a Tensor</li>
<li>and:<ul class="simple"><li>specific coordinates (<tt class="docutils literal"><span class="pre">varargs[int]</span></tt>)</li>
<li>or a slice (cf. tutorial)</li>
</ul>
</li>
</ul>
</dd>
<dt>Returns:</dt>
<dd><ul class="simple"><li>a value or a view of the Tensor corresponding to the slice</li>
</ul>
</dd>
<dt>Warning :</dt>
<dd>This is a no-copy operation, data is shared with the input. This proc does not guarantee that a <tt class="docutils literal"><span class="pre">let</span></tt> value is immutable.</dd>
<dt>Usage:</dt>
<dd>See the <tt class="docutils literal"><span class="pre">[]</span></tt> macro</dd>
</dl>


</dd>
<dt id="[]="><a name="[]=.m,Tensor[T],varargs[untyped]"></a><pre><span class="Keyword">macro</span> <span class="Identifier">`[]=`</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Keyword">var</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">args</span><span class="Other">:</span> <span class="Identifier">varargs</span><span class="Other">[</span><span class="Identifier">untyped</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">untyped</span></pre></dt>
<dd>
Modifies a tensor inplace at the corresponding location or slice<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>a <tt class="docutils literal"><span class="pre">var</span></tt> tensor</li>
<li>a location:<ul class="simple"><li>specific coordinates (<tt class="docutils literal"><span class="pre">varargs[int]</span></tt>)</li>
<li>or a slice (cf. tutorial)</li>
</ul>
</li>
<li>a value:<ul class="simple"><li>a single value that will<ul class="simple"><li>replace the value at the specific coordinates</li>
<li>or be applied to the whole slice</li>
</ul>
</li>
<li>an openarray with a shape that matches the slice</li>
<li>a tensor with a shape that matches the slice</li>
</ul>
</li>
</ul>
</dd>
<dt>Result:</dt>
<dd><ul class="simple"><li>Nothing, the tensor is modified in-place</li>
</ul>
</dd>
<dt>Usage:</dt>
<dd><ul class="simple"><li>Assign a single value - foo[1..2, 3..4] = 999</li>
<li>Assign an array/seq of values - foo[0..1,0..1] = [[111, 222], [333, 444]]</li>
<li>Assign values from a view/Tensor - foo[^2..^1,2..4] = bar</li>
<li>Assign values from the same Tensor - foo[^2..^1,2..4] = foo[^1..^2|-1, 4..2|-1]</li>
</ul>
</dd>
</dl>


</dd>

</dl></div>
<div class="section" id="17">
<h1><a class="toc-backref" href="#17">Templates</a></h1>
<dl class="item">
<dt id="rank"><a name="rank.t,AnyTensor"></a><pre><span class="Keyword">template</span> <span class="Identifier">rank</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">AnyTensor</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">int</span></pre></dt>
<dd>
<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>A tensor</li>
</ul>
</dd>
<dt>Returns:</dt>
<dd><ul class="simple"><li>Its rank</li>
</ul>
</dd>
<dt></dt>
<dd><ul class="simple"><li>0 for scalar (unfortunately cannot be stored)</li>
<li>1 for vector</li>
<li>2 for matrices</li>
<li>N for N-dimension array</li>
</ul>
</dd>
</dl>


</dd>
<dt id="get_data_ptr"><a name="get_data_ptr.t,AnyTensor[T]"></a><pre><span class="Keyword">template</span> <span class="Identifier">get_data_ptr</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">AnyTensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Keyword">ptr</span> <span class="Identifier">T</span></pre></dt>
<dd>
<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>A tensor</li>
</ul>
</dd>
<dt>Returns:</dt>
<dd><ul class="simple"><li>A pointer to the start of its data</li>
</ul>
</dd>
</dl>


</dd>
<dt id="bc"><a name="bc.t,,openArray[int]"></a><pre><span class="Keyword">template</span> <span class="Identifier">bc</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Other">(</span><span class="Identifier">Tensor</span> <span class="Operator">|</span> <span class="Identifier">SomeNumber</span><span class="Other">)</span><span class="Other">;</span> <span class="Identifier">shape</span><span class="Other">:</span> <span class="Identifier">openArray</span><span class="Other">[</span><span class="Identifier">int</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">untyped</span></pre></dt>
<dd>
Alias for <tt class="docutils literal"><span class="pre">broadcast</span></tt>

</dd>
<dt id="makeUniversal"><a name="makeUniversal.t,untyped"></a><pre><span class="Keyword">template</span> <span class="Identifier">makeUniversal</span><span class="Other">(</span><span class="Identifier">func_name</span><span class="Other">:</span> <span class="Identifier">untyped</span><span class="Other">)</span></pre></dt>
<dd>
<p>Auto-generated universal version of the function.</p>
<p>The function can be used directly on tensors and will work element-wise.</p>


</dd>
<dt id="makeUniversalLocal"><a name="makeUniversalLocal.t,untyped"></a><pre><span class="Keyword">template</span> <span class="Identifier">makeUniversalLocal</span><span class="Other">(</span><span class="Identifier">func_name</span><span class="Other">:</span> <span class="Identifier">untyped</span><span class="Other">)</span></pre></dt>
<dd>


</dd>
<dt id="rewriteToTensorReshape"><a name="rewriteToTensorReshape.t,openArray,varargs[int],"></a><pre><span class="Keyword">template</span> <span class="Identifier">rewriteToTensorReshape</span><span class="Other">{</span><span class="Identifier">reshape</span><span class="Other">(</span><span class="Identifier">toTensor</span><span class="Other">(</span><span class="Identifier">oa</span><span class="Other">,</span> <span class="Identifier">dummy_bugfix</span><span class="Other">)</span><span class="Other">,</span> <span class="Identifier">shape</span><span class="Other">)</span>
<span class="Other">}</span><span class="Other">(</span><span class="Identifier">oa</span><span class="Other">:</span> <span class="Identifier">openArray</span><span class="Other">;</span> <span class="Identifier">shape</span><span class="Other">:</span> <span class="Identifier">varargs</span><span class="Other">[</span><span class="Identifier">int</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">dummy_bugfix</span><span class="Other">:</span> <span class="Keyword">static</span><span class="Other">[</span><span class="Identifier">int</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">auto</span></pre></dt>
<dd>
<p>Fuse <tt class="docutils literal"><span class="pre">sequence.toTensor.reshape(new_shape)</span></tt> into a single operation.</p>
<p>Operation fusion leverage the Nim compiler and should not be called explicitly.</p>


</dd>
<dt id="at"><a name="at.t,Tensor[T],varargs[untyped]"></a><pre><span class="Keyword">template</span> <span class="Identifier">at</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">args</span><span class="Other">:</span> <span class="Identifier">varargs</span><span class="Other">[</span><span class="Identifier">untyped</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">untyped</span></pre></dt>
<dd>
Slice a Tensor and collapse singleton dimension.<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>a Tensor</li>
<li>and:<ul class="simple"><li>specific coordinates (<tt class="docutils literal"><span class="pre">varargs[int]</span></tt>)</li>
<li>or a slice (cf. tutorial)</li>
</ul>
</li>
</ul>
</dd>
<dt>Returns:</dt>
<dd><ul class="simple"><li>a value or a view of the Tensor corresponding to the slice Singleton dimension are collapsed</li>
</ul>
</dd>
<dt>Usage:</dt>
<dd>See the <tt class="docutils literal"><span class="pre">[]</span></tt> macro</dd>
</dl>


</dd>
<dt id="unsafeAt"><a name="unsafeAt.t,Tensor[T],varargs[untyped]"></a><pre><span class="Keyword">template</span> <span class="Identifier">unsafeAt</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Identifier">Tensor</span><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">args</span><span class="Other">:</span> <span class="Identifier">varargs</span><span class="Other">[</span><span class="Identifier">untyped</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">untyped</span></pre></dt>
<dd>
<p>Slice a Tensor and collapse singleton dimension.</p>
<p>Data is shared between input and output.</p>
<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>a Tensor</li>
<li>and:<ul class="simple"><li>specific coordinates (<tt class="docutils literal"><span class="pre">varargs[int]</span></tt>)</li>
<li>or a slice (cf. tutorial)</li>
</ul>
</li>
</ul>
</dd>
<dt>Returns:</dt>
<dd><ul class="simple"><li>a value or a view of the Tensor corresponding to the slice Singleton dimension are collapsed</li>
</ul>
</dd>
<dt>Warning :</dt>
<dd>This is a no-copy operation, data is shared with the input. This proc does not guarantee that a <tt class="docutils literal"><span class="pre">let</span></tt> value is immutable.</dd>
<dt>Usage:</dt>
<dd>See the <tt class="docutils literal"><span class="pre">[]</span></tt> macro</dd>
</dl>


</dd>

</dl></div>

  </div>
</div>

    <div class="row">
      <div class="twelve-columns footer">
        <span class="nim-sprite"></span>
        <br/>
        <small>Made with Nim. Generated: 2017-09-24 18:49:04 UTC</small>
      </div>
    </div>
  </div>
</div>

</body>
</html>
